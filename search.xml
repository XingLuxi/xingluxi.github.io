<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Recent Advances on Multi-Hop RC - HotpotQA</title>
      <link href="/2019/05/30/mrc-paper-hotpotqa/"/>
      <url>/2019/05/30/mrc-paper-hotpotqa/</url>
      
        <content type="html"><![CDATA[<p><strong>HotpotQA</strong> is a dataset for <strong>Diverse</strong>, <strong>Explainable</strong> <strong>Multi-hop</strong> Question Answering.</p><p>HotpotQA has 4 features, which can also be seen as challenges:</p><ul><li>questions require finding and reasoning over multiple supporting documents to answer</li><li>questions are diverse and not constrained to any pre-existing knowledge</li><li>contains two types of questions: 1.<strong>bridge</strong> and 2.<strong>comparison</strong> (factoid comparision questions)</li><li>provides sentence-level supporting facts required for reasoning<ul><li>introduces the <strong>strong supervision</strong> for reasoning and make the final predictions <strong>explainable</strong></li></ul></li><li>(can form a reasoning chain through the support facts)</li></ul><p>Reference papers on HotpotQA task:</p><blockquote><ol start="0"><li>Cognitive Graph for Multi-Hop Reading Comprehension at Scale. ACL, 2019.</li><li>Dynamically Fused Graph Network for Multi-Hop Reasoning. ACL, 2019.</li><li>Answering while Summarizing: Multi-task Learning for Multi-Hop QA with Evidence Extraction. ACL, 2019.</li></ol></blockquote><h2 id="Cognitive-Graph-QA"><a href="#Cognitive-Graph-QA" class="headerlink" title="Cognitive Graph QA"></a>Cognitive Graph QA</h2><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>Dual Process Theory</p><h3 id="Model-Details"><a href="#Model-Details" class="headerlink" title="Model Details"></a>Model Details</h3><h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><h2 id="Dynamically-Fused-Graph-Network"><a href="#Dynamically-Fused-Graph-Network" class="headerlink" title="Dynamically Fused Graph Network"></a>Dynamically Fused Graph Network</h2><h3 id="Motivation-1"><a href="#Motivation-1" class="headerlink" title="Motivation"></a>Motivation</h3><h3 id="Model-Details-1"><a href="#Model-Details-1" class="headerlink" title="Model Details"></a>Model Details</h3><h2 id="Query-Focused-Extractor"><a href="#Query-Focused-Extractor" class="headerlink" title="Query Focused Extractor"></a>Query Focused Extractor</h2><h3 id="Motivation-2"><a href="#Motivation-2" class="headerlink" title="Motivation"></a>Motivation</h3><h3 id="Model-Details-2"><a href="#Model-Details-2" class="headerlink" title="Model Details"></a>Model Details</h3><h3 id="Experiments-1"><a href="#Experiments-1" class="headerlink" title="Experiments"></a>Experiments</h3>]]></content>
      
      
      <categories>
          
          <category> MRC-Paper-Intro </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> mrc </tag>
            
            <tag> paper </tag>
            
            <tag> multi-hop </tag>
            
            <tag> gnn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Commonsense Reasoning for Natural Language Understanding - A Survey of Benchmarks, Resources, and Approachs</title>
      <link href="/2019/04/18/mrc-cs-reasoning-for-nlu-survey/"/>
      <url>/2019/04/18/mrc-cs-reasoning-for-nlu-survey/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Authors: Shane Storks, Qianzi Gao, Joyce Y. Chai<br>Org.: Department of Computers Science and Engineering, Michigan State University<br>Year: 2019</p></blockquote><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Commonsense Knowledge (CS Know.) 和 Commonsense Reasoning 是机器智能的两大重要瓶颈。</p><p>现有的NLP研究中，已经提出了一些需要常识推理的benchmarks和tasks，旨在评估机器获得和学习常识知识的能力。</p><p>这篇文章的主要目的是针对NLU的常识推理，提供关于以下四个方面的一个综述：</p><ul><li><p>现有的任务和benchmarks</p></li><li><p>Knowledge Resources</p></li><li><p>Learning and Inference Approachs</p></li><li><p>关于本篇文章的思维导图：</p><ul><li><img src="/.io//mind.png" alt="mind-note"></li></ul></li></ul><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1.Introduction"></a>1.Introduction</h2><p>Davis and Marcus (2015)[^davis] 指出常识推理的挑战：spans from difficulties in <strong>understanding and formulating commonsense knowledge for specific or general domains</strong> to complexities in <strong>various forms of reasoning and their integration for problem solving</strong>.</p><p>现有的研究主要关注如下图所示的几个方面：(在这篇文章中主要关注文本数据源)</p><p><img src="/.io//overview.png" alt="image-overview"></p><h2 id="2-Benchmarks-and-Tasks"><a href="#2-Benchmarks-and-Tasks" class="headerlink" title="2.Benchmarks and Tasks"></a>2.Benchmarks and Tasks</h2><p>这章主要介绍一些需要常识推理的benchmarks，以及对构建这类benchmarks的重要要求进行一个总结。</p><ul><li>benchmarks数据集的发展：<ul><li><img src="/.io//benchmark-trend.png" alt="benchmark-trend"></li></ul></li></ul><h3 id="2-1-Overivew-of-ExistingBenchmarks"><a href="#2-1-Overivew-of-ExistingBenchmarks" class="headerlink" title="2.1 Overivew of ExistingBenchmarks"></a>2.1 Overivew of ExistingBenchmarks</h3><p>很多常识benchmark数据集都是基于classic language processing问题建立起的，从focused task (共指消解、命名实体识别) 到更理解性的任务和应用。</p><p>Benchmarks不应该局限于需要 language processing 能力提升性能的类型，应该更有针对性，更关注某类的常识知识和推理 (或是某几类的混合) 。</p><p>将Benchmarks分为6类，分别展开介绍</p><h4 id="2-1-1-Coreference-Resolution"><a href="#2-1-1-Coreference-Resolution" class="headerlink" title="2.1.1 Coreference Resolution"></a>2.1.1 Coreference Resolution</h4><p>共指消解是NLU中的一个基本任务，在句子中出现<strong>多个代名词或明显复杂的过程</strong>时，需要常识知识确定决策。</p><ul><li>代表数据集：Winograd Schema Challenge (<a href="http://commonsensereasoning.org/winograd.html" target="_blank" rel="noopener">link</a>)</li></ul><h4 id="2-1-2-Question-Answering"><a href="#2-1-2-Question-Answering" class="headerlink" title="2.1.2 Question Answering"></a>2.1.2 Question Answering</h4><p>相比于只关注某些特定的语言处理或是推理的任务，QA提供了一种在单个任务中更全面地混合语言处理和推理技巧的benchmark。</p><blockquote><p>contain questions requiring commonsense knowledge alongside question requiring comprehension of a given text.</p></blockquote><ul><li>代表数据集：ARC、MCScript、ProPara、MultiRC、SQuADv2、CoQA、OpenBookQA、CommonsenseQA<ul><li>ProPara：面向过程性文本，旨在学习目标的追踪和状态变化</li></ul></li></ul><h4 id="2-1-3-Textual-Entailment"><a href="#2-1-3-Textual-Entailment" class="headerlink" title="2.1.3 Textual Entailment"></a>2.1.3 Textual Entailment</h4><p>文本推理任务旨在推理两个句子之间的关系，需要多种语言处理能力（paraphrase）以及object tracking、causal reasoning和常识知识。</p><ul><li>代表数据集：RTE challenges、SICK、SNLI、SciTail</li><li>RTE knowledge resources: <a href="https://aclweb.org/aclwiki/RTE_Knowledge_Resources" target="_blank" rel="noopener">https://aclweb.org/aclwiki/RTE_Knowledge_Resources</a></li></ul><h4 id="2-1-4-Plausible-Inference"><a href="#2-1-4-Plausible-Inference" class="headerlink" title="2.1.4 Plausible Inference"></a>2.1.4 Plausible Inference</h4><p>似然推理：require hypothetical, intermediate or uncertain conclusions defined as plausible inference.</p><p>这类数据集关注的是everyday events和interactions，包含各种的实际的常识关系。</p><ul><li>代表数据集：COPA、CBT、ROCStories、JOCI、CLOTH、SWAG、ReCoRD</li></ul><h4 id="2-1-5-Psychological-Reasoning"><a href="#2-1-5-Psychological-Reasoning" class="headerlink" title="2.1.5 Psychological Reasoning"></a>2.1.5 Psychological Reasoning</h4><p>心理推理：关于情绪（情感）和意图的推理，需要社会心理学的常识知识</p><ul><li>代表数据集：Triangle-COPA、Story Commonsense、Event2Mind<ul><li>StoryCommonsense[^rashkin-2018a]：要求预测Motivation和Emotions，以及Maslow (human need)、Reiss (human motives)、Plutchik (emotions)<ul><li>link：<a href="http://uwnlp.github.io/storycommonsense" target="_blank" rel="noopener">http://uwnlp.github.io/storycommonsense</a></li><li>Theories of Motivation (Maslow and Reiss) and Emotional Reaction (Plutchik): <img src="/.io//MaslowReissPlutchik.png" alt="png"></li></ul></li><li>Event2Mind[^rashkin-2018b]：推理关于事件的intentions和reactions，每个事件都有1到2个参与者，三个任务：预测主要参与者的意图和反应，并预测其他人的反应<ul><li>link：<a href="http://uwnlp.github.io/event2mind" target="_blank" rel="noopener">http://uwnlp.github.io/event2mind</a></li></ul></li></ul></li></ul><h4 id="2-1-6-Multiple-Tasks"><a href="#2-1-6-Multiple-Tasks" class="headerlink" title="2.1.6 Multiple Tasks"></a>2.1.6 Multiple Tasks</h4><p>consist of several focused language processing or reasoning tasks so that reading comprehension skills can be learned one by one in a consistent format</p><ul><li>代表数据集：bAbI、IIE、GLUE、DNC<ul><li>IIE：Inference is Everything，RTE的形式</li><li>DNC [^poliak]：Diverse Natural Language Inference Collection，包含9个NLI任务需要7中不同类型的推理<ul><li>recast from：<ul><li>Event Factuality, recast from UW (Lee, Artzi, Choi, &amp; Zettlemoyer, 2015), MEANTIME (Minard, Speranza, Urizar, Altuna, van Erp, Schoen, &amp; van Son, 2016), and (Rudinger, White, &amp; Van Durme, 2018b)</li><li>Named Entity Recognition, recast from the Groningen Meaning Bank (Bos, Basile, Evang, Venhuizen, &amp; Bjerva, 2017) and the ConLL-2003 shared task (Tjong Kim Sang &amp; De Meulder, 2003)</li><li>Gendered Anaphora Resolution, recast from the Winogender dataset (Rudinger et al., 2018a)</li><li>Lexicosyntactic Inference, recast from MegaVeridicality (White &amp; Rawlins, 2018), VerbNet (Schuler, 2005), and VerbCorner (Hartshorne, Bonial, &amp; Palmer, 2013)</li><li>Figurative Language, recast from puns by Yang, Lavie, Dyer, and Hovy (2015) and Miller, Hempelmann, and Gurevych (2017)</li><li>Relation Extraction, partially from FACC1 (Gabrilovich, Ringgaard, &amp; Subramanya, 2013)</li><li>Subjectivity, recast from Kotzias, Denil, De Freitas, and Smyth (2015)</li></ul></li><li>link：<a href="http://github.com/decompositional-semantics-initiative/DNC" target="_blank" rel="noopener">http://github.com/decompositional-semantics-initiative/DNC</a></li></ul></li></ul></li></ul><h3 id="2-2-Criteria-and-Consideration-for-Creating-Benchmarks"><a href="#2-2-Criteria-and-Consideration-for-Creating-Benchmarks" class="headerlink" title="2.2 Criteria and Consideration for Creating Benchmarks"></a>2.2 Criteria and Consideration for Creating Benchmarks</h3><h4 id="2-2-1-Task-Format"><a href="#2-2-1-Task-Format" class="headerlink" title="2.2.1 Task Format"></a>2.2.1 Task Format</h4><p>决定任务形式对于Benchmarks的创建是重要的一步，现有的任务形式有三类：</p><ul><li>Classification Task：有三种形式<ul><li>Textual Entailment Task</li><li>Cloze Task</li><li>Traditional Multiple-Choice Task</li></ul></li><li>Open-ended Task：开放式任务<ul><li>Span</li><li>Subset of category labels：Story Commonsense</li><li>Purely open-ended：Event2Mind、bAbI</li><li><del>Generative</del></li></ul></li></ul><h4 id="2-2-2-Evaluation-Schemes"><a href="#2-2-2-Evaluation-Schemes" class="headerlink" title="2.2.2 Evaluation Schemes"></a>2.2.2 Evaluation Schemes</h4><p>评测形式</p><p>现有的评测结果都是直接给出是否通过(pass or fail grade)，没有任何反馈</p><p>理想的评测形式应该考虑有信息的指标，可以比较不同的方法，比较机器和人之间性能表现的差异</p><ul><li>Evaluation Metrics：Precision、Recall、F-Measure、Exact-Match、Recall@k、BLEU、ROUGE</li><li>Comparison of Approaches</li><li>Human Performance Measurement</li></ul><h4 id="2-2-3-Data-Biases"><a href="#2-2-3-Data-Biases" class="headerlink" title="2.2.3 Data Biases"></a>2.2.3 Data Biases</h4><p>数据分布的平衡</p><ul><li>Label Distribution Bias</li><li>Question Type Bias</li><li>Superficial Correlation Bias：gender bias</li></ul><h4 id="2-2-4-Collection-Methods"><a href="#2-2-4-Collection-Methods" class="headerlink" title="2.2.4 Collection Methods"></a>2.2.4 Collection Methods</h4><p>[Not Focus]</p><ul><li>Manual versus Automatic Generation</li><li>Automatic Generation versus Text Mining</li><li>Crowsourcing Considerations</li></ul><h2 id="3-Knowledge-Resources"><a href="#3-Knowledge-Resources" class="headerlink" title="3.Knowledge Resources"></a>3.Knowledge Resources</h2><h3 id="3-1-Overview-of-Knowledge-Resources-for-NLU"><a href="#3-1-Overview-of-Knowledge-Resources-for-NLU" class="headerlink" title="3.1 Overview of Knowledge Resources for NLU"></a>3.1 Overview of Knowledge Resources for NLU</h3><p>为了理解自然语言，通常需要语言学知识来却确定文本的句法、语义结构，再进一步使用通识、常识知识来增强对结构的理解，以达到更全面的理解</p><h4 id="3-1-1-Linguistic-Knowledge-Resources"><a href="#3-1-1-Linguistic-Knowledge-Resources" class="headerlink" title="3.1.1 Linguistic Knowledge Resources"></a>3.1.1 Linguistic Knowledge Resources</h4><p>带标记的句法、语义、篇章结构资源</p><ul><li>Annotated Linguistic Corpora<ul><li>Penn TreeBank：POS tags &amp; syntactic structures based on context-free grammar</li><li>PropBank：predicate-argument structures</li><li>Penn Discourse TreeBank</li><li>Abstract Meaning Representation (AMR)</li></ul></li><li>Lexical Resources<ul><li>WordNet</li><li>VerbNet：hierarchical English Verb lexicon</li><li>FrameNet：frame semantics for a set of verbs</li></ul></li></ul><h4 id="3-1-2-Common-Knowledge-Resources"><a href="#3-1-2-Common-Knowledge-Resources" class="headerlink" title="3.1.2 Common Knowledge Resources"></a>3.1.2 Common Knowledge Resources</h4><blockquote><p><strong><font color="blue">Common knowledge refers to speciﬁc facts about the world that are often explicitly stated.</font></strong></p></blockquote><p>与Commonsense Knowledge的不同是[^cambria-2011]：CS Know. required to achieve a deep understanding of both the low- and high-level concepts found in language.</p><ul><li>Yet Another Great Ontology (YAGO): with common knowledge facts extracted from Wikipedia, converting WordNet from a primarily linguistic resource to a common knowledge base.</li><li>DBpedia: Wikipedia-based knowledge base originally consisting of structured knowledge from more than 1.95 million Wikipedia articles.</li><li>WikiTaxonomy: consists of about 105,000 well-evaluated semantic links between categories in Wikipedia articles. Categories and relationships are labeled using the connectivity of the conceptual network formed by the categories.</li><li>Freebase</li><li>NELL</li><li>Probase</li></ul><h4 id="3-1-3-Commonsense-Knowledge-Resources"><a href="#3-1-3-Commonsense-Knowledge-Resources" class="headerlink" title="3.1.3 Commonsense Knowledge Resources"></a>3.1.3 Commonsense Knowledge Resources</h4><blockquote><p><strong><font color="blue">Commonsense knowledge, on the other hand, is considered obvious to most humans, and not so likely to be explicitly stated</font></strong></p><p>Cambria, E., Song, Y., Wang, H., &amp; Hussain, A. (2011). Isanette: A Common and Common Sense Knowledge Base for Opinion Mining. In 2011 IEEE 11th International Conference on Data Mining Workshops, pp. 315–322, Vancouver, BC, Canada. IEEE.</p></blockquote><ul><li>Cyc</li><li>ConceptNet</li><li>AnalogySpace<ul><li>is an algorithm for reducing the dimensionality of commonsense knowledge so that knowledge bases can be more efﬁciently and accurately reasoned over.</li></ul></li><li>SenticNet: intended for sentiment analysis</li><li>IsaCore: a set of “is a” relationships and conﬁdences.<ul><li><a href="http://sentic.net/downloads" target="_blank" rel="noopener">http://sentic.net/downloads</a></li></ul></li><li>COGBASE</li><li>WebChild</li><li>LocatedNear</li><li>Atlas of Machine Commonsense (ATOMIC)<ul><li>about 300,000 nodes corresponding to short textual descriptions of events, and about 877,000 “if-event-then” triples representing if-then relationships between everyday events.</li></ul></li></ul><h3 id="3-2-Approaches-to-Creating-Knowledge-Resources"><a href="#3-2-Approaches-to-Creating-Knowledge-Resources" class="headerlink" title="3.2 Approaches to Creating Knowledge Resources"></a>3.2 Approaches to Creating Knowledge Resources</h3><blockquote><p>The goal is to create general knowledge bases to <strong>provide inductive bias for a variety of learning and reasoning tasks</strong></p></blockquote><ul><li>Manual Encoding</li><li>Text Mining</li><li>Crowdsourcing</li></ul><h2 id="4-Learning-and-Inference-Approaches"><a href="#4-Learning-and-Inference-Approaches" class="headerlink" title="4.Learning and Inference Approaches"></a>4.Learning and Inference Approaches</h2><h3 id="4-1-Symbolic-and-Statistical-Approaches"><a href="#4-1-Symbolic-and-Statistical-Approaches" class="headerlink" title="4.1 Symbolic and Statistical Approaches"></a>4.1 Symbolic and Statistical Approaches</h3><h3 id="4-2-Neural-Approaches"><a href="#4-2-Neural-Approaches" class="headerlink" title="4.2 Neural Approaches"></a>4.2 Neural Approaches</h3><ul><li>common components in neural models: <ul><li><img src="/.io//neural-approachs.png" alt="neural"></li></ul></li></ul><h4 id="4-2-1-Memory-Augmentation"><a href="#4-2-1-Memory-Augmentation" class="headerlink" title="4.2.1 Memory Augmentation"></a>4.2.1 Memory Augmentation</h4><p>针对需要理解状态变化或是具有多个支撑事实来进行文本理解的任务</p><h5 id="Memory-Network"><a href="#Memory-Network" class="headerlink" title="Memory Network"></a>Memory Network</h5><ul><li>add a long-term memory component to track the world state and context</li><li>MemNet can efficiently leverage a wider context in making inferences<ul><li>outperform primarily RNN and LSTM based models</li></ul></li></ul><h5 id="Recurrent-Entity-Networks-ENTENT"><a href="#Recurrent-Entity-Networks-ENTENT" class="headerlink" title="Recurrent Entity Networks (ENTENT)"></a>Recurrent Entity Networks (ENTENT)</h5><blockquote><p>Henaff, M., Weston, J., Szlam, A., Bordes, A., &amp; LeCun, Y. (2017).<br>Tracking the World State with Recurrent Entity Networks. In Proceedings of the 5th International Conference on Learning Representations.<br>ICLR,2017.</p></blockquote><ul><li>composed of several dynamic memory cell<ul><li>each cell learns to represent the <strong>state</strong> or <strong>properties</strong> concerning entities mentioned in the input.</li><li>each cell is a Gated-RNN, only updates its content when new information relevant to the particular entity is received</li><li>run in parallel, allow multiple locations of memory to be updated at the same time.</li></ul></li><li>unlike MemNet:<ul><li>MemNet only preform reasoning when the entire supporting text and the question are processed and loaded to the memory.</li><li>when given a supporting text with multiple questions:<ul><li>ENTENT do not need to process the input text multiple times to answer these question.</li><li>MemNet need to re-process the whole input for each question.</li></ul></li></ul></li><li>drawbacks<ul><li>perform well in bAbI, but not in ProPara</li><li>maintain memory registers for entities, it has no separate embedding for individual states of entities over time</li><li>do not explicitly update coreferences in memory</li></ul></li></ul><h5 id="KG-MRC"><a href="#KG-MRC" class="headerlink" title="KG-MRC"></a>KG-MRC</h5><blockquote><p>Das, R., Munkhdalai, T., Yuan, X., Trischler, A., &amp; McCallum, A.<br>Building Dynamic Knowledge Graphs from Text using Machine Reading Comprehension.<br>ICLR, 2019</p></blockquote><p>Knowledge Graph Machine Reading Comprehension</p><ul><li>maintain a dynamic memory<ul><li>memory is in the form of knowledge graphs generated after every sentence of procedural text.</li></ul></li><li>generated knowledge graphs:<ul><li>are bipartite, connecting entities in the paragraph with their locations (currently, only capture the location relation)</li><li>connections between entities and locations are updated to generate a new graph after each sentence</li></ul></li><li>KG-MRC learns some commonsense constraints automatically.<ul><li>recurrent graph representations help.</li></ul></li></ul><h4 id="4-2-2-Attention-Mechanism"><a href="#4-2-2-Attention-Mechanism" class="headerlink" title="4.2.2 Attention Mechanism"></a>4.2.2 Attention Mechanism</h4><ul><li>automatically provides an alignment between inputs and outputs</li><li>have limitations when the alignment between inputs and outputs is not straightforward.</li><li>sequentail attention</li><li>self-attention</li><li>multi-head</li><li>comparison score function</li></ul><h4 id="4-2-3-Pre-Trained-Models-and-Representations"><a href="#4-2-3-Pre-Trained-Models-and-Representations" class="headerlink" title="4.2.3 Pre-Trained Models and Representations"></a>4.2.3 Pre-Trained Models and Representations</h4><ul><li>ELMO</li><li>GPT</li><li>BERT<ul><li>still far from human: <del>SciTail</del>、ReCoRD、OpenBookQA</li></ul></li><li>When to fine-tune<ul><li>sentence pair tasks</li></ul></li></ul><h3 id="4-3-Incorporating-External-Knowledge"><a href="#4-3-Incorporating-External-Knowledge" class="headerlink" title="4.3 Incorporating External Knowledge"></a>4.3 Incorporating External Knowledge</h3><ul><li>WordNet in Textual Entailment</li><li>ConceptNet in Commonsense Task</li><li>Main Problems：<ul><li>how to incorporate external knowledge in modern neural approaches</li><li>how to acquire relevant external knowledge</li></ul></li></ul><h2 id="5-Other-Related-Benchmarks"><a href="#5-Other-Related-Benchmarks" class="headerlink" title="5.Other Related Benchmarks"></a>5.Other Related Benchmarks</h2><ul><li>language-related tasks</li><li>visual benchmarks<ul><li>perception</li></ul></li></ul><h2 id="6-Discussion-and-Conclusion"><a href="#6-Discussion-and-Conclusion" class="headerlink" title="6.Discussion and Conclusion"></a>6.Discussion and Conclusion</h2><ul><li><p>two types of commonsense knowledge are considered fundamental for human reasoning and decision making:</p><ul><li>intuitive psychology：心理</li><li>intuitive physics：物理</li></ul></li><li><p>Challenges</p><ul><li>relation with humans: understanding <strong>how much Commonsense Knowledge is developed and acquire in humans</strong> and how they related to human Language Production and Comprehension may shed light on computational models for NLP</li><li>difficult to identify and formalize Commonsense Knowledge</li><li>disconnect between Commonsense Knowledge resources and approaches to tackle these benchmarks<ul><li>One likely reason is that these knowledge bases do not cover the kind of knowledge that is required to solve those tasks<ul><li>To address this problem, several methods have been proposed for <strong>leveraging incomplete knowledge bases</strong></li><li>Eg1 <strong>AnalogySpace</strong>：uses principle component analysis to make analogies to smooth missing commonsense axioms</li><li>Eg2 <strong>Memory Comparison Networks</strong>：allow machines to generalize over existing temporal relations in Knowledge Sources in order to acquire new relations</li></ul></li><li>jointly develop benchmark tasks and construct knowledge bases<ul><li>Event2Mind &amp; ATOMIC</li><li>CommonsenseQA &amp; ConceptNet</li></ul></li></ul></li><li>only learning superficial artifacts from the dataset<ul><li>obscure statistical biases — high preformance, but not actual reasoning</li></ul></li></ul></li></ul><p>[^davis]: Commonsense reasoning and commonsense knowledge in artiﬁcial intelligence. Commun. ACM, 58(9), 92–103.<br>[^rashkin-2018a]: Modeling Naive Psychology of Characters in Simple Commonsense Stories. ACL,2018.<br>[^rashkin-2018b]: Event2Mind: Commonsense Inference on Events, Intents, and Reactions. ACL,2018.<br>[^poliak]: Collecting Diverse Natural Language Inference Problems for Sentence Representation Evaluation. EMNLP, 2018.<br>[^cambria-2011]: Isanette: A Common and Common Sense Knowledge Base for Opinion Mining. In 2011 IEEE 11th International Conference on Data Mining Workshops, pp. 315–322, Vancouver, BC, Canada. IEEE.</p>]]></content>
      
      
      <categories>
          
          <category> MRC-Research </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> mrc </tag>
            
            <tag> knowledge </tag>
            
            <tag> reasoning </tag>
            
            <tag> survey </tag>
            
            <tag> commonsense </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Memory Networks</title>
      <link href="/2019/04/17/paper-memory-network/"/>
      <url>/2019/04/17/paper-memory-network/</url>
      
        <content type="html"><![CDATA[<p>Memory Networks 是一种框架，在这个框架内部的每个module都可以根据特定任务的需要用不同的方式来实现（task-specific）。</p><p>本篇主要以 《End-to-End Memory Networks》 (2015, MemN2N) 对 Memory Network 的框架进行介绍。</p><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><ul><li>记忆网络的核心是记忆模块，可以看做是一个知识存储器。</li><li>在学习的过程中，首先需要对这个存储器的内容进行插入或更新，然后在测试的时候依靠这个存储器中的信息对于答案进行推理判断，具体包含以下四个主要模块：<ul><li>I：输入特征映射<ul><li>将输入转换为内部特征的表示？</li><li>将输入映射到特征空间</li></ul></li><li>G：泛化<ul><li>得到新的输入时，对过去的记忆进行更新；</li><li>称为泛化的原因是：在整个过程中网络能够根据未来的某些特定需要压缩、泛化本身的记忆；</li></ul></li><li>O：输出特征映射<ul><li>根据当前的输入和记忆状态得到输出，输出的是内部特征表示的形式（以内部特征表示作为输出）</li></ul></li><li>R：响应<ul><li>将上一步中的输出转换为指定的响应格式；</li></ul></li></ul></li><li>具体过程：对于一个特定的输入：one-hop<ul><li>1、将转换为内部特征表示的形式；</li><li>2、根据输入更新记忆；</li><li>3、根据输入和记忆计算输出特征；</li><li>4、解码得到响应的结果；</li></ul></li><li>MemN2N 的模型结构图，左侧是单层结构，右侧是多层（3层）结构<ul><li><img src="/.io//memn2n-model.png" alt="MemN2N-Architecture"></li><li>Multi-hop的计算过程：<ul><li><img src="/.io//memn2n-arch-flow.png" alt="MemN2N-Architecture2"></li></ul></li><li>Memory Module:<ul><li><img src="/.io//memn2n-memory-module.png" alt="MemN2N-Memory-Module"></li></ul></li></ul></li></ul><h2 id="Approach-Details"><a href="#Approach-Details" class="headerlink" title="Approach Details"></a>Approach Details</h2><ul><li>模型的输入输出：<ul><li>输入：inputs $x_1,…,x_n$ (会被存储到memory中，$x_i$是一个句子) 和 query $q$，词典大小为 $|V|$</li><li>输出：answer $a$</li></ul></li></ul><h3 id="Single-Layer"><a href="#Single-Layer" class="headerlink" title="Single Layer"></a>Single Layer</h3><ol><li>input memory representation，将输入映射到特征/memory空间<ul><li>将 $x_i$ 通过 input embedding $A \in \mathbb{R}^{d\times |V|}$ 映射为 memory vector $m_i$</li><li>将 $q$ 通过 question embedding $B \in \mathbb{R}^{d\times |V|}$ 映射为 internal state $u$</li></ul></li><li>计算每个 memory 和 query 之间的attention，得到匹配程度：<ul><li>$p_i = softmax(u^T m_i)$</li><li>有多少个 memory vector 就有多少个 $p$</li></ul></li><li>output memroy representation：<ul><li>再将 $x_i$ 通过 output embedding $C \in \mathbb{R}^{d\times |V|}$ 映射为相应的 output vector $c_i$</li><li>计算 response context vector $o$:<ul><li>$o = \sum_i p_i c_i$</li></ul></li></ul></li><li>generating final prediction:<ul><li>使用 $o$ 和 $u$ 一起预测答案标签（可以是一个词）</li><li>$\hat{a} = softmax(W(o+u))$</li></ul></li></ol><ul><li>模型中的主要训练参数为：$A$、$B$、$C$、$W$</li></ul><h3 id="Multiple-Layers"><a href="#Multiple-Layers" class="headerlink" title="Multiple Layers"></a>Multiple Layers</h3><p>多层的结构就是对memory进行多次寻址（addressing/attention），每次关注不同的memory，主要的几点不同是：</p><ul><li>第一层之后的每层/每个hop的 query vector 是前一层的 response context vector 和 query vector 的结合，可以用不同的结合方式计算：<ul><li>$u^{k+1} = u^k + o^k$</li></ul></li><li>每层之间的embedding矩阵$A^k$和$C^k$不是共享的，具体有两种 权重初始化方式，参考下面的weight typing。</li></ul><h4 id="Weight-Typing"><a href="#Weight-Typing" class="headerlink" title="Weight Typing"></a>Weight Typing</h4><p>每个embedding A 和 embedding C 都是与词典大小相等的词向量矩阵，在multiple layers的结构中引入这两个参数矩阵会带来很大的参数开销</p><ul><li>Adjacent方式<ul><li>使第$k+1$层的input embedding $A^{k+1}$ 等于 第$k$ 层的output embedding $C^{k}$：$A{k+1} = C^k$</li><li>还是增加其他的约束：<ul><li>(a) 用最后一层的output embedding $C^{K}$ 去对 answer prediction中的参数矩阵 $W$ 进行赋值：$W^T = C^K$</li><li>(b) 使 question embedding 等于 第一层的input embedding $A^1$：$B = A^1$</li></ul></li></ul></li><li>Layer-wise（RNN-like）方式<ul><li>不同的层之间使用相同的embedding参数，在层间加入一个线性映射 $H$ 来更新 $u$：$u^{k+1} = H u^k + o^k$</li><li>在这种方式下，整体模型可以看成一个传统的rnn，将rnn的输出分为 internal 和 external 两类，$u$ 是rnn的hidden state</li></ul></li></ul><h2 id="Related-Works"><a href="#Related-Works" class="headerlink" title="Related Works"></a>Related Works</h2><ul><li>Memory Networks</li><li>Ask Me Anything: Dynamic Memory Networks for Natural Language Processing</li></ul>]]></content>
      
      
      <categories>
          
          <category> Paper-Note </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> paper </tag>
            
            <tag> network </tag>
            
            <tag> memory </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ICLR2019 | Coarse-Grain Fine-Grain Coattention Network for Multi-Evidence Question Answering</title>
      <link href="/2019/04/11/paper-iclr2019-cfc/"/>
      <url>/2019/04/11/paper-iclr2019-cfc/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Coarse-Grain Fine-Grain Coattention Network for Multi-Evidence Question Answering<br>ICLR 2019<br>Victor Zhong, Caiming Xiong, Nitish Shirish Keskar, Richard Socher<br>University of Washington, Salesforce Research<br>Datasets: Qangaroo-WikiHop</p></blockquote><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><h2 id="Summary-amp-Analysis"><a href="#Summary-amp-Analysis" class="headerlink" title="Summary &amp; Analysis"></a>Summary &amp; Analysis</h2>]]></content>
      
      
      <categories>
          
          <category> Paper-Note </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> mrc </tag>
            
            <tag> paper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Analysis of Multi-Passage RC Task</title>
      <link href="/2019/04/11/mrc-analysis-multi-passage/"/>
      <url>/2019/04/11/mrc-analysis-multi-passage/</url>
      
        <content type="html"><![CDATA[<p>Works of multi-passage MRC task<br>Target Datasets: MS MARCO, Dureader</p><p>Reference papers on this track:</p><blockquote><ol start="0"><li>Multi-Passage Machine Reading Comprehension with Cross-Passage Answer Verification. ACL,2018.</li><li>A Multi-answer Multi-task Framework for Real-world Machine Reading Comprehension. EMNLP,2018.</li><li>A Deep Cascade Model for Multi-Document Reading Comprehension. AAAI,2019.</li><li>Multi-Mention Learning for Reading Comprehension with Neural Cascades. ICLR,2018.</li><li>Coarse-Grain Fine-Grain Coattention Network for Multi-Evidence Question Answering. ICLR,2019.</li><li>Multi-style Generative Reading Comprehension. 2019.</li></ol></blockquote><p>TO BE Updated</p>]]></content>
      
      
      <categories>
          
          <category> MRC-Paper-Intro </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> mrc </tag>
            
            <tag> paper </tag>
            
            <tag> research </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Analysis of Multi-Choice RC Task</title>
      <link href="/2019/03/28/mrc-analysis-multichoice/"/>
      <url>/2019/03/28/mrc-analysis-multichoice/</url>
      
        <content type="html"><![CDATA[<ul><li>focus on the strategy of <strong>matching processing</strong> between <code>(P, Q, Ans)</code></li><li>target datasets: <strong>RACE, MCScripts</strong></li></ul><p>Reference papers on multi-choice MRC task, especially toward matching processing.</p><blockquote><ol start="0"><li>Hierarchical Attention Flow for Multiple-Choice Reading Comprehension. AAAI,2018.</li><li>Dynamic Fusion Networks for Machine Reading Comprehension. 2017.</li><li><strong>A Co-Matching Model for Multi-choice Reading Comprehension</strong>. ACL,2018.</li><li><strong>Dual Co-Matching Network for Multi-choice Reading Comprehension</strong>. 2019.</li><li>Convolutional Spatial Attention Model for Reading Comprehension with Multiple-Choice Questions. AAAI,2019.</li><li><strong>Option Comparison Network for Multiple-choice Reading Comprehension</strong>. 2019</li><li>Yuanfudao at SemEval-2018 Task 11: Three-way Attention and Relational Knowledge for Commonsense Machine Comprehension. 2018.</li><li>HFL-RC System at SemEval-2018 Task 11: Hybrid Multi-Aspects Model for Commonsense Reading Comprehension. 2018.</li></ol></blockquote><h2 id="Co-Match-Network-HCM"><a href="#Co-Match-Network-HCM" class="headerlink" title="Co-Match Network (HCM)"></a>Co-Match Network (HCM)</h2><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul><li><p>previous works: 之前的MRC的工作通常是基于句对的序列匹配（Pair-Wise Sequence Matching)，有如下情况：</p><ul><li>passage 与 question 和 candidate answer 的串联进行比较；</li><li>passage 先与 question 进行比较，计算出 matching 结果，再使结果与 candidate answer 进行比较；</li></ul></li><li><p>这样的计算方式不适用于多选型RC任务，具体存在以下几点问题：</p><ul><li>1、仅将 passage 和 question 进行匹配，得到的结果可能没有意义并且会导致原始 passage 的信息丢失；<ul><li>例如：问题 Which statement of the following is true？</li></ul></li><li>若将 question 和 candidate answer 串联成为一个序列，损失了 question 和 candidate answer 的交互信息；</li></ul></li><li><p>基于此，多选RC任务需要解决<strong>匹配序列三元组 (matching sequence triplets)</strong>的问题；</p></li><li><p>本文的方法：</p><ul><li>match a question-answer pair to a given passage；<ul><li>explicitly treat the question and the candidate answer as two sequences and jointly match them to the given passage；</li></ul></li><li>对P中的每个位置，都计算两个attention权重，构成两个匹配表示，形成一个co-match状态（同时计算P和Q/A的匹配），然后再用一个层次LSTM框架（2个LSTM）对passage进行编码；<ul><li>层次汇聚信息：<ul><li>在passage中的每个句子内部，信息从word-level汇聚在sentence-level</li><li>在passage中的句子序列维度上，再从sentence-level汇聚到document-level；</li></ul></li><li>可以更好的处理，问题需要的信息分散在passage中不同句子，的情况</li></ul></li></ul></li></ul><h3 id="Model-Details"><a href="#Model-Details" class="headerlink" title="Model Details"></a>Model Details</h3><p>Notation:<br>&nbsp;&nbsp;&nbsp;&nbsp;(one sentence in) Passage: $P\in \mathbb{R}^{d\times P}$<br>&nbsp;&nbsp;&nbsp;&nbsp;Question: $Q \in \mathbb{R}^{d\times Q}$<br>&nbsp;&nbsp;&nbsp;&nbsp;(one candidate answer in) Answer: $A \in \mathbb{R}^{d\times A}$</p><ul><li><p>architecture</p><ul><li><img src="/.io//co-match.png" alt="co-match"></li></ul></li><li><p>co-matching</p><ul><li>encoding: the same BiLSTM<ul><li>$H^p\in \mathbb{R}^{l\times P}$, 每个句子分别计算</li><li>$H^q\in \mathbb{R}^{l\times Q}$,</li><li>$H^a\in \mathbb{R}^{l\times A}$, 每个候选分别计算</li></ul></li><li>attention:<ul><li>$G^q = softmax( (W^gH^q + b^g \otimes e_Q)^T H^p ) \in \mathbb{R}^{Q\times P}$</li><li>$G^a = softmax( (W^gH^a + b^g \otimes e_Q)^T H^p ) \in \mathbb{R}^{A\times P}$</li></ul></li><li>aggregation: attentive passage representation<ul><li>$\bar{H}^q = H^q G^q \in \mathbb{R}^{l \times P}$</li><li>$\bar{H}^a = H^q G^a \in \mathbb{R}^{l \times P}$</li></ul></li><li>co-match passage state: concurrently matches a passage state with both the question and the candidate answer. It represent how each P state can be matched with the Q and Candidate A.<ul><li>$M^q = ReLU(W^m[\bar{H}^q \ominus H^p; \bar{H}^q \otimes H^p]) + b^m \in \mathbb{R}^{l\times P}$</li><li>$M^a = ReLU(W^m[\bar{H}^a \ominus H^p; \bar{H}^a \otimes H^p]) + b^m \in \mathbb{R}^{l\times P}$</li><li>$W^m \in \mathbb{R}^{l\times 2l}$</li><li>$C = [M^q; M^a] \in \mathbb{R}^{2l \times P}$</li></ul></li></ul></li><li><p>hierarchical aggregation</p><ul><li>for each triplet ${P_n, Q, A}, n\in [1,N]$, get $C_n$ through co-match</li><li>sentence-level aggregation of the co-matching states:<ul><li>sentence sequence representation merge into a single vector</li><li>$h_n^s = MaxPooling(BiLSTM(C_n)) \in \mathbb{R}^l$</li><li>$MaxPooling$： row-wise max pooling</li></ul></li><li>final triplet matching representation:<ul><li>$H^s=[h_1^s, h_2^s,…,h_N^s]$</li><li>$h^t = MaxPooling (BiLSTM (H^s)) \in \mathbb{R}^{l}$</li></ul></li></ul></li><li><p>Output Layer</p><ul><li>for each candidate answer $A_i$, get $h_i^t \in \mathbb{R}^{l} $</li><li>$L(A_i|P,Q) = -log \frac{exp(w^Th_i^t)}{\sum_{j=1}^4 exp(w^T h_j^t)}$</li></ul></li></ul><h3 id="Model-Parameters"><a href="#Model-Parameters" class="headerlink" title="Model Parameters"></a>Model Parameters</h3><ul><li>word emb dim: 300</li><li>rnn hidden dim: 150</li><li>optimizer: Adamax, lr=0.002</li><li>batch：10</li><li>epochs：30</li><li>dropout：0.2</li></ul><h2 id="Dual-Co-Matching-Network"><a href="#Dual-Co-Matching-Network" class="headerlink" title="Dual Co-Matching Network"></a>Dual Co-Matching Network</h2><h3 id="Motivation-1"><a href="#Motivation-1" class="headerlink" title="Motivation"></a>Motivation</h3><ul><li>previous work: <ul><li>只计算了question-aware P表示和 option-aware P表示；</li><li>一些pretrainLM的做法是将P和Q串联成为一个句子，A单独作为另一个句子；</li></ul></li><li>本文：<ul><li>model the relationship among passage，question and answer <strong>bidirectionally</strong></li><li>在计算question-aware P表示和 option-aware P表示的同时，计算passage-aware Q表示和passage-aware O表示</li></ul></li></ul><h3 id="Model-Details-1"><a href="#Model-Details-1" class="headerlink" title="Model Details"></a>Model Details</h3><ul><li>Encoding<ul><li>$H^p = Bert(P) \in \mathbb{R}^{P\times l}$</li><li>$H^q = Bert(Q) \in \mathbb{R}^{Q\times l}$</li><li>$H^a = Bert(A) \in \mathbb{R}^{A\times l}$</li><li>$l$: Bert hidden state dimension</li></ul></li><li>Matching Layer<ul><li>attention between P and A:<ul><li>$W = softmax(H^p(H^a G+b)^T) \in \mathbb{R}^{P\times A}$<ul><li>$G \in \mathbb{R}^{l\times l}$</li></ul></li><li>$M^p = WH^a \in \mathbb{R}^{P\times l}$</li><li>$M^a = W^TH^p \in \mathbb{R}^{A\times l}$<ul><li>$W \in \mathbb{R}^{P\times A}$</li></ul></li></ul></li><li>attention  between P and Q in the same method, get:<ul><li>$M^q \in\mathbb{R}^{Q\times l}$</li><li>$W^\prime \in \mathbb{R}^{P\times Q}$</li><li><font color="blue">问题：为什么P和Q进行attention，不计算question-aware的passage表示？</font></li></ul></li><li>integration original contextual representation<ul><li>$S^a = F([M^a - H^a;M^a \cdot H^a]W_1 + b_1) \in \mathbb{R}^{P \times l}$</li><li>$S^p = F([M^p - H^p;M^p \cdot H^p]W_2 + b_2)\in \mathbb{R}^{A \times l}$</li><li>$F()$ is activation function $ReLU$</li><li>in the question side:<ul><li>$S^{p^\prime} \in \mathbb{R}^{P\times l}$</li><li>$S^q \in \mathbb{R}^{Q\times l}$</li></ul></li></ul></li></ul></li><li>Aggregation Layer<ul><li>get final representation for each candidate answer<ul><li>row-wise max pooling</li><li>$C^p = Pooling(S^p) \in \mathbb{R}^{l}$</li><li>$C^a = Pooling(S^a) \in \mathbb{R}^{l}$</li><li>$C^{p^\prime} = Pooling(S^{p^\prime}) \in \mathbb{R}^{l}$</li><li>$C^q = Pooling(S^q) \in \mathbb{R}^{l}$</li><li>$C = [C^p;C^a;C^{p^\prime};C^q]$</li></ul></li></ul></li><li>Output Layer<ul><li>$L(A_i|P,Q)=-log\frac{exp(V^TC_i)}{\sum_{j=1}^N exp(V^TC_j)}$</li></ul></li></ul><h3 id="Model-Parameters-1"><a href="#Model-Parameters-1" class="headerlink" title="Model Parameters"></a>Model Parameters</h3><p> No description</p><h2 id="Option-Comparison-Network-OCN"><a href="#Option-Comparison-Network-OCN" class="headerlink" title="Option Comparison Network (OCN)"></a>Option Comparison Network (OCN)</h2><h3 id="Motivation-2"><a href="#Motivation-2" class="headerlink" title="Motivation"></a>Motivation</h3><ul><li>previous work:<ul><li>read each option independently.</li><li>compute a fixed-length representation for each option before comparing them.</li></ul></li><li>ideas:<ul><li>humans typically compare the options at multiple-granularity level before reading the article in detail and make reasoning more efficient.</li><li>人解决多选RC任务的策略，通常在仔细阅读文章之前会在不同粒度上比较候选答案。</li><li>通过比较候选答案，可以定位答案选项间的相互关系，在读文章时只关注与选项相互关系有关的文章信息。（更高效？more efﬁciently and effectively）</li></ul></li><li>本文：<ul><li>explicitly compare options at word-level to better identify their correlations to help reasoning</li><li><ol><li>首先使用一个skimmer network对每个option进行独立编码；</li></ol></li><li><ol start="2"><li>然后对每个option，将其与其他的options使用attention进行word-level的比较，来建立option之间的相互比较；</li></ol></li><li><ol start="3"><li>最后，带着聚集之后的option间的相关性，重读文章，进行推理和答案选择</li></ol></li></ul></li><li>Analysis:<ul><li>这篇文章的主要更新的是option的表示</li></ul></li></ul><h3 id="Model-Details-2"><a href="#Model-Details-2" class="headerlink" title="Model Details"></a>Model Details</h3><p>Notation:<br>&nbsp;&nbsp;&nbsp;&nbsp;Passage: $P={w_1^p,…,w_m^p}$&nbsp;&nbsp;&nbsp;&nbsp;Question: $Q= {w_1^q,…,w_n^q}$&nbsp;&nbsp;&nbsp;&nbsp;Answer set: $O={O_1,…,O_K}$&nbsp;&nbsp;&nbsp;&nbsp;Each option: $O_k = {w_1^o,…,w_{n_k}^o}$</p><ul><li><p>Overall: 4 stages</p><ol><li>concatenate each (article, question, option) triple into a sequence and use a skimmer to encode them into vector sequences.</li><li>attention-based mechanism is leveraged to compare the options.</li><li>the article is reread with the correlation information gathered in last stage as extra input.</li><li>compute the probabilities for each option.</li></ol></li><li><p>Option Feature Extraction</p><ul><li>skimmer encoding: 将每个option与P和Q串联构成一个句子，使用BERT进行编码<ul><li>$[P^{enc};Q^{enc};O^{enc}_k] = BERT(&lt;P;Q;O_k&gt;)$<ul><li>$P^{enc} \in \mathbb{R}^{d\times m}$</li><li>$Q^{enc} \in \mathbb{R}^{d\times n}$</li><li>$O^{enc}_k \in \mathbb{R}^{d\times n_k}$</li></ul></li></ul></li><li>由于Q和option的关联紧密，将两者串联，作为option的特征<ul><li>$O_k^q=[Q^{enc}|O^{enc}_k] \in \mathbb{R}^{d\times n_k^\prime}$<ul><li>$n_k^\prime = n+n_k$</li></ul></li></ul></li></ul></li><li><p>Option Correlation Features Extraction</p><ul><li>$Att(\cdot)$的计算方式：假设输入为$U\in \mathbb{R}^{d\times N}$和 $V\in \mathbb{R}^{d\times M}$<ul><li>$v \in \mathbb{R}^{3d}$ 是参数</li><li>$s_{ij}=v^T[U_{:i};V_{:j};U_{:i}\circ V_{:j}]$</li><li>$A= Att(U,V;v)=[\frac{exp(s_{ij})}{\sum_i exp(s_{ij})}]_{ij} \in \mathbb{R}^{N\times M}$</li></ul></li><li>option correlation feature extraction 分3步进行<ul><li><ol><li>option $O_k$ 与其他options进行one-by-one比较，收集 pair-wise correlation信息<ul><li>$\bar{O}_k^{(l)}=O^q_l Att(O^q_l,O_k^q;v_o)$</li><li>$\tilde{O}_k^{(l)}=[O_k^q-\bar{O}_k^{(l)};O_k^q \circ \bar{O}_k^{(l)}] \in \mathbb{R}^{2d\times n_k^\prime}$</li></ul></li></ol></li><li><ol start="2"><li>gather pair-wise correlation information<ul><li>$\tilde{O}<em>k^c=tanh(W_c [O_k^q;{\tilde{O}_k^{(l)}}</em>{l\neq k} ])$<ul><li>$W_c \in \mathbb{R}^{d\times (d+2d(|O|-1))}$</li></ul></li></ul></li></ol></li><li><ol start="3"><li>element-wise gating 机制控制option feature和option-wise correlation information的融合，以产生option correlation features $O_k^c$<ul><li>$g_k \in \mathbb{R}^{d\times n_k^\prime}$<ul><li>$g_{k,:i}=\sigma (W_g [Q_{K,:i}^q; \tilde{O}_{k,:i}^c; \tilde{O}]+b_g)$</li><li>$g_{k,:i}$ 表示 g 向量的第i列</li></ul></li><li>$\tilde{O}$ 的计算：关于 Q 的attention pooling<ul><li>$A_q = softmax(v_a^T Q^{enc})^T, v_a \in \mathbb{R}^d$</li><li>$\tilde{O}=Q^{enc}A^q \in \mathbb{R}^{d}$</li></ul></li><li>option correlation features: $O_k^c\in \mathbb{R}^{d\times n_k^\prime}$<ul><li>$O_{k,:i}^c = g_{k,:i} \circ O_{k,:i}^q + (1-g_{k,:i}) \circ \tilde{O}_{k,:i}^c$</li><li>Note: $O_k^c$ 不被压缩成fixed-length向量，文中的解释为-这样可以使我们的模型更灵活的使用correlation信息。</li></ul></li></ul></li></ol></li></ul></li></ul></li><li><p>Article ReReading</p><ul><li>co-attention + self-attention</li><li>对于每个option $O_k$ 计算 co-attention:<ul><li>$A_k^c = Att(O_k^c,P^{enc};v_p) \in \mathbb{R}^{n_k^\prime \times m}$</li><li>$A_k^p = Att(P^{enc},O_k^c;v_p) \in \mathbb{R}^{m\times n_k^\prime}$</li><li>$\hat{O}_k^p = [P^{enc};O_k^c A_k^c]A_k^p \in \mathbb{R}^{2d\times n_k^\prime}$</li></ul></li><li>fused with correlation information<ul><li>$\tilde{O}_k^p = ReLU(W_p[O_k^c;\hat{O}_k^p]+b_p) \in \mathbb{R}^{d\times n_k^\prime}$</li></ul></li><li>self-attention to get full-info option representation $O_k^f\in \mathbb{R}^{d\times n_k^\prime}$<ul><li>$\tilde{O}_k^s = \tilde{O}_k^p Att(\tilde{O}_k^p, \tilde{O}_k^p;v_r)$</li><li>$\tilde{O}_k^f = [\tilde{O}_k^p;\tilde{O}_k^s;\tilde{O}_k^p-\tilde{O}_k^s;\tilde{O}_k^p \circ \tilde{O}_k^s]$</li><li>$O_k^f = ReLU(W_f\tilde{O}_k^f +b_f)$</li></ul></li></ul></li><li><p>Answer prediciton</p><ul><li>score $s_k = v_s^T MaxPooling(O_k^f)$<ul><li>MaxPooling: row-wise</li><li>$v_s \in \mathbb{R}^d$</li></ul></li><li>probability：<ul><li>$P(K|Q,P,O)=\frac{exp(s_k)}{\sum_i exp(s_i)}$</li></ul></li><li>loss:<ul><li>$J(\theta)=-\frac{1}{N}\sum_i log(P(\hat{k}_i | Q_i,P_i,O_i)) + \lambda||\theta||_2^2$</li></ul></li></ul></li></ul><h3 id="Model-Parameters-2"><a href="#Model-Parameters-2" class="headerlink" title="Model Parameters"></a>Model Parameters</h3><ul><li>for BERT base:<ul><li>batch:12</li><li>epochs:3</li><li>lr: $3\times 10^{-5}$ </li></ul></li><li>for BERT large:<ul><li>batch:24</li><li>epochs:5</li><li>lr: $1.5\times 10^{-5}$ </li></ul></li><li>$\lambda$: 0.01</li><li>lengths:<ul><li>P: 400</li><li>Q: 30</li><li>A: 16</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> MRC-Paper-Intro </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> mrc </tag>
            
            <tag> paper </tag>
            
            <tag> research </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Practicable Course List (continually updated)</title>
      <link href="/2019/03/12/course-list/"/>
      <url>/2019/03/12/course-list/</url>
      
        <content type="html"><![CDATA[<p>The main areas of concern are:</p><blockquote><p><a href="#NLP">Natural Language Processing</a><br><a href="#MLandDL">Machine Learning and Deep Learning</a><br><a href="#RL">Reinforcement Learning</a><br><a href="#MathBasic">Foundation of Mathematics</a></p></blockquote><h2 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h2><ul><li>Stanford，CS224n<ul><li><a href="http://web.stanford.edu/class/cs224n/index.html" target="_blank" rel="noopener">http://web.stanford.edu/class/cs224n/index.html</a></li><li>video：<a href="https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z" target="_blank" rel="noopener">Winter 2019</a></li></ul></li><li>CMU，CS 11-731<ul><li>Machine Translation and Seq-to-Seq Models，2018</li><li><a href="http://www.phontron.com/class/mtandseq2seq2018/" target="_blank" rel="noopener">http://www.phontron.com/class/mtandseq2seq2018/</a></li></ul></li><li>CMU，CS 11-747<ul><li>Neural Networks for NLP，Spring 2018</li><li><a href="http://www.phontron.com/class/nn4nlp2018/schedule.html" target="_blank" rel="noopener">http://www.phontron.com/class/nn4nlp2018/schedule.html</a></li><li>video：<a href="https://www.youtube.com/playlist?list=PL8PYTP1V4I8Ajj7sY6sdtmjgkt7eo2VMs" target="_blank" rel="noopener">2019</a></li></ul></li><li>Oxford<ul><li><a href="https://github.com/oxford-cs-deepnlp-2017/lectures" target="_blank" rel="noopener">https://github.com/oxford-cs-deepnlp-2017/lectures</a></li></ul></li><li>Berkeley<ul><li>Applied Natural Language Processing</li><li><a href="http://people.ischool.berkeley.edu/~dbamman/info256.html" target="_blank" rel="noopener">http://people.ischool.berkeley.edu/~dbamman/info256.html</a></li></ul></li><li>Penn，CIS 700<ul><li>Advanced Machine Learning for Natural Language Processing，Dan Roth</li><li><a href="http://www.cis.upenn.edu/~danroth/Teaching/CIS-700-006/index.html" target="_blank" rel="noopener">http://www.cis.upenn.edu/~danroth/Teaching/CIS-700-006/index.html</a></li></ul></li><li>CS 4650 and 7650<ul><li><a href="https://github.com/jacobeisenstein/gt-nlp-class" target="_blank" rel="noopener">https://github.com/jacobeisenstein/gt-nlp-class</a></li></ul></li><li>University of Washington<ul><li>CSE 447/547M: Natural Language Processing</li><li><a href="https://courses.cs.washington.edu/courses/cse447/19wi/" target="_blank" rel="noopener">https://courses.cs.washington.edu/courses/cse447/19wi/</a></li></ul></li></ul><h2 id="MLandDL"><a href="#MLandDL" class="headerlink" title="MLandDL"></a>MLandDL</h2><ul><li>Stanford，CS229<ul><li><a href="http://cs229.stanford.edu/index.html#info" target="_blank" rel="noopener">http://cs229.stanford.edu/index.html#info</a></li></ul></li><li>李宏毅<ul><li><a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses.html" target="_blank" rel="noopener">http://speech.ee.ntu.edu.tw/~tlkagk/courses.html</a></li></ul></li><li>Berkeley，STAT 157<ul><li>Introduction to Deep Learning</li><li><a href="http://courses.d2l.ai/berkeley-stat-157/index.html" target="_blank" rel="noopener">http://courses.d2l.ai/berkeley-stat-157/index.html</a></li></ul></li><li>Berkeley，2019，无监督学习<ul><li>CS294-158 Deep Unsupervised Learning Spring 2019</li><li><a href="https://sites.google.com/view/berkeley-cs294-158-sp19/home" target="_blank" rel="noopener">https://sites.google.com/view/berkeley-cs294-158-sp19/home</a></li></ul></li><li>Stanford，CS 236: Deep Generative Models<ul><li><a href="https://deepgenerativemodels.github.io/" target="_blank" rel="noopener">https://deepgenerativemodels.github.io/</a></li></ul></li><li>MIT，6.883<ul><li>Science of Deep Learning：Bridging Theory and Practice</li><li><a href="https://people.csail.mit.edu/madry/6.883/" target="_blank" rel="noopener">https://people.csail.mit.edu/madry/6.883/</a></li></ul></li><li>Maching Learning Summer School<ul><li><a href="http://mlss.cc/" target="_blank" rel="noopener">http://mlss.cc/</a></li></ul></li></ul><h2 id="RL"><a href="#RL" class="headerlink" title="RL"></a>RL</h2><ul><li>UCL，David Sliver<ul><li><a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" target="_blank" rel="noopener">http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html</a></li></ul></li><li>Berkeley S294-112<ul><li>Deep Reinforcement Learning</li><li><a href="http://rail.eecs.berkeley.edu/deeprlcourse/" target="_blank" rel="noopener">http://rail.eecs.berkeley.edu/deeprlcourse/</a></li></ul></li><li>Stanford<ul><li>CS234: Reinforcement Learning Winter 2019</li><li><a href="http://web.stanford.edu/class/cs234/" target="_blank" rel="noopener">http://web.stanford.edu/class/cs234/</a></li></ul></li><li>Berkeley CS188<ul><li>Introduction to Artificial Intelligence</li><li><a href="https://inst.eecs.berkeley.edu/~cs188/sp19/" target="_blank" rel="noopener">https://inst.eecs.berkeley.edu/~cs188/sp19/</a></li></ul></li></ul><h2 id="MathBasic"><a href="#MathBasic" class="headerlink" title="MathBasic"></a>MathBasic</h2><ul><li>Stanford，CS229T/STATS231<ul><li>Statistical Learning Theory</li><li><a href="https://web.stanford.edu/class/cs229t/" target="_blank" rel="noopener">https://web.stanford.edu/class/cs229t/</a></li></ul></li><li>CMU，10-708，Probabilistic Graphical Models<ul><li>Eric Xing， Spring 2014</li><li><a href="http://www.cs.cmu.edu/~epxing/Class/10708/lecture.html" target="_blank" rel="noopener">http://www.cs.cmu.edu/~epxing/Class/10708/lecture.html</a></li></ul></li><li>NYU，MathsDL-spring18<ul><li>Topics course Mathematics of Deep Learning, NYU, Spring 18. CSCI-GA 3033.</li><li><a href="https://github.com/joanbruna/MathsDL-spring18" target="_blank" rel="noopener">https://github.com/joanbruna/MathsDL-spring18</a></li></ul></li></ul><h2 id="Recommend-Archive-Links"><a href="#Recommend-Archive-Links" class="headerlink" title="Recommend Archive Links"></a>Recommend Archive Links</h2><ul><li><a href="https://deep-learning-drizzle.github.io/index.html#contents" target="_blank" rel="noopener">https://deep-learning-drizzle.github.io/index.html#contents</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> ForStudy </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> study </tag>
            
            <tag> resource </tag>
            
            <tag> course </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Knowledge-based MRC Papers</title>
      <link href="/2019/03/10/mrc-knowedge-paper-info/"/>
      <url>/2019/03/10/mrc-knowedge-paper-info/</url>
      
        <content type="html"><![CDATA[<p>A list of recent papers with respect to Knowledge-based Machine Reading Comprehension.</p><a id="more"></a><style>    table th:nth-of-type(2){    width: 60%;    }</style><h2 id="Works-on-Knowledge-aware-MRC"><a href="#Works-on-Knowledge-aware-MRC" class="headerlink" title="Works on Knowledge-aware MRC"></a>Works on Knowledge-aware MRC</h2><!-- aware/based/enhanced --><table><thead><tr><th align="center">Conf.</th><th align="left">Title</th><th align="left">Authors/Org.</th><th align="center">Note</th></tr></thead><tbody><tr><td align="center">ACL<br>2017</td><td align="left"><a href="https://doi.org/10.18653/v1/P17-1132" target="_blank" rel="noopener">Leveraging knowledge bases in lstms for improving machine reading</a></td><td align="left">Yang, et al.<br>CMU</td><td align="center"></td></tr><tr><td align="center">ACL<br>2017</td><td align="left">Reasoning with Heterogeneous Knowledge for Commonsense Machine Comprehension</td><td align="left">Hongyu Lin, et al.</td><td align="center"></td></tr><tr><td align="center">ACL<br>2017</td><td align="left"><a href="http://www.aclweb.org/anthology/D17-1086" target="_blank" rel="noopener">World knowledge for reading comprehension: Rare entity prediction with hierarchical lstms using external descriptions</a></td><td align="left">Long, et al.<br>McGill University</td><td align="center"></td></tr><tr><td align="center">ACL<br>2018</td><td align="left"><a href="http://aclweb.org/anthology/P18-1076" target="_blank" rel="noopener">Knowledgeable Reader: Enhancing Cloze-Style Reading Comprehension with External Commonsense Knowledge</a></td><td align="left">Mihaylov, et al.<br>Heidelberg University</td><td align="center"><a href="/2019/01/09/paper-knreader/" title="knreader-note">knreader-note</a></td></tr><tr><td align="center">2018</td><td align="left">Dynamic Integration of Background Knowledge in Neural NLU Systems</td><td align="left">Dirk Weissenborn, et al.</td><td align="center"><a href="/2019/03/06/paper-2018-refinewordemb/" title="note">note</a></td></tr><tr><td align="center">EMNLP<br>2018</td><td align="left"><a href="http://aclweb.org/anthology/D18-1454" target="_blank" rel="noopener">Commonsense for Generative Multi-Hop Question Answering Tasks</a></td><td align="left">Lisa Bauer</td><td align="center"><a href="/2019/02/21/paper-emnlp2018-mhpgm/" title="mhpgm-note">mhpgm-note</a></td></tr></tbody></table><h2 id="MRC-with-Knowledge"><a href="#MRC-with-Knowledge" class="headerlink" title="MRC with Knowledge"></a>MRC with Knowledge</h2><ul><li>how to let the machine obtain Knowledge？</li><li>how to represent knowledge？ in which kind of format？</li><li>how to let the machine to learn Knowledge incrementally？</li><li>how to make the machine can automatically use Knowledge it already knows or it has been told？</li></ul>]]></content>
      
      
      <categories>
          
          <category> MRC-Paper-Intro </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> mrc </tag>
            
            <tag> paper </tag>
            
            <tag> knowledge </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2018 | Dynamic Integration of Background Knowledge in Neural NLU Systems</title>
      <link href="/2019/03/06/paper-2018-refinewordemb/"/>
      <url>/2019/03/06/paper-2018-refinewordemb/</url>
      
        <content type="html"><![CDATA[<blockquote><p><em>Dynamic Integration of Background Knowledge in Neural NLU Systems</em><br><em>ICLR,2018. Reject</em><br><em>Dirk Weissenborn, et.al.</em><br><em>Datasets: SQuAD, TriviaQA, SNLI, MNLI</em></p></blockquote><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><ul><li>the requisite background knowledge is indirectly acquired from static corpora.</li><li>background knowledge learned from task supervision and also by pre-training word embeddings.</li><li>从静态的训练数据中获取背景知识有两点缺陷:<ul><li>1/不是所有的对解决NLU任务重要的背景知识都可以从有限量的训练数据中抽取出来；</li><li>2/随着时间的变化，对于理解文本有帮助的事实也会发生变化；</li></ul></li></ul><p>This work:（不同于仅依赖于从训练数据中获取静态知识）</p><ul><li>develop a new reading architecture for the <strong>dynamic integration</strong> of <strong>explicit background knowledge</strong> in NLU models.</li><li>a new <strong>task-agnostic(任务无关)</strong> reading module provides <strong>reﬁned word representations</strong> to a task-speciﬁc NLU architecture by processing background knowledge in the form of free-text statements, together with the task-speciﬁc inputs.</li></ul><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>输入是：待理解的文本，即context，和抽取出的相关知识的assertions.<br>然后，使用 word embedding refinement 的策略，增量式地读入context和assertions，最初使用上下文无关的词向量仅初始化.<br>这种 contextually refined word embedding <strong>可以看成是一种动态记忆，用来存储新结合的知识</strong>. </p><h3 id="External-Knowledge-as-Supplementary-Text-Inputs"><a href="#External-Knowledge-as-Supplementary-Text-Inputs" class="headerlink" title="External Knowledge as Supplementary Text Inputs"></a>External Knowledge as Supplementary Text Inputs</h3><ul><li>结合知识的形式：<ul><li>本文中并不限制外部信息的形式：无结构/结构化知识都可以作为补充信息</li></ul></li><li>结合何种知识：<ul><li>从知识源中抽取上下文相关的信息本身就是个复杂的研究，并且依赖于知识库的形式</li><li>全面抽取所有潜在的assertions，然后依赖于我们的阅读结构来学习抽取相关的信息</li><li>Assertion Retrieval<ul><li>抽取知识是为了获得句子之间的关联</li><li>抽取出连接头/尾实体在text中，尾/头实体在question中的知识</li><li>由于抽取出的assertion过多，使用排序分数对assertions进行打分（类似于tf-idf的打分方式，针对的是罕见但是重要的知识，选择top-k个）</li></ul></li></ul></li></ul><h3 id="Refine-Word-Embeddings-by-Reading"><a href="#Refine-Word-Embeddings-by-Reading" class="headerlink" title="Refine Word Embeddings by Reading"></a>Refine Word Embeddings by Reading</h3><p>将词向量看做一种记忆，不仅包含通用的知识，还包含上下文信息和抽取的知识信息.</p><p>本文提出的增量式 refinement 过程编码输入文本，然后使用多个阅读步得到的编码输入来更新词向量矩阵.<br>过程如图：</p><ul><li><img src="/.io//fig-1.png" alt="refinement"></li></ul><p>Notations:</p><ul><li>$E^0$: 初始的词向量</li><li>$E^\ell$: 第$\ell$步更新的词向量</li><li>$X^\ell$: 第$\ell$步的上下文信息</li><li>$FC(z)=W z + b, W\in \mathbb{R}^{n \times m}, b\in \mathbb{R}^{n}, z\in \mathbb{R}^m$</li></ul><h4 id="1-Unrefined-Word-Embeddings"><a href="#1-Unrefined-Word-Embeddings" class="headerlink" title="1.Unrefined Word Embeddings"></a>1.Unrefined Word Embeddings</h4><p>这一步的目标是根据预训练词向量$e_w^p \in \mathbb{R}^{n^\prime}$得到初始的non-contextual词表示，计算如下：</p><ul><li>$e_w^{p^\prime} = ReLU(FC(e_w^p))$</li><li>$g_w = \sigma(FC([e_w^{p^\prime} ; e_w^{char}]))$</li><li>$e_w^0 = g_w \cdot e_w^{p^\prime} + (1-g_w) \cdot e_w^{char}$<br>其中，$e_w^{char}$是通过cnn编码（n convolutional ﬁlters w of width 5 followed by a max-pooling operation over time.）得到</li></ul><h4 id="2-Contextually-Refined-Word-Representation"><a href="#2-Contextually-Refined-Word-Representation" class="headerlink" title="2.Contextually Refined Word Representation"></a>2.Contextually Refined Word Representation</h4><p>在编码输入文本时，</p><ul><li>给每个词concatenate一个长度为L(即进行refienment处理的次数)的one-hot向量表示对应的位($\ell$)置1，</li><li>得到输入文本$X_i^{\ell} \in \mathbb{R}^{d\times |x_i^l|}$</li><li>经过lstm进行context编码: $\hat{X}_i^{\ell} = ReLU(FC(BiLSTM(X_i^{\ell})))$</li><li>在任务中：$X^1$相当于是Passage(Premise)文本的表示，$X^2$相当于是Question(Hypothesis)的表示，额外的知识assertions是$X^3$<ul><li>在实验中，p\q的顺序对最终的结果没有显著的影响</li></ul></li></ul><p>更新词向量：</p><ul><li>首先对所有在文本中与此词的lemma相同的词进行一个maxpool: <ul><li>$\hat{e}_w^{\ell} = max{\hat{x}_k^{\ell} | x^{\ell} \in X^{\ell}, lemma(x_k^{\ell}) = lemma(w) }$</li></ul></li><li>然后，用context-independent的表示去计算一个context-sensitive的表示<ul><li>通过门控机制，是模型决定利用多少新读入的信息来改写词向量</li><li>$u_w^{\ell} = \sigma(FC( [e_w^{\ell -1}; \hat{e}_w^{\ell}] ))$</li><li>$e_w^{\ell} = u_w^{\ell} \cdot e_w^{\ell -1} + (1- u_w^{\ell})\cdot \hat{e}_w^{\ell}$</li></ul></li><li>关于pooling操作：在具有相同lemma的词上面进行pooling操作<ul><li>有效的联系可以缓解长距离依赖问题</li><li>更充分的利用输入作为相关背景知识</li></ul></li></ul><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>这篇文章的实验是在NLI（SNLI）和DQA（SQuAD）的任务上进行。</p><p>对NLI任务上：</p><ul><li>使用全部的数据进行训练时的提升不是很大</li><li>但是使用部分数据进行训练时的提升相对较多</li></ul>]]></content>
      
      
      <categories>
          
          <category> Paper-Note </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> mrc </tag>
            
            <tag> paper </tag>
            
            <tag> knowledge </tag>
            
            <tag> nli </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ACL2018 | Multi-Granularity Hierarchical Attention Fusion Networks for Reading Comprehension and Question Answering</title>
      <link href="/2019/03/03/paper-acl2018-slqa/"/>
      <url>/2019/03/03/paper-acl2018-slqa/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Multi-Granularity Hierarchical Attention Fusion Networks for Reading Comprehension and Question Answering<br>ACL 2018<br>Wei Wang, Ming Yan, Chen Wu.<br>Alibaba Group.<br>Multi-Granularity; Hierarchical Attention Fusion; Architecture<br>Datasets: SQuAD; TriviaQA</p></blockquote><p>看到题目，首先就产生了三个关注点：</p><ul><li>multi-granularity, 代表哪些粒度？ (word level 和 sentence level)</li><li>hierarchical, 有哪些层次？（co-attention 和 self-attention）</li><li>fusion, 怎样进行融合？对粒度的融合（global level）</li></ul><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><ul><li>启发于人类通常的阅读模式：<ul><li>浏览全篇文章，大致了解文章内容（通读全文）</li><li>浏览问题，记住问题，找到P和Q之间的联系，理解Q的意图</li><li>定位一个大致/粗略的潜在的答案区域，使注意力聚集到定位的上下文（重点阅读上下文）</li><li>再次回顾问题，确定一个最优答案</li></ul></li></ul><h3 id="This-Work"><a href="#This-Work" class="headerlink" title="This Work"></a>This Work</h3><ul><li>建模问题和文章中特定区域关联的同时，借助分层策略逐步集中注意力，是答案边界清晰</li><li>提出 hierarchical attention network：<ul><li>逐步定位答案边界</li><li>建模P和Q之间的不同粒度层级间的关系</li></ul></li><li>在Encoder层：<ul><li>为了更好的建模Q和P的多个aspects：同时使用预训练的glove表示和ELMo表示作为一个词的表示</li><li>针对ELMo的融合，设计了一个 Representation-aware fusion 方法来结合ELMo输出向量和BiLSTM建模的上下文表示</li></ul></li><li>在本文提出的Hierarchical Attention Fusion Network中：<ul><li>利用co-attention和self-attention机制，逐步的将注意力聚集到最优的答案span<ul><li>co-attention with shallow semantic fusion</li><li>self-attention with deep semantic fusion </li><li>memory-wise bilinear alignment function</li></ul></li><li>特点：<ul><li>fine-grained fusion 结合attention vector 更好的建模P和Q的关系</li><li>multi-granularity attention 应用于 word-level 和 sentence-level</li></ul></li><li>与其他方法不同的是：<ul><li>利用全局表示（原始的上下文表示）构建attention表示</li><li>利用fusion layer来对attention表示进行进一步的微调</li></ul></li></ul></li></ul><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><ul><li>本文提出模型 SLQA+ (Semantic Learning for Question Answering) 的整体架构：<ul><li>encoder、attention、matching、output</li><li><img src="/.io//slqa-model.png" alt="slqa+模型图"></li></ul></li></ul><h3 id="1-Encoder-Layer"><a href="#1-Encoder-Layer" class="headerlink" title="1.Encoder Layer"></a>1.Encoder Layer</h3><ul><li>输入是 P和Q的每个词的glove向量和ELMo向量：<ul><li>问题：${e_t^Q}<em>{t=1}^m$，${c_t^Q}</em>{t=1}^m$</li><li>文章：${e_t^P}<em>{t=1}^n$，${c_t^P}</em>{t=1}^n$</li></ul></li><li>输出：original context representation<ul><li>BiLSTM 的输出结果，再次和ELMo 串联concat</li><li>问题：Q = $u_t^Q = [BiLSTM_Q(e_t^Q, c_t^Q), c_t^Q]$</li><li>文章：P = $u_t^P = [BiLSTM_P(e_t^P, c_t^P), c_t^P]$</li></ul></li></ul><h3 id="2-Hierarchical-Attention-Fusion-Layer"><a href="#2-Hierarchical-Attention-Fusion-Layer" class="headerlink" title="2.Hierarchical Attention Fusion Layer"></a>2.Hierarchical Attention Fusion Layer</h3><ul><li>original context representation和通过attention得到的aligned representation可以反映上下文不同粒度的语义</li></ul><h4 id="2-1-Co-attention-amp-Fusion"><a href="#2-1-Co-attention-amp-Fusion" class="headerlink" title="2.1 Co-attention &amp; Fusion"></a>2.1 Co-attention &amp; Fusion</h4><ul><li>co-attention 过程：<ul><li>计算一个soft-alignment 矩阵：<ul><li>$$S_{ij} = Att(u_t^Q, u_t^P) = ReLU(W^T_{lin}u_t^Q)^T \cdot ReLU(W^T_{lin}u_t^P)$$</li></ul></li><li>计算 P2Q attention<ul><li>$$\alpha_{j} = softmax(S_{:j})$$</li><li>$$\tilde{Q}<em>{:t} = \sum_j \alpha</em>{ij} \cdot Q_{:j}, \forall j \in [1,…,m]$$</li></ul></li><li>计算 Q2P attention<ul><li>$$\beta_j = softmax(S_{i:})$$</li><li>$$\tilde{P}<em>{k:} = \sum_i \beta</em>{ik} \cdot P_{i:}, \forall i \in [1,..,n]$$</li></ul></li></ul></li><li><font color="red"><strong>Fusion</strong></font>：本文重点<ul><li>定义fusion kernel<ul><li>$P^\prime=Fuse(P,\tilde{Q})$</li><li>$Q^\prime=Fuse(Q,\tilde{P})$</li></ul></li><li>simple fusion 过程：<ul><li>$$m(P,\tilde{Q}) = tanh(W_f[P;\tilde{Q};P\circ\tilde{Q};P-\tilde{Q}] + b_f)$$</li></ul></li><li>输出：利用gate机制，融合/refine 注意力表示和original contextual 表示<ul><li>希望利用 original context representation 提供的重要的 global level 的语义信息提供指导，进一步引入gate机制控制不同层次表示的融合</li><li>文档：$P^\prime = g(P,\tilde{Q})\cdot m(P,\tilde{Q}) + (1-g(P, \tilde{Q})）\cdot P$</li><li>问题：$Q^\prime = g(Q,\tilde{P})\cdot m(Q,\tilde{P}) + (1-g(Q, \tilde{P})）\cdot Q$</li><li>$g(\cdot)$的定义见2.3</li></ul></li></ul></li></ul><h4 id="2-2-Self-attention-amp-Fusion"><a href="#2-2-Self-attention-amp-Fusion" class="headerlink" title="2.2 Self-attention &amp; Fusion"></a>2.2 Self-attention &amp; Fusion</h4><p>文档的self-attention fusion过程：</p><ul><li>首先将manual feature引入，与refined question-aware passage表示进行串接<ul><li>$D = BiLSTM([P^\prime; feat_{man}])$</li></ul></li><li>self-alignment <strong>fusion</strong> process<ul><li>$L = softmax(D \cdot W_1 \cdot D^T)$</li><li>$\tilde{D} = L \cdot D$</li><li>$D^\prime = Fuse(D,\tilde{D})$</li></ul></li><li>双向LSTM获得最终的上下文文档表示：<ul><li>$D^{\prime\prime} = BiLSTM(D^\prime)$</li></ul></li></ul><p>问题端的self-attention fusion过程</p><ul><li>获得新的问题上下文表示：$Q^{\prime\prime} = BiLSTM(Q^\prime)$<ul><li>$Q^\prime$ 来自于co-attention+fusion的结果</li></ul></li><li>linear self-alignment, 使用 linear transformation (linear sequence attention，同drqa中的问题编码)，将问题编码为向量<ul><li>$\gamma = softmax(w_q^T Q^{\prime\prime})$</li><li>$q = \sum_{j} \gamma_j \cdot Q^{\prime\prime}, \forall j \in [1,…,m]$</li></ul></li></ul><h4 id="2-3-Fusion-Functions"><a href="#2-3-Fusion-Functions" class="headerlink" title="2.3 Fusion Functions"></a>2.3 Fusion Functions</h4><ul><li>simple concat：简单讲两个channel的输入进行串联（计算m(·)时）</li><li>Full Projection：heuristic matching，形如<ul><li>$[P;\tilde{Q};P\circ\tilde{Q};P-\tilde{Q}]$</li></ul></li><li>Scalar-based fusion：训练一个标量参数<ul><li>$g(P,\tilde{Q}) = g_p$</li></ul></li><li><font color="green"><strong>Vector-based Fusion</strong></font>: 效果最好的<ul><li>$g(P,\tilde{Q}) = \sigma(w_g^T \cdot [P;\tilde{Q};P\circ\tilde{Q};P-\tilde{Q}] + b_g)$</li><li>$w_g$是待训练的权重向量</li></ul></li><li>Matrix-based Fusion：<ul><li>$g(P,\tilde{Q}) = \sigma(W_g^T \cdot [P;\tilde{Q};P\circ\tilde{Q};P-\tilde{Q}] + b_g)$</li><li>$W_g$是待训练的权重矩阵</li></ul></li></ul><h3 id="3-Output-Layer"><a href="#3-Output-Layer" class="headerlink" title="3.Output Layer"></a>3.Output Layer</h3><ul><li>bilinear match function<ul><li>$P_{start} = softmax(q \cdot W_s^T D^{\prime\prime})$</li><li>$P_{end} = softmax(q \cdot W_e^T D^{\prime\prime})$</li><li>可以看做是对问题的回顾</li></ul></li></ul><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h2 id="Summary-amp-Analysis"><a href="#Summary-amp-Analysis" class="headerlink" title="Summary &amp; Analysis"></a>Summary &amp; Analysis</h2><ul><li>ELMo 与上下文表示融合的新思路</li><li><strong>原始的context representation可以看做是global level的信息，在fusion中的作用很大</strong>(每一步的fusion都是将attention representation与original context representation进行融合)，利用original context representation对attention之后的表示进行融合，微调带有注意力的表示</li><li>计算attention时，采取 linear + relu 的bilinear的效果最优</li><li>输出层的 <font color="blue"><strong>bilinear match function</strong></font> 对结果的提升很大</li></ul>]]></content>
      
      
      <categories>
          
          <category> Paper-Note </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> mrc </tag>
            
            <tag> paper </tag>
            
            <tag> model </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>EMNLP2018 | Commonsense for Generative Multi-Hop Question Answering Tasks</title>
      <link href="/2019/02/21/paper-emnlp2018-mhpgm/"/>
      <url>/2019/02/21/paper-emnlp2018-mhpgm/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Commonsense for Generative Multi-Hop Question Answering Tasks<br>EMNLP 2018<br>Lisa Bauer et al. UNC.<br>Multi-Hop reasoning; generative-mrc; commmonsense knowledge<br>Datasets: NarrativeQA; QAngaroo-WikiHop<br>Source code: <a href="https://github.com/yicheng-w/CommonSenseMultiHopQA" target="_blank" rel="noopener">https://github.com/yicheng-w/CommonSenseMultiHopQA</a></p></blockquote><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><ul><li>Multi-Hop Generative Task (<em>e.g. NarrativeQA</em>) requires models to <strong>reasong, gather and synthesize disjoint pieces of information</strong> within the context to generate an answer.</li><li>This type of multi-step reasoning requires understanding <strong>implicit relations</strong> (<em>external, background commonsense knowledge</em>).</li><li>Related work:<ul><li>some <strong>fact-based</strong> datasets (e.g. SQuAD) do not need to place heavy emphasis on multi-step reasoning capabilities.</li><li>some multi-hop datasets (e.g. QAngaroo) prompt a strong focus on multi-hop reasoning in very long texts.<ul><li>QAngaroo is an extractive dataset where answers are guaranteed to be spans within the context, thus, it more focuse on <strong>fact finding</strong> and <strong>linking</strong>.</li></ul></li></ul></li><li>This work:<ul><li>a. a strong generative baseline, <strong>Multi-Hop Pointer-Generator Model</strong>, uses a <strong>multi-attention</strong> to perform multiple hops of reasoning and a pointer-generator decoder to synthesize the answer.</li><li>b. a novel system for <strong>selecting grounded multi-hop relational commonsense information</strong> from ConceptNet via a <strong>pointwise mutual information</strong> and <strong>term-frequency</strong> based scoring function.</li><li>c. a <strong>selectively gated attention</strong> mechanism to insert <strong>selected commonsense paths</strong> between the hops of document-context reasoning.</li><li>multi-hop commonsense paths: multiple connected edges within ConceptNet graph that give us information beyond a single relationship triple.</li><li>different aspects of the commonsense relationship path at each hop to bridge different inference gaps in the multi-hop task.</li></ul></li></ul><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><ul><li>Model Overview:<ul><li><img src="/.io//mhpgm-1-overview.png" alt="MHPGM"></li></ul></li></ul><h3 id="1-Multi-Hop-Pointer-Generator-Baseline"><a href="#1-Multi-Hop-Pointer-Generator-Baseline" class="headerlink" title="1.Multi-Hop Pointer-Generator Baseline"></a>1.Multi-Hop Pointer-Generator Baseline</h3><p>模型的输入:</p><ul><li>context: $X^C={w_1^C, w_2^C,…,w_n^C}$</li><li>query: $X^Q = {w_q^Q, w_2^Q,…,w_m^Q}$</li></ul><p>模型的输出:</p><ul><li>answer tokens: $X^a = {w_1^a,w_2^a,…,w_p^a}$</li></ul><h4 id="1-1-Embedding-Layer"><a href="#1-1-Embedding-Layer" class="headerlink" title="1.1.Embedding Layer"></a>1.1.Embedding Layer</h4><p>pretrained word embeddings with ELMO: $e_i^Q$/$e_i^C$ $\in \mathbb{R}^{d+1024}$</p><h4 id="1-2-Reasoning-Layer"><a href="#1-2-Reasoning-Layer" class="headerlink" title="1.2.Reasoning Layer"></a>1.2.Reasoning Layer</h4><p>$k$ 个 reasoning cell 增量式地更新 context representation.</p><p>第 $t$ 个reasoning cell的计算过程:</p><ul><li>输入: 前一时刻的输出 $\lbrace c_i^{t-1} \rbrace _{i=1}^n$ 和 query 的向量 $\lbrace e_i^Q \rbrace _{i=1}^m$</li><li>a.通过 cell-specific Bi-LSTM 计算一个 step-specific 的 context 和 query 的编码<ul><li>$u^t=BiLSTM(c^{t-1})$; $v_t=BiLSTM(e^Q)$</li></ul></li><li>b.通过bi-attention 计算 context 中的相关方面 来模拟一个hop的推理:<ul><li>context-to-query attention:<ul><li>$S_{ij}^t = W_1^t u_i^t + W_2^t v_j^t + W_3^t (u_i^t \odot v_j^t)$</li><li>$$p_{ij}^t = \frac{exp(S_{ij}^t)}{\sum_{k=1}^m exp(S_{ik}^t)}$$</li><li>$$(c_q)^t_i = \sum_{j=1}^m p_{ij}^t v_j^t \in \mathbb{R}^{n \times dim}$$</li></ul></li><li>query-to-context attention vector:<ul><li>$m_i^t = \max_{1 \leq j\leq m} S_{ij}^t$</li><li>$$p_i^t = \frac{exp(m_i^t)}{\sum_{j=1}^n exp(m_j^t)}$$</li><li>$$q_c^t = \sum_{i=1}^n p_i^t u_i^t \in \mathbb{R}^{dim}$$</li></ul></li><li>更新的context representation:<ul><li>$c_i^t = [u_i^t; (c_q)_i^t; u_i^t \odot (c_q)_i^t; q_c^t \odot (c_q)_i^t]$</li></ul></li><li>$c^0 = e^C$</li><li>最后一时刻的输出是 $c^k$</li></ul></li></ul><h4 id="1-3-Self-Attention-Layer"><a href="#1-3-Self-Attention-Layer" class="headerlink" title="1.3.Self-Attention Layer"></a>1.3.Self-Attention Layer</h4><ul><li>帮助模型处理long context中的长期依赖</li><li>输入是 reasoning 层最后一时刻的输出 经过 一个BiLSTM之后的表示 $c^{SA}$</li><li>计算流程：<ul><li>$S_{ij}^{SA} = W_4 c_i^{SA} + W_5 c_j^{SA} + W_6(c_i^{SA}\odot c_j^{SA})$<!-- * $$p_{ij}^{SA} = \frac{exp(S_{ij}^{SA})}{\sum_{k=1}^n exp(S_{ij}^{SA})}$$ --></li><li>$p_{ij}^{SA} = exp(S_{ij}^{SA}) / \left( \sum_{k=1}^n exp(S_{ij}^{SA}) \right)$</li><li>$c^\prime = \sum_{j=1}^n p_{ij}^{SA} c_j^{SA}$</li><li>$c^{\prime\prime} = BiLSTM([c^\prime;c^{SA};c^\prime \odot c^{SA}])$</li><li>$c = c^k + c^{\prime\prime}$</li></ul></li></ul><h4 id="1-4-Pointer-Generator-Decoding-Layer"><a href="#1-4-Pointer-Generator-Decoding-Layer" class="headerlink" title="1.4.Pointer-Generator Decoding Layer"></a>1.4.Pointer-Generator Decoding Layer</h4><ul><li><p>输入: </p><ul><li>$x_t$, 前一时刻解码出的词向量表示</li><li>$s_{t-1}$, 前一时刻的隐藏层状态</li><li>$a_{t-1}$, 上下文向量</li></ul></li><li><p>计算:</p><ul><li>当前时刻的隐藏层状态:<ul><li>$s_t = LSTM([x_t; a_{t-1}], s_{t-1})$</li></ul></li><li>计算在生成词典上的概率分布:<ul><li>$P_{gen} = softmax(W_{gen}s_t + b_{gen})$</li></ul></li><li>计算 attention (使用 Bahdanau 的attention计算过程):<ul><li>$$\alpha_i = v^\intercal tanh(W_c c_i + W_s s_t + b_{attn})$$</li><li>$$\hat{\alpha}<em>i = \frac{exp(\alpha_i)}{\sum</em>{j=1}^n exp(\alpha_j)}$$</li><li>$$ \mathbf{a}<em>i = \sum</em>{i=1}^n \hat{\alpha}_i c_i $$</li></ul></li><li>计算选择生成还是复制的概率:<ul><li>$\mathbf{o} = \sigma(W_a \mathbf{a}<em>t + W_x x</em>{t} + W_s s_t + b_{ptr})$</li><li>$\mathbf{p}^{sel} = softmax(\mathbf{o}) \in \mathbb{R}^2$</li></ul></li><li>最终 $t$ 时刻输出的分布为:<ul><li>$$ P_t(w) = p_1^{sel} P_{gen}(w) + p_2^{sel} \sum_{i:w_i^C=w} \hat{\alpha}_i$$</li></ul></li></ul></li></ul><h3 id="2-Commonsense-Selection-and-Representation"><a href="#2-Commonsense-Selection-and-Representation" class="headerlink" title="2.Commonsense Selection and Representation"></a>2.Commonsense Selection and Representation</h3><p>为什么需要常识知识：知识关系有时候没有直接在文本中指出</p><p>由于语义网络/知识图谱的规模较大，包含很多无关信息，需要设计有效的选择算法来确定需要的信息 (有用的知识且可以在context-query对中落地(<em>grounded</em>:在context-query中出现) )</p><ul><li><p>常识知识选择策略：包含两方面</p><ul><li>1.通过<strong>树结构</strong>，收集潜在的相关知识，目的是选择出具有high recall的候选推理路径；</li><li>2.通过<strong>三步</strong>打分策略对候选路径进行排序和过滤，以确保加入信息的质量和多样性；<ul><li>Initial Node Scoring, Cumulative Node Scoring, Path Selection</li></ul></li></ul></li><li><p>图: Commonsense selection approach</p><ul><li><img src="/.io//mhpgm-2-path.png" alt="Commonsense selection approach"></li></ul></li></ul><h4 id="2-1-Tree-Construction"><a href="#2-1-Tree-Construction" class="headerlink" title="2.1.Tree Construction"></a>2.1.Tree Construction</h4><p>树的根节点为query中的一个词, 通过一些分支操作来构建多步推理路径.针对问题中的一个词/concept $c_1$, 进行如下操作:</p><ol><li>Direct Interaction:方向交互<ul><li>从ConceptNet中选择与$c_1$和文本上下文中concept( $c_2 \in C$ )有直接链接的关系$r_1$(多个)</li><li>例如图中的第一列</li></ul></li><li>Multi-Hop<ul><li>继续在ConceptNet中选择文本中另外的concept($c_3 \in C$)与$c_2$有链接的关系$r_2$</li></ul></li><li>Outside Knowledge<ul><li>无文本上下文的约束,寻找收集外部知识</li><li>在ConceptNet中通过关系$r_3$寻找$c_3$的邻居(one-hop)得到 $c_4 \in nbh(c_3)$</li></ul></li><li>Context-Grounding<ul><li>再次利用context进行约束, 来确保3中额外的知识是对任务有帮助的</li><li>即, 使$c_3$通过$c_4$可找到的二阶邻居$c_5 \in C$是在文本中出现的</li></ul></li></ol><ul><li>这构建路径的过程中，有几点疑问:<ul><li>a. 如果针对一个query中的concept无法查找到这么长的路径如何处理？</li></ul></li></ul><h4 id="2-2-Rank-and-Filter"><a href="#2-2-Rank-and-Filter" class="headerlink" title="2.2.Rank and Filter"></a>2.2.Rank and Filter</h4><p>在构建树的过程中, 会收集大量的潜在相关路径, 相应地会引入很多噪声以及与问题无关的路径, 所以需要对2.1中收集到的知识路径进行排序过滤掉噪音.</p><ol><li>Initial Node Scoring:<ul><li>初始化节点分数</li><li>选择有节点可以提供对context的理解的重要信息的路径</li><li>使用 tf 来估计context中concept的重要度和显著度:<ul><li>$score(c) = \frac{count(c)}{|C|}, c \in \lbrace c_2,c_3,c_5 \rbrace$</li></ul></li><li>对于outside Knowledge选择出来的节点$c_4$, 希望它与推理路径中的$c_1$到$c_3$保持<strong>逻辑一致性</strong><ul><li>利用点互信息</li><li>$$PMI(c_4,c_{1-3}) = log(\frac{\mathbb{P}(c_4,c_{1-3})}{\mathbb{P}(c_4) \mathbb{P}(c_{1-3})})$$</li><li>$$\mathbb{P}(c_4,c_{1-3}) = \frac{Num.\ of\ paths\ connecting\ c_1,c_2,c_3,c_4}{Num.\ of\ distinct\ paths\ of\ length\ 4}$$</li><li>$$\mathbb{P}(c_4) = \frac{Num.\ of\ nodes\ that\ can\ reach\ c_4}{|ConceptNet|}$$</li><li>$$\mathbb{P}(c_{1-3}) = \frac{Num.\ of\ paths\ connecting\ c_1,c_2,c_3}{Num.\ of\ paths\ of\ length\ 3}$$</li><li>由于PMI对low-frequency敏感, 改进为 normalized PMI<ul><li>$score(c_4) = PMI(c_4, c_{1-3}) / (-log\mathbb{P}(c_4,c_{1-3}))$</li></ul></li></ul></li><li>由于每个连接分支代表了one-hop，所以不同层级的hops或者是拥有不同父节点的nodes无法与其他节点相比较, 最终对每个节点的打分进行归一化:<ul><li>在同级(siblings)节点中进行归一化</li><li>$n-socre(c) = softmax_{siblings(c)}(score(c))$</li></ul></li></ul></li><li>Cumulative Node Scoring<ul><li>累积节点打分</li><li>选择多跳的Commonsense路径中有相关信息的,根据节点以其子节点的相关性和显著性对节点进行再次打分</li><li>采取bottom-up的累积计算方式</li><li>对于叶子节点(leaf node):<ul><li>$c-socre = n-score$</li></ul></li><li>对于非叶子节点<ul><li>$c-score(c_l) = n-socre(c_l) + f(c_l)$</li><li>$f(c_l)$是该节点的$c-socre$打分top-2的子节点的$c-score$平均分值</li></ul></li></ul></li><li>Path Selection<ul><li>路径选择</li><li>采取top-down breath-first(广度优先)的方式选择路径</li><li>从根节点(回顾: query中的一个concept)开始, 递归的选择其两个具有最高累计得分的子节点, 直到选择到叶子节点.</li><li>选择路径数: $2^4=16 paths$</li><li>路径直接以token序列的方式传给模型</li></ul></li></ol><h3 id="3-Commonsense-Model-Incorporation"><a href="#3-Commonsense-Model-Incorporation" class="headerlink" title="3.Commonsense Model Incorporation"></a>3.Commonsense Model Incorporation</h3><p>有选择性的结合需要的知识，使用常识知识来弥补推理步之间的gaps.<br>提出 Necessary and Optional Information Cell (NOIC) 一种 selectively gated 注意力机制。</p><ul><li><p>输入:以词序列的形式表示给定的 list of commonsense logic paths:</p><ul><li>$X^{CS} = {w_1^{CS}, w_2^{CS},…,w_l^{CS}}$</li><li>$w_l^{CS}$表示构成一条路径的token序列</li><li>使用词向量表示: $e_{ij}^{CS}\in \mathbb{R}^d$</li></ul></li><li><p>NOIC 是基于 Baseline Reasoning Cell 的扩展:</p><ul><li>在第 $t$ 个推理步, 得到 baseline reasoning cell 的输出之后, 为Commonsense信息计算cell-specific表示:<ul><li>将Commonsense paths上的所有向量串接, 每条路径得到一个表示向量$u_i^{CS}$</li><li>通过映射进行降维, 使维度与 $c_i^t$ 的维度相等<ul><li>$v_i^{CS} = ReLU(W u_i^{CS} + b)$</li></ul></li><li>利用attention机制使Commonsense与context之间进行交互:<ul><li>$$S_i^{CS}=W_1^{CS}c_i^t + W_2^{CS} v_j^{CS} + W_3^{CS} (c_i^t \odot v_j^{CS})$$</li><li>$$p_{ij}^{CS} = \frac{exp(S_{ij}^{CS})}{\sum_{k=1}^l exp(S_{ij}^{CS})}$$</li><li>$$c_i^{CS} = \sum_{j=1}^l p_{ij}^{CS} v_j^{CS}$$</li></ul></li><li>最后, 将Commonsense-aware的context表示和baseline reasoning cell的结果进行组合得到NOIC的输出<ul><li>$$z_i = \sigma(W_z [c_i^{CS}; c_i^t] + b_z)$$</li><li>$$(c_o)_i^t = z_i \odot c_i^t + (1-z_i) \odot c_i^{CS}$$</li></ul></li></ul></li><li>通过这种方式做到在每一个推理步对知识进行有选择的结合</li></ul></li></ul><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><h3 id="Ablations"><a href="#Ablations" class="headerlink" title="Ablations"></a>Ablations</h3><ol><li>Model Ablations</li><li>Commonsense Ablations</li><li>Commonsense Selection</li></ol><h2 id="Summary-amp-Analysis"><a href="#Summary-amp-Analysis" class="headerlink" title="Summary &amp; Analysis"></a>Summary &amp; Analysis</h2><p>TBA</p>]]></content>
      
      
      <categories>
          
          <category> Paper-Note </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> mrc </tag>
            
            <tag> paper </tag>
            
            <tag> multi-hop </tag>
            
            <tag> reasoning </tag>
            
            <tag> commonsense </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Commonsense to Controllable TG</title>
      <link href="/2019/01/23/paper-tg-with-commonsense/"/>
      <url>/2019/01/23/paper-tg-with-commonsense/</url>
      
        <content type="html"><![CDATA[<p>本文将介绍 两篇 关于利用常识知识进行可控地文本生成的论文，都是清华大学黄民烈老师组的研究工作：</p><blockquote><p>Commonsense Knowledge Aware Conversation Generation with Graph Attention. IJCAI,2018.<br>Story Ending Generation with Incremental Encoding and Commonsense Knowledge. AAAI,2019.</p></blockquote><p>相比于文本生成问题，我更关注怎样将常识知识引入到文本的理解，即编码过程。</p><h2 id="1-CS-Know-to-Dialogue-with-GAT"><a href="#1-CS-Know-to-Dialogue-with-GAT" class="headerlink" title="1.CS Know. to Dialogue with GAT"></a>1.CS Know. to Dialogue with GAT</h2><p>这篇文章的主要目的是利用大规模的常识知识帮助对话的理解与生产。<br>在对话任务中，给定一个用户 post：</p><ul><li>在编码端：采取静态策略<ul><li>从(常识)知识库中抽取出与 post 相关的知识子图</li><li>在编码端知识子图是静态的，包含与 post 相关的信息</li><li>用 Graph Attention(GAT) 机制进行编码</li></ul></li><li>在解码端：采取动态策略<ul><li>有关注的读取 Knowledge Graph 以及 Knowledge Graph 中的知识三元组</li></ul></li><li>文章中强调了一点：与已有的其他模型(分开、独立使用 knowledge triples/entities)不同，此模型将每个 knowledge graph 作为一个整体进行处理，可以编码更多的结构信息以及有关联的语义信息。</li></ul><p>模型的整体结构: <img src="/.io//tg-ccm-architecture.png" alt="CCM-overview"></p><h3 id="Task-Definition-and-Overview"><a href="#Task-Definition-and-Overview" class="headerlink" title="Task Definition and Overview"></a>Task Definition and Overview</h3><ul><li>user post(input): $X=x_1 x_2 … x_n$</li><li>some commonsense knowledge graphs: $G={g_1, g_2, …, g_{N_G}}$</li><li>desired response(output): $Y=y_1 y_2 … y_m$</li><li>使用 post 中的每个词作为查询，去常识知识库中 为每个词抽取出一个对应的子图:<ul><li>eg: 对于 post $X=x_1 x_2 … x_n$, 其对应的抽取出来的图是 $G={g_1, g_2,…,g_{N_G}}$</li><li>每个子图由一个三元组集合构成: $g_i = {\tau_1, \tau_2, …, \tau_{N_{g_i}}}$</li><li>每个三元组(head entity, relation, tail entity): $\tau = (h,r,t)$</li><li>使用 TransE 来表示 KG 中的实体和关系;</li><li>最终每个三元组 $\tau$ 表示为: <ul><li>$k = (h,r,t) = MLP(TransE(h,r,t))$<ul><li>$h/r/t$ 为各自的 TransE Embedding</li><li>使用 $MLP$ 是为了缩小 知识库 和 无结构对话文本 之间的 表示差距(bridge the representation gap)</li></ul></li></ul></li><li>对于在知识库中没有检索到匹配的词，使用一个特殊的 <code>Not_A_Fact</code> 来表示</li></ul></li></ul><h3 id="Knowledge-Interpreter"><a href="#Knowledge-Interpreter" class="headerlink" title="Knowledge Interpreter"></a>Knowledge Interpreter</h3><p>Knowledge Interpreter overview: <img src="/.io//tg-ccm-enc-1.png" alt="KI-overview"></p><ul><li>知识感知的词表示: $e(x_t) = [w(x_t);g_i]$</li><li>Knowledge Interpreter 的主要目的是用每个词对应的知识子图向量来增强词表示<ul><li>使用 post 中的每个词 $w_t$ 作为 key entity (红色点)去抽取出一个子图 $g_i$ (上图中黄色的部分)</li><li>knowledge interpreter 的输出为静态图注意力机制计算得到的 graph vector $g_i$</li></ul></li><li>Static Graph Attention<ul><li>使用功能 GAT 的好处是：不仅可以编码结构语义信息还可以考虑到图中节点间的关系</li><li>SGA 的输入: knowledge triple vectors<ul><li>$$K(g_i) = {k_1, k_2, …, k_{N_{g_i}}}$$</li></ul></li><li>SGA 的输出: knowledge graph vector<ul><li>$$g_i = \sum_{n=1}^{N_{g_i}} \alpha_n^s [h_n;h_t]$$</li><li>$$\alpha_n^s = \frac{exp(\beta_n^s)}{\sum_{j=1}^{N_{g_i}} exp(\beta_j^s)}$$</li><li>$$\beta_n^s = (W_r r_n)^T tanh(W_h h_n + W_t t_n)$$</li><li>其中, $(h_n, r_n, t_n) = k_n$</li><li>(Note: 在原始的GAT中没有引入relation向量计算attention的score)</li></ul></li></ul></li></ul><h2 id="2-CS-Know-to-Story-Ending-Generation"><a href="#2-CS-Know-to-Story-Ending-Generation" class="headerlink" title="2.CS Know. to Story Ending Generation"></a>2.CS Know. to Story Ending Generation</h2><p>这篇文章的主要目的是生成连贯、合理且有逻辑的故事结尾。</p><ul><li>故事例子：故事与知识的关联<ul><li><img src="/.io//story-data-example.png" alt="story-data-example"></li></ul></li></ul><p>动机：</p><ul><li>为故事生成一个合理的结尾需要对故事有很强的理解，需要以下两个方面</li><li>Context Clues：故事的逻辑、因果关系以及时序依赖（logic/causality/chronological order）通常跨越多个句子，通过句子中的事件/实体序列来获取；</li><li>Implicit/Commonsense Knowledge：超越文本表明信息的隐含知识</li></ul><p>针对以上的需求/目的，本文提出了：</p><ul><li>Incremental Encoding Schema：表示文本线索<ul><li>逐句编码</li></ul></li><li>Multi-Source Attention：帮助故事理解，充分利用常识知识<ul><li>为每个词抽取一个 one-hop Knowledge graph，计算graph的表示</li><li>在编码当前句子时，不仅对前一个句子中的每个词的上下文表示进行Attention，还对每个词的KG进行Attention</li></ul></li></ul><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>模型的整体结构: <img src="/.io//story-architecture.png" alt="storygen-model"></p><h3 id="Incremental-Encoding-Scheme"><a href="#Incremental-Encoding-Scheme" class="headerlink" title="Incremental Encoding Scheme"></a>Incremental Encoding Scheme</h3><p>最直接的对故事进行上下文编码的方法有：</p><ul><li>将所有的句子进行串联，构成一个长句子，然后用LSTM进行计算</li><li>使用带有 Hierarchical-Attention 的层次LSTM</li><li>但是这两种都不能够有效的表示上下文的线索信息，相邻句子中事件/实体的时序顺序(chronological order)和因果关系(causal relationship)</li></ul><p>本文提出的增量编码模式：编码当前句子 $X_i$ 中的第j个位置的隐状态计算如下</p><ul><li>$h_j^{(i)} = LSTM(h_{j-1}^{(i)}, e(x_j^{(i)}), c_{lj}^{(i)}), i&gt;2$<ul><li>其中，$e(\cdot)是词向量$， $c_{lj}^{(i)}$ 是关于前一个句子的上下文向量（基于隐状态$h_{j-1}^{(i)}$）</li></ul></li></ul><h3 id="Multi-Source-Attention"><a href="#Multi-Source-Attention" class="headerlink" title="Multi-Source Attention"></a>Multi-Source Attention</h3><p>通过多源Attention来获取上下文向量表示文本线索信息，由两部分组成：</p><ul><li>$c_{lj}^{(i)} = W_l( [c_{hj}^{(i)} ; c_{xj}^{(i)}] ) + b_l$</li><li>$c_{hj}^{(i)}$ 是 state context vector，即前一个句子隐状态的权重和<ul><li>$$c_{hj}^{(i)}  = \sum_{k=1}^{l_{i-1}} \alpha_{hk}^{(i)} h_k^{(i-1)}$$</li><li>$$\alpha_{hk}^{(i)} = \frac{ exp( \beta_{h_{k,j}}^{(i)} ) }{ \sum_{m=1}^{l_{i-1}} exp( \beta_{h_{m,j}}^{(i)} ) }$$</li><li>$$\beta_{h_{k,j}}^{(i)} = h_{j-1}^{(i)} W_s h_k^{(i-1)}$$</li><li>$h_k^{(i-1)}$ 前一个句子第k时刻的隐状态</li></ul></li><li>$c_{xj}^{(i)}$ 是 knowledge context vector， 即前一个句子的知识表示权重和<ul><li>$$c_{xj}^{(i)}  = \sum_{k=1}^{l_{i-1}} \alpha_{xk}^{(i)} g(x_k^{(i-1)})$$</li><li>$$\alpha_{xk}^{(i)} = \frac{ exp( \beta_{x_{k,j}}^{(i)} ) }{ \sum_{m=1}^{l_{i-1}} exp( \beta_{x_{m,j}}^{(i)} ) }$$</li><li>$$\beta_{x_{k,j}}^{(i)} = h_{j-1}^{(i)} W_k g(x_k^{(i-1)})$$</li><li>$g(x_k^{(i-1)})$ 是前一个句子中第k个词的graph vector</li><li>$h_{j-1}^{(i)}$ 是第i个句子中的第j个位置的隐状态，即当前句子中的前一时刻的隐状态</li></ul></li></ul><h3 id="Knowledge-Graph-Representation"><a href="#Knowledge-Graph-Representation" class="headerlink" title="Knowledge Graph Representation"></a>Knowledge Graph Representation</h3><p>对知识图编码有两种方式：</p><ul><li>graph attention</li><li>contextual attention (knowledgeable-reader)</li></ul><p>针对词$x$抽取（以$x$为头实体）出的图: $G(x) = {R_1,R_2, …,R_{N_x}}$</p><p>$R_i$ 为知识三元组 $(h,r,t)$， 用词向量表示h/t， r向量作为参数进行学习；<br>$N_x$ 为 $x$ 的邻居数量；</p><h4 id="Graph-Attention-的图表示方式"><a href="#Graph-Attention-的图表示方式" class="headerlink" title="Graph Attention 的图表示方式"></a>Graph Attention 的图表示方式</h4><ul><li>$$g(x) = \sum_{i=1}^{N_x} \alpha_{R_i} [h_i；t_i]$$</li><li>$$\alpha_{R_i} = \frac{ exp(\beta_{R_i}) }{ \sum_{j}^{N_x} exp(\beta_{R_j})}$$</li><li>$$\beta_{R_i} = (W_r r_i)^T tanh( W_h h_i + W_t t_i )$$</li></ul><h4 id="Contextual-Attention-的图表示方式"><a href="#Contextual-Attention-的图表示方式" class="headerlink" title="Contextual Attention 的图表示方式"></a>Contextual Attention 的图表示方式</h4><ul><li>$$g(x) = \sum_{i=1}^{N_x} \alpha_{R_i} M_{R_i}$$</li><li>$$M_{R_i} = BiGRU(h_i, r_i, t_i)$$</li><li>$$\alpha_{R_i} = \frac{ exp(\beta_{R_i}) }{ \sum_{j}^{N_x} exp(\beta_{R_j})}$$</li><li>$$\beta_{R_i} =h_{(x)}^T W_c M_{R_i}$$</li><li>$h_{(x)}$ 是词$x$的隐状态</li></ul><h2 id="CS-Know-Process"><a href="#CS-Know-Process" class="headerlink" title="CS Know. Process"></a>CS Know. Process</h2><p>对于常识知识的抽取方式以及和数据的融合方式</p><ul><li>CCM中：<ul><li>实体和关系的向量通过transE进行学习，维度均为100</li><li>去除了由多个词构成的头/尾实体</li><li>最终的数据量：<ul><li>三元组：120850</li><li>实体数：21471</li><li>关系数：44</li></ul></li></ul></li><li>StoryEndGen中：<ul><li>只抽取出one-hop的三元组</li><li>为每个词抽取最多10个三元组;</li><li>头/尾实体为名词(noun)或动词(verb)</li><li>最终的数据量：<ul><li>关系数：45</li><li>三元组：16652</li></ul></li></ul></li><li>两篇论文都是直接给出了处理好的数据，并没有给出数据的预处理过程，github链接分别为：<ol><li><a href="https://github.com/tuxchow/ccm" target="_blank" rel="noopener">https://github.com/tuxchow/ccm</a></li><li><a href="https://github.com/JianGuanTHU/StoryEndGen" target="_blank" rel="noopener">https://github.com/JianGuanTHU/StoryEndGen</a></li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> Paper-Note </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> paper </tag>
            
            <tag> text-generation </tag>
            
            <tag> commonsense </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Survey about Works of MOSAIC</title>
      <link href="/2019/01/21/note-research-ai2-mosaic/"/>
      <url>/2019/01/21/note-research-ai2-mosaic/</url>
      
        <content type="html"><![CDATA[<p>MOSAIC 是 AI2 (ALLEN Institute for Artificial Intelligence) 研究院中进行机器常识智能研究的小组<a href="https://mosaic.allenai.org/" target="_blank" rel="noopener">^1</a>.</p><p>现有的研究项目：</p><h2 id="Commonsense-Knowledge-Graphs"><a href="#Commonsense-Knowledge-Graphs" class="headerlink" title="Commonsense Knowledge Graphs"></a>Commonsense Knowledge Graphs</h2><p>Exploring semi-structured representations of commonsense.<a href="https://mosaic.allenai.org/projects/commonsense-knowledge-graphs" target="_blank" rel="noopener">^2</a></p><ul><li>ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning. AAAI,2019.</li></ul><h2 id="Visual-Commonsense-Reasoning"><a href="#Visual-Commonsense-Reasoning" class="headerlink" title="Visual Commonsense Reasoning"></a>Visual Commonsense Reasoning</h2><p>视觉常识推理项目<a href="https://visualcommonsense.com/" target="_blank" rel="noopener">^3</a></p><ul><li>From Recognition to Cognition: Visual Commonsense Reasoning</li></ul><h2 id="Mosaic-Commonsense-Benchmarks"><a href="#Mosaic-Commonsense-Benchmarks" class="headerlink" title="Mosaic Commonsense Benchmarks"></a>Mosaic Commonsense Benchmarks</h2><p>Measuring progress on Machine Common Sense.<a href="https://mosaic.allenai.org/projects/mosaic-commonsense-benchmarks" target="_blank" rel="noopener">^4</a></p><ul><li>SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference. EMNLP,2018.</li></ul><h2 id="Papers"><a href="#Papers" class="headerlink" title="Papers"></a>Papers</h2><ul><li>Event2Mind: Commonsense Inference on Events, Intents, and Reactions. ACL,2018.</li><li>Modeling Naive Psychology of Characters in Simple Commonsense Stories. ACL,2018.</li><li>Reasoning about Actions and State Changes by Injecting Commonsense Knowledge. EMNLP,2018.</li></ul>]]></content>
      
      
      <categories>
          
          <category> MRC-Research </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> mrc </tag>
            
            <tag> research </tag>
            
            <tag> note </tag>
            
            <tag> cs-know </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>20190121 | 清华大学AI研究院知识智能研究中心发布会的记录</title>
      <link href="/2019/01/21/note-20190121-thukc/"/>
      <url>/2019/01/21/note-20190121-thukc/</url>
      
        <content type="html"><![CDATA[<p>Minute and thoughts of the launch conference of THUKC (清华大学人工智能研究院知识智能研究中心).<br>Mainly about the part of Commonsense-Awared Natural Language Generation (常识知识感知的语言生成, 黄民烈)</p><h2 id="Commonsense-Extraction"><a href="#Commonsense-Extraction" class="headerlink" title="Commonsense Extraction"></a>Commonsense Extraction</h2><ul><li>what is Commonsense Knowledge (CS Know.)</li><li>what is the Boundary of commonsense</li><li>Commonsense Extraction<ul><li>From Embedding<ul><li>Extracting Commonsense Properties from Embeddings with Limited Human Guidance. 2018</li></ul></li><li>Commonsense Knowledge base completion<ul><li>Commonsense Knowledge base Completion. 2018</li></ul></li><li>From RAW data(text, image)<ul><li>Automatic Extraction of Commonsense LocatedNear Knowledge. 2018</li></ul></li></ul></li></ul><h2 id="Commonsense-Knowledge-in-RC"><a href="#Commonsense-Knowledge-in-RC" class="headerlink" title="Commonsense Knowledge in RC"></a>Commonsense Knowledge in RC</h2><ul><li>代表工作：Knowledgeable Reader</li></ul><h2 id="Commonsense-Knowledge-to-Intent-Reaction-Emotion-etc"><a href="#Commonsense-Knowledge-to-Intent-Reaction-Emotion-etc" class="headerlink" title="Commonsense Knowledge to Intent, Reaction, Emotion, etc"></a>Commonsense Knowledge to Intent, Reaction, Emotion, etc</h2><ul><li>代表工作：<ul><li>Event2Mind: Commonsense Inference on Events, Intents and Reaction</li><li>Modeling Naive Psychology of Characters in Simple Commonsense Stories</li></ul></li><li>AI2 实验室做了大量这方面的工作，相关调研：<a href="/2019/01/21/note-research-ai2-mosaic/" title="link">link</a></li></ul><h2 id="Commonsense-to-Controllable-TG"><a href="#Commonsense-to-Controllable-TG" class="headerlink" title="Commonsense to Controllable TG"></a>Commonsense to Controllable TG</h2><ul><li>黄民烈老师组的一些很好的工作（黄老师称这些工作是常识知识感知的语言生成的初步探索）：<ul><li>Commonsense Knowledge Aware Conversation Generation with Graph Attention. IJCAI,2018.(distinguished paper)<a href="https://juejin.im/post/5b6a9e085188251a8d37136d" target="_blank" rel="noopener">^1</a></li><li>Story Ending Generation with Incremental Encoding Commonsense Knowledge. AAAI,2019.</li><li>学习笔记：<a href="/2019/01/23/paper-tg-with-commonsense/" title="note_link">note_link</a></li></ul></li><li>Three Fundamental problems in current Neural Language Generation Models<ul><li>semantics(real understanding)</li><li>Consistency(long text generation)</li><li>Logic(reasonable and making sense)</li><li>在评价方面，关于如何评价生成的文本具有逻辑性还是个挑战（相关研究点：文本生成评价指标(BLEU、ROUGE等)的研究）</li></ul></li><li>New Architecture: <ul><li><strong>symbolic knowledge + planning + neural computing</strong></li></ul></li></ul><h2 id="发布的重要资源"><a href="#发布的重要资源" class="headerlink" title="发布的重要资源"></a>发布的重要资源</h2><p>知识智能研究中心：<a href="http://ai.tsinghua.edu.cn/kirc/#" target="_blank" rel="noopener">http://ai.tsinghua.edu.cn/kirc/#</a></p><ul><li>中英文跨语言百科知识图谱XLORE – <span id="inline-blue">世界知识</span><ul><li>特点：<ul><li>大规模跨语言百科知识图谱</li><li>通过融合维基百科和百度百科，并对百科知识进行结构化和跨语言链接构建而成。</li><li>以结构化形式描述客观世界中的概念、实例、属性及其丰富语义关系。</li><li>XLORE目前包含约247万概念、44.6万属性/关系、1628万实例和260万跨语言链接。</li></ul></li><li>项目地址：<a href="https://xlore.org/" target="_blank" rel="noopener">https://xlore.org/</a></li></ul></li><li>基于义原的开放语言知识库 OpenHowNet – <span id="inline-green">语言知识</span>、<span id="inline-orange">常识知识</span><ul><li>！HowNet 核心数据首次开源</li><li>项目地址：<a href="https://openhownet.thunlp.org/" target="_blank" rel="noopener">https://openhownet.thunlp.org/</a></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> MRC-Research </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> mrc </tag>
            
            <tag> research </tag>
            
            <tag> note </tag>
            
            <tag> report </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Natural Language Inference | Analysis and Paper List</title>
      <link href="/2019/01/16/nli-paper-info/"/>
      <url>/2019/01/16/nli-paper-info/</url>
      
        <content type="html"><![CDATA[<h2 id="NLI-Introduction"><a href="#NLI-Introduction" class="headerlink" title="NLI Introduction"></a>NLI Introduction</h2><h3 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h3><ul><li>词语匹配的多元性（同义词、一词多义）lexical gap、lexical variant；</li><li>短语匹配的结构性、多粒度计算语义；</li><li>文本匹配的层次性；</li><li>利用不相似部分的信息；</li><li>自然语言的基础现象：Variability of Semantic expression<ul><li>是语言歧义的对偶问题；</li><li>语义表达的多变性、语言结构的多样性；</li></ul></li></ul><h3 id="Approachs"><a href="#Approachs" class="headerlink" title="Approachs"></a>Approachs</h3><p>models on NLI(Natural Language Infernce), concluded as: <strong>sentence-encoding-based</strong> vs. <strong>interaction-based</strong></p><ul><li>基于encoding的基本框架：<ul><li>input encoding –&gt;concat vector –&gt;vector &amp; element-wise difference/product–&gt; prediction</li></ul></li><li>基于交互的基本框架：<ul><li>input encoding –&gt; inference(interaction) –&gt; composition –&gt; prediction</li></ul></li></ul><h3 id="Measure-of-Similarity"><a href="#Measure-of-Similarity" class="headerlink" title="Measure of Similarity"></a>Measure of Similarity</h3><h2 id="Models-of-Sentence-Encoding-Based"><a href="#Models-of-Sentence-Encoding-Based" class="headerlink" title="Models of Sentence Encoding Based"></a>Models of Sentence Encoding Based</h2><ul><li>BiLSTM-Max</li><li>NSE</li><li>Deep Gated Attn. BiLSTM</li><li>Residual Stacked Encoder</li><li>Reinforced Self-Attention Network</li><li>Distance-based Self-Attention Network</li><li>Hierarchical BiLSTM with Max Pooling</li><li>Dynamic Self-Attention Model</li></ul><h2 id="Models-of-Interaction-Based"><a href="#Models-of-Interaction-Based" class="headerlink" title="Models of Interaction Based"></a>Models of Interaction Based</h2><ul><li>Decomposable Attention</li><li>ESIM</li><li>KIM</li><li>Densely Interactive Inference Network (DIIN)</li><li>BIMPM</li><li>Multi-Way Attention</li><li>DR-BiLSTM</li><li>CAFE</li><li>Densely-Connected Recurrent and Co-Attentive Network</li><li>DMAN</li><li>SLRC</li><li>AFN</li></ul>]]></content>
      
      
      <categories>
          
          <category> NLI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> paper </tag>
            
            <tag> research </tag>
            
            <tag> nli </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WIP| Analysis of FEVER</title>
      <link href="/2019/01/15/mrc-analysis-fever/"/>
      <url>/2019/01/15/mrc-analysis-fever/</url>
      
        <content type="html"><![CDATA[<h2 id="FEVER-Introduction"><a href="#FEVER-Introduction" class="headerlink" title="FEVER Introduction"></a>FEVER Introduction</h2><ul><li>FEVER data: <a href="http://fever.ai/resources.html" target="_blank" rel="noopener">link</a><ul><li>包含 185,445 条断言(claims)</li></ul></li><li>FEVER shared Task(with NAACL 2018) info: <a href="http://fever.ai/task.html" target="_blank" rel="noopener">details here</a></li><li>FEVER official baseline code: <a href="https://github.com/sheffieldnlp/fever-naacl-2018" target="_blank" rel="noopener">github repo</a></li></ul><p>FEVER(Fact Extraction and VERification) 任务中，给定一个未经验证的断言(claim)，即一个句子，要求模型/系统从Wikipedia中找到对应的证据句(evidence)，来验证这个断言，是否可以被证实(<strong>SUPPORTED</strong>)、反驳(<strong>REFUTED</strong>)或是没有足够的信息判断(<strong>NOT ENOUGH INFO</strong>)。对于SUPPORTED和REFUTED的判断，需要给出证据句子。其中 16.82%的例子中，需要多个证据句子来进行判断，12.15%的情况下，证据句来源于多篇文档。</p><h3 id="Data-Statistics"><a href="#Data-Statistics" class="headerlink" title="Data Statistics"></a>Data Statistics</h3><table><thead><tr><th>split</th><th>SUPPORTED</th><th>REFUTED</th><th>NEI</th></tr></thead><tbody><tr><td>Train</td><td>80035</td><td>29775</td><td>35639</td></tr><tr><td>Dev</td><td>6666</td><td>6666</td><td>6666</td></tr><tr><td>Test</td><td>6666</td><td>6666</td><td>6666</td></tr></tbody></table><h3 id="Baseline-System"><a href="#Baseline-System" class="headerlink" title="Baseline System"></a>Baseline System</h3><p>baseline 系统是 pipelined 形式，由三部分组成: 1.document retrieval, 2.sentence-level evidence selection, 3.textual entailment.</p><p>其中文本蕴含识别(recognizing textual entailment)部分采用的是 谷歌的 Decomposable Attention 模型</p><h3 id="Score-Metrics"><a href="#Score-Metrics" class="headerlink" title="Score Metrics"></a>Score Metrics</h3><p>official scorer: <a href="https://github.com/sheffieldnlp/fever-scorer" target="_blank" rel="noopener">https://github.com/sheffieldnlp/fever-scorer</a></p><p>判断 claim 的类型(SUPPORTED/REFUTED/NOT ENOUGH INFO)是个三分类问题，对此使用 accuracy 来评价。<br>对于 SUPPORTED 和 REFUTED 的类别，还需要提供证据片段，对此使用 F1 来评价。</p><h2 id="FEVER-Shared-Task-Top-3-Systems-Solutions"><a href="#FEVER-Shared-Task-Top-3-Systems-Solutions" class="headerlink" title="FEVER Shared Task Top-3 Systems Solutions"></a>FEVER Shared Task Top-3 Systems Solutions</h2><blockquote><p>The Fact Extraction and VERification (FEVER) Shared Task</p></blockquote><h3 id="Top-1-UNC-NLP"><a href="#Top-1-UNC-NLP" class="headerlink" title="Top-1: UNC-NLP"></a>Top-1: UNC-NLP</h3><blockquote><p>Combining Fact Extraction and Verification with Neural Semantic Matching Networks<br>AAAI 2019</p></blockquote><h3 id="Top-2-UCL-Machine-Reading-Group"><a href="#Top-2-UCL-Machine-Reading-Group" class="headerlink" title="Top-2: UCL Machine Reading Group"></a>Top-2: UCL Machine Reading Group</h3><blockquote><p>UCL Machine Reading Group: Four Factor Framework For Fact Finding (HexaF)</p></blockquote><h3 id="Top-3-Athene-UKP-TU-Darmstadt"><a href="#Top-3-Athene-UKP-TU-Darmstadt" class="headerlink" title="Top-3: Athene UKP TU Darmstadt"></a>Top-3: Athene UKP TU Darmstadt</h3><blockquote><p>Multi-Sentence Textual Entailment for Claim Verification</p></blockquote><h3 id="Shared-Task-Overview"><a href="#Shared-Task-Overview" class="headerlink" title="Shared Task Overview"></a>Shared Task Overview</h3><h2 id="FEVER-Workshop-Notes"><a href="#FEVER-Workshop-Notes" class="headerlink" title="FEVER Workshop Notes"></a>FEVER Workshop Notes</h2><ul><li>FEVER workshop info: <a href="http://fever.ai/workshop.html" target="_blank" rel="noopener">details here</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> MRC-Paper-Intro </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> mrc </tag>
            
            <tag> paper </tag>
            
            <tag> research </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MRC 的评测与所需能力</title>
      <link href="/2019/01/14/mrc-measure-skills/"/>
      <url>/2019/01/14/mrc-measure-skills/</url>
      
        <content type="html"><![CDATA[<h2 id="Reading-Comprehension-Skills"><a href="#Reading-Comprehension-Skills" class="headerlink" title="Reading Comprehension Skills"></a>Reading Comprehension Skills</h2><blockquote><p>An Analysis of Prerequisite Skills for Reading Comprehension.<a href="https://aclweb.org/anthology/W16-6001" target="_blank" rel="noopener">^1</a><br>Prerequisite skills for reading comprehension: Multi-perspective analysis of mctest datasets and systems. AAAI,2017.<a href="http://www.aaai.org/Conferences/AAAI/2017/PreliminaryPapers/14-Sugawara-14614.pdf" target="_blank" rel="noopener">^2</a><br>Evaluation Metrics for Machine Reading Comprehension: Prerequisite Skills and Readability. ACL,2017.<a href="https://aclanthology.info/papers/P17-1075/p17-1075" target="_blank" rel="noopener">^3</a></p></blockquote><p>(从数据的角度)将阅读理解所需要的能力分为两类: <span id="inline-blue">认知能力(prerequisite skill)</span> 和 <span id="inline-blue">语言能力(readability)</span></p><h3 id="1-prerequisite-skills"><a href="#1-prerequisite-skills" class="headerlink" title="1.prerequisite skills"></a>1.prerequisite skills</h3><p>认知能力: measure different types of reasoning and knowledge required to answer the question</p><p>定义了 13 种认知能力<a href="王炳宁《A_Cognitive_Perspective_of_Machine_Comprehension_And_Recent_Advances》">^4</a>, 如下:</p><ol><li>object tracking 目标跟踪<ul><li>同时锁定和跟踪多个目标，如集合或个体，也被称为列举或枚举</li></ul></li><li>mathematical reasoning 数学推理<ul><li>能够完成统计或者量化操作</li></ul></li><li>coreference resolution 指代消解<ul><li>将指代词映射到相应的实体上</li></ul></li><li>logical reasoning 逻辑推理<ul><li>逻辑操作，例如对量词、否定、条件以及转移推理</li></ul></li><li>analogy 类比<ul><li>能够了解一些隐喻，如转喻和提喻</li></ul></li><li>causal relation 因果关系<ul><li>理解文本中的因果关系</li></ul></li><li>spatiotemporal relation 空间关系<ul><li>理解空间或者时间上的关系</li></ul></li><li>ellipsis 省略<ul><li>识别出文章中隐含或者忽略的信息，如参数、谓词、量词、时间等等</li></ul></li><li>bridging 间接引用<ul><li>能够根据词法或者句法的信息进行推理</li></ul></li><li>elaboration 阐述<ul><li>能够根据已有事实/常识进行推理</li></ul></li><li>meta-knowledge 元知识<ul><li>理解读者、作者或者文体信息（如：谁是这个故事的主人公）</li></ul></li><li>schematic clause relation 短语关系<ul><li>理解包含有并列、从句或者关系子句的复杂句子</li></ul></li><li>punctuation 标点符号<ul><li>理解文章中标点符号代表的意义</li></ul></li></ol><p>备注：</p><ul><li>认知能力与RC的一个联系是：当回答一个问题时，需要用到的认知能力越多，该问题越难回答</li><li>9和10的区别在于：9利用词项/句法信息还是10通用的常识信息</li><li>8到11是对Commonsense reasoning的细致分类</li><li>1-11是涉及到多句的，12-13涉及单句</li></ul><h3 id="2-readability"><a href="#2-readability" class="headerlink" title="2.readability"></a>2.readability</h3><p>语言能力: 如何将低层次的文本符号（字、词）组合为高层次的含义的能力<br>measures the text ease of processing and a wide range of linguistic features/human readability measurements are used.</p><ul><li>词义辨析：正确理解和区分词的意思。</li><li>句法识别：识别出文本的句法信息，使推理过程不受句法 变化的影响。</li><li>语义组合：根据句法信息将基本单元（字、词）的语义组 合成高等单元（句子，篇章）的语义。</li></ul><h2 id="Metrics-Evaluation"><a href="#Metrics-Evaluation" class="headerlink" title="Metrics/Evaluation"></a>Metrics/Evaluation</h2><p>如何评价一个example的难度？</p>]]></content>
      
      
      <categories>
          
          <category> MRC-Research </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> mrc </tag>
            
            <tag> research </tag>
            
            <tag> metric </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器阅读理解数据集</title>
      <link href="/2019/01/12/mrc-dataset-info/"/>
      <url>/2019/01/12/mrc-dataset-info/</url>
      
        <content type="html"><![CDATA[<p>Contributed by Luxi Xing and Yuqiang Xie. IIE, CAS.</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Based on the style of the ANSWER for each datasets, we split the datasets into several category and we will give details for each datasets.</p><blockquote><ol><li><a href="#Extractive">Extractive</a></li><li><a href="#Multi-Choice">Multi-Choice</a></li><li><a href="#Generative">Generative</a></li><li><a href="#Sequential">Sequential</a></li><li><a href="#Others">Others</a><br><del>Cloze-Style</del></li></ol></blockquote><h2 id="Extractive"><a href="#Extractive" class="headerlink" title="Extractive"></a>Extractive</h2><table><thead><tr><th>Dataset</th><th>Language</th><th>Domain</th><th>#Train<br>#Doc</th><th>#Dev</th><th>#Test</th><th>Year</th><th>Features</th></tr></thead><tbody><tr><td>SQuADv1</td><td>English</td><td>Wikipedia</td><td>87599<br>442</td><td>10570<br>48</td><td>9533<br>46</td><td>2016</td><td></td></tr><tr><td>SQuADv2</td><td>English</td><td>Wikipedia</td><td>130319<br>442</td><td>11873<br>35</td><td>8862<br>28</td><td>2018</td><td>have no answer</td></tr><tr><td>TriviaQA</td><td>English</td><td>Web<br>Wikipedia</td><td>528979<br>61888</td><td>68621<br>9951</td><td>65059<br>9509</td><td>2017</td><td>avg. length is 2895</td></tr><tr><td>HotPotQA</td><td>English</td><td>Wikipedia</td><td>90564</td><td>7405</td><td>7405</td><td>2017</td><td>multiple supporting doc. to answer</td></tr><tr><td>Natural Questions</td><td>English</td><td>Wikipedia</td><td>307k</td><td>8k</td><td>8k</td><td>2019</td><td>whole wikipedia article;<br>long answer</td></tr></tbody></table><h2 id="Multi-Choice"><a href="#Multi-Choice" class="headerlink" title="Multi-Choice"></a>Multi-Choice</h2><table><thead><tr><th>Dataset</th><th>Language</th><th>Domain</th><th>#Train<br>#Doc</th><th>#Dev</th><th>#Test</th><th>Year</th><th>Features</th></tr></thead><tbody><tr><td>RACE</td><td>English</td><td>Multi</td><td>87866<br>25137</td><td>4887<br>1389</td><td>4934<br>1407</td><td>2017</td><td>high<br>middle</td></tr><tr><td>MCScript</td><td>English</td><td>InScript</td><td>9731<br>1470</td><td>1411<br>219</td><td>2797<br>430</td><td>2018</td><td></td></tr><tr><td>ARC</td><td>English</td><td>Science</td><td></td><td></td><td>14M/7787</td><td>2018</td><td>hard</td></tr><tr><td>OpenBook</td><td>English</td><td></td><td>4957</td><td>500</td><td>500</td><td>2018</td><td>multi-hop;<br>commonsense;<br>science fact</td></tr><tr><td>MultiRC</td><td>English</td><td>7 domain</td><td>9872<br>871</td><td></td><td></td><td>2018</td><td>multi correct answers</td></tr><tr><td>QAngaroo<br>wikihop</td><td>English</td><td></td><td>43738</td><td>5129</td><td>2451</td><td>2017</td><td>multi evidence pieces;<br>multi options</td></tr><tr><td>DREAM</td><td>English</td><td></td><td></td><td></td><td></td><td>2019</td><td>dialogue-based multi-choice</td></tr></tbody></table><h2 id="Generative"><a href="#Generative" class="headerlink" title="Generative"></a>Generative</h2><p>Free-form answer generation</p><table><thead><tr><th>Dataset</th><th>Language</th><th>Domain</th><th>#Train</th><th>#Dev</th><th>#Test</th><th>Year</th><th>Features</th></tr></thead><tbody><tr><td>MSMARCO<br>v1</td><td>English</td><td>Web</td><td></td><td></td><td>100k</td><td>2016</td><td></td></tr><tr><td>MSMARCO<br>v2</td><td>English</td><td>Web</td><td></td><td></td><td>100k</td><td>2018</td><td></td></tr><tr><td>NarrativeQA</td><td>English</td><td>book/moive<br>(wikipedia)</td><td>32747</td><td>3461</td><td>10557</td><td>2018</td><td>based on summary</td></tr><tr><td>DuReader</td><td>Chinese</td><td>Web</td><td></td><td></td><td></td><td>2017</td><td></td></tr></tbody></table><ul><li>Metric for evaluate the Generative-style QA dataset is: ROUGE-L/BLEU</li></ul><h3 id="MS-MARCO"><a href="#MS-MARCO" class="headerlink" title="MS MARCO"></a>MS MARCO</h3><ul><li>More details about MSMARCO, please reference to <a href="https://github.com/IndexFziQ/MSMARCO-MRC-Analysis" target="_blank" rel="noopener">this REPO</a></li></ul><h3 id="Narrative-QA"><a href="#Narrative-QA" class="headerlink" title="Narrative QA"></a>Narrative QA</h3><ul><li>dataset consists of two settings:<ul><li>based on the summary： average 659 tokens</li><li>based on the full book/movie script: average 62528 tokens</li></ul></li></ul><h2 id="Sequential"><a href="#Sequential" class="headerlink" title="Sequential"></a>Sequential</h2><table><thead><tr><th>Dataset</th><th>Language</th><th>Domain</th><th>Document</th><th>Question</th><th>Size<br>(Train/Dev/Test)</th><th>Year</th><th>Features</th></tr></thead><tbody><tr><td>QuAC</td><td>English</td><td>Wikipedia</td><td></td><td></td><td></td><td>2018</td><td></td></tr><tr><td>CoQA</td><td>English</td><td>Wikipedia</td><td></td><td></td><td></td><td>2018</td><td></td></tr><tr><td>DREAM</td><td>English</td><td>Daily life</td><td>6444</td><td>10197</td><td></td><td>2019</td><td>dialogue-based multi-choice;<br>multi-turn multi-party</td></tr></tbody></table><h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><h3 id="Chinese-Datasets"><a href="#Chinese-Datasets" class="headerlink" title="Chinese Datasets"></a>Chinese Datasets</h3><ul><li>People Daily &amp; Children’s Fairy Tale (PD&amp;CFT): <a href="https://github.com/ymcui/Chinese-RC-Dataset" target="_blank" rel="noopener">https://github.com/ymcui/Chinese-RC-Dataset</a><ul><li>cloze-style</li></ul></li><li>dureader: <a href="https://github.com/baidu/DuReader" target="_blank" rel="noopener">https://github.com/baidu/DuReader</a><ul><li>generative</li></ul></li><li>cmrc2018: <a href="https://github.com/ymcui/cmrc2018" target="_blank" rel="noopener">https://github.com/ymcui/cmrc2018</a><ul><li>extractive</li></ul></li></ul><h3 id="Multi-Documents-Datasets"><a href="#Multi-Documents-Datasets" class="headerlink" title="Multi-Documents Datasets"></a>Multi-Documents Datasets</h3><ul><li>TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension.</li><li>SearchQA: A new Q&amp;A dataset augmented with context from a search engine.</li><li>HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering.</li></ul><h3 id="Commonsense-Reasoning"><a href="#Commonsense-Reasoning" class="headerlink" title="Commonsense Reasoning"></a>Commonsense Reasoning</h3><ul><li>Winograd Schema Challenge. <a href="https://cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WS.html" target="_blank" rel="noopener">https://cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WS.html</a></li><li>COPA: Choice of Plausible Alternatives. <a href="https://www.cs.york.ac.uk/semeval-2012/task7/index.html" target="_blank" rel="noopener">https://www.cs.york.ac.uk/semeval-2012/task7/index.html</a></li><li>ReCoRD: Bridging the Gap between Human and Machine Commonsense Reading Comprehension</li><li>CommonsenseQA</li></ul><h3 id="FEVER-Fact-Extraction-and-VERification"><a href="#FEVER-Fact-Extraction-and-VERification" class="headerlink" title="FEVER: Fact Extraction and VERification"></a>FEVER: Fact Extraction and VERification</h3><ul><li>FEVER data: <a href="http://fever.ai/resources.html" target="_blank" rel="noopener">link</a></li><li>FEVER shared Task(with NAACL 2018) info: <a href="http://fever.ai/task.html" target="_blank" rel="noopener">details here</a></li><li>FEVER official baseline code: <a href="https://github.com/sheffieldnlp/fever-naacl-2018" target="_blank" rel="noopener">github repo</a></li><li>my note and analysis of FEVER: <a href="/2019/01/15/mrc-analysis-fever/" title="fever-note">fever-note</a></li></ul><h3 id="Google-Natural-Questions"><a href="#Google-Natural-Questions" class="headerlink" title="Google Natural Questions"></a>Google Natural Questions</h3><p>official details: <a href="https://ai.googleblog.com/2019/01/natural-questions-new-corpus-and.html" target="_blank" rel="noopener">https://ai.googleblog.com/2019/01/natural-questions-new-corpus-and.html</a><br>github: <a href="https://github.com/google-research-datasets/natural-questions" target="_blank" rel="noopener">https://github.com/google-research-datasets/natural-questions</a></p><p>自然问题数据集(NQ)是一个公开的自然发生问题(即由寻求信息的人提出的问题)</p><ul><li>用于训练和评估开放领域问答系统的新的、大规模语料库;</li><li>也是第一个复制人类查找问题答案的端到端流程的语料库;</li><li>专注于通过阅读整个页面来查找答案，而不是从一个短段落中提取答案;</li><li>来源于Wikipedia;</li><li>人工注释答案:<ul><li>要求注释者通过通读整个维基百科页面来找到答案，就好像这个问题是他们自己提出的一样。</li><li>注释者需要找到一个长答案和一个短答案，长答案涵盖推断问题所需的所有信息，短答案需要用一个或多个实体的名称简洁地回答问题</li></ul></li></ul><p><strong>自然语言理解挑战：</strong></p><ul><li>NQ的目的是使QA系统能够阅读和理解完整的维基百科文章，其中可能包含问题的答案，也可能不包含问题的答案。</li><li>系统首先需要确定这个问题的定义是否足够充分，是否可以回答<ul><li>许多问题本身基于错误的假设，或者过于模糊，无法简明扼要地回答。</li></ul></li><li>然后，系统需要确定维基百科页面中是否包含推断答案所需的所有信息。</li><li>作者认为，相比在知道长答案后在寻找短答案，长答案识别任务(找到推断答案所需的所有信息)需要更深层次的语言理解。</li></ul><p>human upper bound:</p><ul><li>long answer selection task: 87% F1</li><li>short answer selection task: 76% F1</li></ul><p>dataset statistics:</p><ul><li>train: 307k</li><li>dev: 8k</li><li>test: 8k</li></ul>]]></content>
      
      
      <categories>
          
          <category> MRC-Research </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> mrc </tag>
            
            <tag> paper </tag>
            
            <tag> dataset </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-Granular Sequence Encoding via Dilated Compositional Units for Reading Comprehension</title>
      <link href="/2019/01/12/paper-emnlp2018-dcu/"/>
      <url>/2019/01/12/paper-emnlp2018-dcu/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Multi-Granular Sequence Encoding via Dilated Compositional Units for Reading Comprehension<br>EMNLP 2018<br>Yi Tay et al.<br>多粒度/尺度序列编码; 膨胀组合单元</p></blockquote><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><ul><li>Sequence encoder是MRC中的重要部件: helps to model compositionality of words, capturing rich and complex linguistic and syntactic structure in language</li><li>Sequence encoder的问题:<ul><li>文档较长，文档数多时计算开销大;</li><li>限制获取长距离上下文;</li><li>限制了多句和文档内部的推理;</li></ul></li><li>本文工作: 采取组合式编码方式<ul><li>主要思路是将多个尺度的信息组合在一起进行编码，利用多尺度 n 元语法信息来实现语义融合，得到更好的文档表达，用于后续的推理和Attention操作.</li><li>设计了一种 dilated compositions 机制来建模多个尺度之间的关系，相当于通过门控的方式决定要保留多少信息<ul><li>多尺度 包括：word-level、phrase-level、sentence-level、paragraph-level etc.</li><li>一种 divide-and-conquer 的序列编码方式</li></ul></li></ul></li><li>本文贡献:<ul><li>提出了一个 compositional encoder DCU (Dilated Compositional Units), DCU 既可以进行独立编码，也可以以RNN-style的方式进行更有表示能力的编码；</li><li>DCU 可以加速序列编码速度，并且保持相邻词之间的交互关系；</li><li>建模长句子时，模型可以获得前方更多的信息，是对所有上下文的全局概览；</li><li>相当于一个门控单元对不同粒度的关系进行建模，有利于捕获文档内部细粒度关系；</li></ul></li></ul><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><ul><li>DCU用于MRC时的整体结构，左侧为DCU Encoder，右侧为DCU分别用于span prediction model和Multiple choice model的结构:<br><img src="/.io//dcu-1-overall.png" alt="dcu-model"></li></ul><p>本节只介绍 DCU 的操作和 encoding 操作，不对整体的mrc模型进行介绍</p><h3 id="Dilated-Compositional-Mechanism"><a href="#Dilated-Compositional-Mechanism" class="headerlink" title="Dilated Compositional Mechanism"></a>Dilated Compositional Mechanism</h3><p>Notations:</p><ul><li>Input Sequence: $S=[w_1, w_2, …, w_l]$</li><li>Range list: $R={r_1, r_2, …, r_k}$<ul><li>$k$ 表示进行 $k$ 次 fold/unfold 操作</li></ul></li></ul><h4 id="1-Fold"><a href="#1-Fold" class="headerlink" title="1.Fold"></a>1.Fold</h4><p>对于每个 $r_j$:</p><ul><li>将$S$中的每 $r_j$ 个词进行串接(concat, neural bag-of-words 表示), 原输入长度缩减为 $l/r_j$</li><li>对于新得到的、包含 $l/r_j$ 个 tokens/blocks 的序列中的每个表示进行如下计算:<ul><li>$\bar{w}_t = \sigma_r(W_a(w_t)) + b_a$</li><li>$W_a \in \mathbb{R}^{d\times d}, b\in \mathbb{R}^d$</li></ul></li><li>Fold 的操作次数等于 range list 的大小</li><li>对于 range list 中不同的 $r$ 值, 参数 $W_a$ 和 $b_a$ 不共享</li></ul><h4 id="2-Unfold"><a href="#2-Unfold" class="headerlink" title="2.Unfold"></a>2.Unfold</h4><p>将transformed之后的序列展开为原长</p><ul><li>下图中为 $r_j=2$ 时的 Fold-Unfold 操作:<br><img src="/.io//dcu-2-op.png" alt="dcu-fold-unfold"></li></ul><h4 id="3-Multi-Granular-Reasoning"><a href="#3-Multi-Granular-Reasoning" class="headerlink" title="3.Multi-Granular Reasoning"></a>3.Multi-Granular Reasoning</h4><p>多尺度推理</p><ul><li>将不同尺度的unfold之后的token表示进行串接，然后通过两层前馈神经网络得到一个门向量<ul><li>$g_t = F_2(F_1([w_1^t,w_2^t,…,w_t^k]))$</li><li>$F(\cdot) = ReLU(Wx+b)$</li></ul></li><li>$g_t$ 相当于一个从多尺度中学习的门控向量，尺度值最低的那些词会拥有相同的 $g_t$ 值</li></ul><h3 id="Encoding-Operation"><a href="#Encoding-Operation" class="headerlink" title="Encoding Operation"></a>Encoding Operation</h3><h4 id="1-Simple-Encoding"><a href="#1-Simple-Encoding" class="headerlink" title="1.Simple Encoding"></a>1.Simple Encoding</h4><ul><li>$z_t = tanh(W_p w_t) + b_p$</li><li>$y_t = \sigma(g_t) \ast w_t + (1-\sigma(g_t))z_t$</li></ul><h4 id="2-Recurrent-Encoding"><a href="#2-Recurrent-Encoding" class="headerlink" title="2.Recurrent Encoding"></a>2.Recurrent Encoding</h4><p>DCU 相当于循环神经网络中的 cell</p><ul><li>$c_t = g_t \odot c_{t-1} + (1-g_t)\odot z_t$</li><li>$o_t = W_o(w_t) + b_o$</li><li>$h_t = o_t \odot c_t$</li></ul><blockquote><p>问题：<br>此处有一点疑问是，为什么通过DCU得到的门控向量 $g_t$ 没有参与到后续的编码过程, 而只是作为了控制初始 $w_t$ 词向量的门控输入</p></blockquote><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><h3 id="Implementation-Details"><a href="#Implementation-Details" class="headerlink" title="Implementation Details"></a>Implementation Details</h3><ul><li>Multi-Choice 模型:<ul><li>数据输入: include the standard EM (exact match) binary feature to each word. In this case, we use a three-way EM adaptation, i.e., EM(P, Q), EM(Q, A) and EM(P, A). The projected embeddings are then passed into a single layered highway network</li><li>输出(答案选择层): 将每个候选答案的答案向量转化为标量<ul><li>$a_j^f=softmax(W_2(\sigma_r(W_1([a_j])+b_1)+b_2))$</li></ul></li></ul></li><li>range valuse: ${1,2,4,10,25}$</li><li>最大序列长度 (RACE/SearchQA/NarrativeQA): $500/200/1100$</li></ul><h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><p>只关注了一下RACE和NarrativeQA上的结果，在没有使用RNN-based编码器的情况下，取得了不错的效果，在论文完成时(2018.03)是RACE上的top-1</p><h4 id="RACE"><a href="#RACE" class="headerlink" title="RACE"></a>RACE</h4><p><img src="/.io//dcu-results-race.png" alt="results-race"></p><h4 id="NarrativeQA"><a href="#NarrativeQA" class="headerlink" title="NarrativeQA"></a>NarrativeQA</h4><p><img src="/.io//dcu-results-narrativeqa.png" alt="results-nqa"></p><h2 id="Summary-amp-Analysis"><a href="#Summary-amp-Analysis" class="headerlink" title="Summary &amp; Analysis"></a>Summary &amp; Analysis</h2><ul><li>对于长文本的编码问题是MRC中的重点问题之一【–&gt;表示问题】<ul><li>长文本和多篇文本</li></ul></li><li>本文提供了一种跨尺度的交互，或是融合跨尺度的信息的有效方式</li></ul>]]></content>
      
      
      <categories>
          
          <category> Paper-Note </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> mrc </tag>
            
            <tag> paper </tag>
            
            <tag> reasoning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WIP| On the Capabilities and Limitations of Reasoning for Natural Language Understanding</title>
      <link href="/2019/01/11/paper-1901-02522/"/>
      <url>/2019/01/11/paper-1901-02522/</url>
      
        <content type="html"><![CDATA[<p>[Under reading]</p><blockquote><p>On the Capabilities and Limitations of Reasoning for Natural Language Understanding<br>Khashabi et al.<br>作者来自 University of Pennsylvania, Indiana University 和 AllennAI<br>题目: 论自然语言理解推理的能力与局限</p></blockquote><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul><li>一些NLU系统在克服查找 Style Reasoning 的语言可变性(linguistic variability)方面具有很强的实力, 但是他们的准确率会随着推理步数的增加而下降.<ul><li>key: style reasoning; linguistic variability; reasoning step;</li></ul></li><li>本文基于上述观察第一次提出了一个正式框架, 旨在解决<strong>使用语言表示隐藏概念空间时引入的</strong>:<ul><li><span id="inline-blue">1.模糊性(ambiguity) </span></li><li><span id="inline-blue">2.冗余性(redundancy) </span></li><li><span id="inline-blue">3.不完整性(incompleteness) </span></li><li><span id="inline-blue">4.不准确性(inaccuracy) </span></li></ul></li><li>模型使用了两个相互关联的(interrelated)空间:<ul><li><span id="inline-green">conceptual meaning space</span>: unambiguous and complete but hidden.</li><li><span id="inline-yellow">linguistic symbol space</span>: captures a noisy grounding of the meaning space in the symbols or words of a language.</li></ul></li><li>本文引用此框架来研究无向图中的连通性(connectivity)问题: 是构成更复杂的多步推理的基础核心推理问题<ul><li>证明了构建高质量算法来检测 latent meaning graph 中的连通性是可能的, 前提: 基于一个可观察的 noisy symbol graph, 并且这些噪声低于我们定量的噪声等级.</li><li>此外, 证明了一个不可能的结果: 如果一个query需要大量的推理步数, no reasoning system operating over the symbol graph is likely to recover any useful property of the meaning graph.</li><li>这一点同时强调了对于推理问题和系统，<strong>需要的是限制两个空间的距离</strong>，而不是投入更多的推理步数(hops)</li></ul></li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li>Reasoning的定义: the process of combining facts(事实) and beliefs(信念), in order to make decisions.</li></ul>]]></content>
      
      
      <categories>
          
          <category> Paper-Note </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> mrc </tag>
            
            <tag> paper </tag>
            
            <tag> nlu </tag>
            
            <tag> reasoning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Text Summarization - Main Problems</title>
      <link href="/2019/01/09/nlp-challenge-ts/"/>
      <url>/2019/01/09/nlp-challenge-ts/</url>
      
        <content type="html"><![CDATA[<p>文本摘要中的主要问题与挑战</p><h2 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h2><p>区分是挑战还是技术问题</p><h3 id="1-关注重点的词、句；"><a href="#1-关注重点的词、句；" class="headerlink" title="1.关注重点的词、句；"></a>1.关注重点的词、句；</h3><ul><li>Attention、pos、tf-idf</li><li>intra-temporal attention</li><li>encoder-less self-attention 【generating Wikipedia by Summarizing long Sequences】</li></ul><h3 id="2-不准确的复制-生成事实细节；"><a href="#2-不准确的复制-生成事实细节；" class="headerlink" title="2.不准确的复制\生成事实细节；"></a>2.不准确的复制\生成事实细节；</h3><ul><li>不准确的复制\生成事实细节；<ul><li>copy</li></ul></li></ul><h3 id="3-重复性短语、句子"><a href="#3-重复性短语、句子" class="headerlink" title="3.重复性短语、句子"></a>3.重复性短语、句子</h3><ul><li>重复性短语、句子；<ul><li>temporal Attention</li><li>coverage</li><li>intra-attention</li></ul></li></ul><h3 id="4-处理长文档"><a href="#4-处理长文档" class="headerlink" title="4.处理长文档"></a>4.处理长文档</h3><ul><li>处理长文档；<ul><li>Sentence-level Attention</li><li>selective gate</li><li>self-attention：缓解长距离依赖</li></ul></li></ul><h3 id="5-生成可读性好的摘要"><a href="#5-生成可读性好的摘要" class="headerlink" title="5.生成可读性好的摘要"></a>5.生成可读性好的摘要</h3><ul><li>生成可读性好的摘要；<ul><li>RL</li></ul></li></ul><h3 id="6-生成新的词（基于理解的基础上）；"><a href="#6-生成新的词（基于理解的基础上）；" class="headerlink" title="6.生成新的词（基于理解的基础上）；"></a>6.生成新的词（基于理解的基础上）；</h3><ul><li>生成新的词（基于理解的基础上）；</li></ul><h3 id="7-词汇问题"><a href="#7-词汇问题" class="headerlink" title="7.词汇问题"></a>7.词汇问题</h3><ul><li>罕见词（rare but important）、未登录词；<ul><li>add n-gram match term to loss【A neural Attention model for Sentence Summarization】</li><li>pointer  </li></ul></li><li>使用大规模词典；candidate sampling</li></ul><h2 id="关注要解决的问题："><a href="#关注要解决的问题：" class="headerlink" title="关注要解决的问题："></a>关注要解决的问题：</h2><ul><li>如何在生成过程中使decoder的注意力更集中，使Attention更聚焦，由于输入序列的长度 比较长？即便使用Attention模型，也不能很好的聚焦到对应的源端token（loss focus）；<ul><li>encoder的输出在用于Attention计算时包含噪声</li><li>使重点更突出；而不是过滤？区别？</li></ul></li><li>copy 机制的贡献程度？<ul><li>以及coverage  </li></ul></li><li>如何判定信息冗余与信息丢失</li></ul>]]></content>
      
      
      <categories>
          
          <category> Text Summarization </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> research </tag>
            
            <tag> challenge </tag>
            
            <tag> ts </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Neural Machine Translation - Main Problems</title>
      <link href="/2019/01/09/nlp-challenge-nmt/"/>
      <url>/2019/01/09/nlp-challenge-nmt/</url>
      
        <content type="html"><![CDATA[<p>神经机器翻译中的主要问题与挑战</p><h2 id="1-难以跨领域"><a href="#1-难以跨领域" class="headerlink" title="1.难以跨领域"></a>1.难以跨领域</h2><p>神经机器翻译（NMT）在处理领域之外的数据时的表现很糟：<br>当前的机器翻译系统会生成非常流畅的输出，这些输出与领域外数据的输入无关。因此像Google翻译这样的通用机器翻译系统在法律或金融等专业领域的表现尤其糟糕。与基于短语的系统等传统方法相比，NMT系统的效果更差。</p><h2 id="2-小数据集上表现不佳"><a href="#2-小数据集上表现不佳" class="headerlink" title="2.小数据集上表现不佳"></a>2.小数据集上表现不佳</h2><p>NMT在小数据集上表现不佳：一般而言，大多数机器学习都是这样，但这个问题在NMT上尤为突出。 NMT的优点在于，随着数据量的增加，它的表现要（比基于短语的机器翻译）更好，但在数据量很低的情况下，NMT的表现确实更差。事实上，正如作者所说，“在资源条件较差的情况下，NMT会产生与输入内容无关的流畅输出。”这可能是Motherboard的文章探讨的一些关于NMT表现奇怪的另一个原因。</p><h2 id="3-罕见词汇"><a href="#3-罕见词汇" class="headerlink" title="3.罕见词汇"></a>3.罕见词汇</h2><p>NMT在罕见词汇上的表现不佳：尽管比基于短语的翻译的表现更好，但NMT对于罕见或未见过的词语翻译的表现不佳。对于存在大量变形词的语言及大量命名实体的领域，这可能成为一个问题，因为变形词和命名实体一般非常罕见。</p><h2 id="4-长句翻译"><a href="#4-长句翻译" class="headerlink" title="4.长句翻译"></a>4.长句翻译</h2><p>长句的翻译问题：对长句编码及生成长句仍然是一个没有解决的问题。 机器翻译系统随句子长度的增加，其表现会越来越糟，NMT系统尤其如此。使用注意力有帮助，但问题远未“解决”。在许多领域，如法律领域，冗长复杂的句子是很常见的。</p><h2 id="5-注意力机制不等于简单对齐"><a href="#5-注意力机制不等于简单对齐" class="headerlink" title="5.注意力机制不等于简单对齐"></a>5.注意力机制不等于简单对齐</h2><p>注意力（Attention）机制不等于简单对齐：这是一个非常微妙但重要的问题。在传统的SMT系统（如基于短语的MT）中，对齐翻译为模型的检测提供了有用的调试信息。但是注意机制不能被视为传统意义上的对齐，即使论文经常将注意力机制作为“软对齐”引起注意。在NMT系统中，除了源语言中的动词之外，目标语言中的动词也可以作为主语和宾语成分。</p><h2 id="6-翻译质量"><a href="#6-翻译质量" class="headerlink" title="6.翻译质量"></a>6.翻译质量</h2><ul><li>难以控制翻译质量：每个单词都有多种翻译，典型的机器翻译系统在源句的翻译结构上表现很好。为了保持句子结构的大小合理，会使用集束搜索（beam search）。通过改变集束宽度，可以找到低概率但正确的平移。而对于NMT系统，调整集束的宽度似乎没有任何影响，甚至可能会有不良影响。</li><li>翻译的忠实度（adequacy）与流畅度（fluency）</li><li>信达雅</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>参考链接：<a href="http://deliprao.com/archives/301" target="_blank" rel="noopener">http://deliprao.com/archives/301</a></li><li>论文地址：<a href="http://www.aclweb.org/anthology/W/W17/W17-3204.pdf" target="_blank" rel="noopener">http://www.aclweb.org/anthology/W/W17/W17-3204.pdf</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> NMT </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> research </tag>
            
            <tag> challenge </tag>
            
            <tag> nmt </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2019年讨论组日程记录</title>
      <link href="/2019/01/09/schedule-2019/"/>
      <url>/2019/01/09/schedule-2019/</url>
      
        <content type="html"><![CDATA[<h1 id="2019年讨论组论文报告会"><a href="#2019年讨论组论文报告会" class="headerlink" title="2019年讨论组论文报告会"></a>2019年讨论组论文报告会</h1><a id="more"></a><style>    table th:nth-of-type(1){    width: 90px;    }    table th:nth-of-type(2){    width: 90px;    }    table th:nth-of-type(3){    width: 50%;    }    table th:nth-of-type(4){    width: 100px;    }</style><table><thead><tr><th align="left">Date</th><th align="left">Reporter</th><th align="left">Title/Papers</th><th align="left">Appx.</th></tr></thead><tbody><tr><td align="left">01.13</td><td align="left">邢璐茜</td><td align="left">Multi-Granular Sequence Encoding via Dilated Compositional Units for RC</td><td align="left"><a href="http://aclweb.org/anthology/D18-1238" target="_blank" rel="noopener">EMNLP2018</a><br><a href="/2019/01/12/paper-emnlp2018-dcu/" title="note link">note link</a></td></tr><tr><td align="left">01.13</td><td align="left">孙雅静</td><td align="left">The Design and Implementation of XiaoIce, an Empathetic Social Chatbot</td><td align="left"><a href="https://arxiv.org/abs/1812.08989" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">01.13</td><td align="left">谢玉强</td><td align="left">Analysis on MS MARCOv1 Leaderboard Top 3:<br>1.S-Net<br>2.V-Net<br>3.MARS<br>Multi-task Learning</td><td align="left"><a href="https://github.com/IndexFziQ/MSMARCO-MRC-Analysis" target="_blank" rel="noopener">details-1</a><br><a href="https://github.com/IndexFziQ/Thinking-about-Multi-Task-Learning" target="_blank" rel="noopener">details-2</a></td></tr><tr><td align="left">01.18</td><td align="left">雷扬帆</td><td align="left">Self-Supervised Learning Introduction</td><td align="left"></td></tr><tr><td align="left">01.18</td><td align="left">魏相鹏</td><td align="left">Meta-Learning Introduction</td><td align="left"><a href="https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html" target="_blank" rel="noopener">blog</a></td></tr><tr><td align="left">01.18</td><td align="left">邢璐茜</td><td align="left">Meta-Learning a Dynamic Language Model</td><td align="left">ICLR workshop</td></tr><tr><td align="left">01.18</td><td align="left">孙雅静</td><td align="left">Continual Leanring Introduction</td><td align="left"></td></tr><tr><td align="left">01.24</td><td align="left">孙雅静</td><td align="left">1. A Dual-Attention Hierarchical RNN for Dialogue Act Classification<br>2.LifeLong Learning with Dynamically Expandable Networks</td><td align="left"></td></tr><tr><td align="left">01.24</td><td align="left">谢玉强</td><td align="left">A Survey to Self-Supervised Learning</td><td align="left"></td></tr><tr><td align="left">01.24</td><td align="left">雷扬帆</td><td align="left">Self-Supervised Learning<br>Unsupervised Learning by Cross-Channel Prediction</td><td align="left"></td></tr><tr><td align="left">01.24</td><td align="left">彭伟</td><td align="left">Attention-over-Attention NN for RC</td><td align="left">ACL,2017</td></tr><tr><td align="left">02.20</td><td align="left">邢璐茜</td><td align="left">Evaluation Metrics for Machine Reading Comprehension: Prerequisite Skills and Readability</td><td align="left">ACL,2017</td></tr><tr><td align="left">02.20</td><td align="left">谢玉强</td><td align="left">Multi-Style Generative Reading Comprehension</td><td align="left"></td></tr><tr><td align="left">02.20</td><td align="left">彭伟</td><td align="left">Match-LSTM</td><td align="left"></td></tr><tr><td align="left">02.20</td><td align="left">孙雅静</td><td align="left">个性化对话:<br>1.Persona-Chat对话数据集<br>2.Personalizing a Dialogue Systems with Transfer Reinforcement Learning</td><td align="left"></td></tr><tr><td align="left">02.20</td><td align="left">于静</td><td align="left">Lifelong Learning Cross Media Search</td><td align="left">ACM-MM</td></tr><tr><td align="left">03.01</td><td align="left">邢璐茜</td><td align="left">TG with Commonsense</td><td align="left"><a href="/2019/01/23/paper-tg-with-commonsense/" title="tg-with-cs-note">tg-with-cs-note</a></td></tr><tr><td align="left">03.01</td><td align="left">谢玉强</td><td align="left">Incorporating Structured Commonsense Knowledge in Story Completion</td><td align="left">AAAI,2019</td></tr><tr><td align="left">03.01</td><td align="left">孙雅静</td><td align="left">What makes a good conversation? How controllable attributes affect human judgments</td><td align="left"></td></tr><tr><td align="left">03.08</td><td align="left">孙雅静</td><td align="left">Learning Personalized End-to-End Goal-Oriented Dialog</td><td align="left">AAAI,2019</td></tr><tr><td align="left">03.08</td><td align="left">于静</td><td align="left">1.Compositional Attention Networks for Machine Reasoning<br>2.Visual Dialog</td><td align="left">ICLR,2018<br>CVPR,2017</td></tr><tr><td align="left">03.08</td><td align="left">邢璐茜</td><td align="left">Commonsense for Generative Multi-Hop Question Answering Tasks</td><td align="left"><a href="http://xingluxi.github.io/2019/02/21/paper-emnlp2018-mhpgm/">details</a></td></tr><tr><td align="left">03.09</td><td align="left">魏相鹏</td><td align="left">1.Cross-Lingual Language Model Pretraining<br>2.An Effective Approach to Unsupervised Machine Translation</td><td align="left"></td></tr><tr><td align="left">03.09</td><td align="left">谢玉强</td><td align="left">Self-supervised learning in video and multi-modal</td><td align="left"></td></tr><tr><td align="left">03.09</td><td align="left">彭伟</td><td align="left">Dynamic Coattention Networks For Question Answering</td><td align="left">ICLR,2017</td></tr><tr><td align="left">03.15</td><td align="left">谢玉强</td><td align="left">Improving Machine Reading Comprehension with General Reading Strategies</td><td align="left"></td></tr><tr><td align="left">03.15</td><td align="left">邢璐茜</td><td align="left">Improving Question Answering with External Knowledge</td><td align="left"></td></tr><tr><td align="left">03.15</td><td align="left">孙雅静</td><td align="left">Learning to Select Knowledge for Response Generation in Dialog System</td><td align="left"></td></tr><tr><td align="left">03.22</td><td align="left">邢璐茜</td><td align="left">Multi-Granularity Hierarchical Attention Fusion Networks for Reading Comprehension and Question Answering</td><td align="left">ACL, 2018</td></tr><tr><td align="left">03.22</td><td align="left">谢玉强</td><td align="left">Tackling the Story Encding Biases in The Story Cloze Test</td><td align="left">ACL,2018</td></tr><tr><td align="left">03.22</td><td align="left">于静</td><td align="left">文本匹配模型介绍</td><td align="left"></td></tr><tr><td align="left">03.29</td><td align="left">邢璐茜</td><td align="left">Multi-Choice Machine Reading Comprehension Task - PartI</td><td align="left"><a href="/2019/03/28/mrc-analysis-multichoice/" title="details">details</a></td></tr><tr><td align="left">03.29</td><td align="left">孙雅静</td><td align="left">Sentence embedding Alignment for LifeLong Relation Extraction</td><td align="left">NAACL,2019</td></tr><tr><td align="left">04.12</td><td align="left">谢玉强</td><td align="left">Does it care what you asked? Understanding Importance of Verbs in QA Model</td><td align="left">EMNLP,2018 workshop</td></tr><tr><td align="left">04.12</td><td align="left">孙雅静</td><td align="left">1.Mem2Seq: Effectively Incorporating Knowledge Bases into End-to-End Task-Oriented Dialog Systems<br>2.Global-to-Local Memory Pointer Networks for Task-Oriented Dialogue</td><td align="left">ACL,2018<br>ICLR,2019</td></tr><tr><td align="left">04.12</td><td align="left">李云鹏</td><td align="left">Relation Extraction Survey - 1</td><td align="left"></td></tr><tr><td align="left">04.19</td><td align="left">邢璐茜</td><td align="left">Commonsense Reasoning for Natural Language Understanding</td><td align="left"><a href="/2019/04/18/mrc-cs-reasoning-for-nlu-survey/" title="detail">detail</a></td></tr><tr><td align="left">05.24</td><td align="left">彭伟</td><td align="left">1.A Deep Cascade Model for Multi-Document Reading Comprehension<br>2.Multi-Granularity Hierarchical Attention Fusion Networks for Reading Comprehension and Question Answering</td><td align="left"></td></tr><tr><td align="left">05.24</td><td align="left">魏相鹏</td><td align="left">MASS: Masked Sequence to Sequence Pre-training for Language Generation</td><td align="left">ICML,2019</td></tr><tr><td align="left">05.31</td><td align="left">邢璐茜</td><td align="left">HotpotQA at ACL 2019</td><td align="left"><a href="http://xingluxi.github.io/2019/05/30/mrc-paper-hotpotqa/">details</a></td></tr><tr><td align="left">05.31</td><td align="left">孙雅静</td><td align="left">Challenges in Building Intelligent Open-domain Dialog Systems</td><td align="left">2019</td></tr><tr><td align="left"></td><td align="left"></td><td align="left"></td><td align="left"></td></tr></tbody></table><h1 id="往期内容列表"><a href="#往期内容列表" class="headerlink" title="往期内容列表"></a>往期内容列表</h1><ul><li><a href="/2019/01/09/schedule-2017-md/" title="2017年讨论组内容列表">2017年讨论组内容列表</a></li><li><a href="/2019/01/09/schedule-2018-md/" title="2018年讨论组内容列表">2018年讨论组内容列表</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Group-Discussion </category>
          
      </categories>
      
      
        <tags>
            
            <tag> schedule </tag>
            
            <tag> group </tag>
            
            <tag> discussion </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>KIM</title>
      <link href="/2019/01/09/paper-kim/"/>
      <url>/2019/01/09/paper-kim/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Neural Natural Language Inference Models Enhanced with External Knowledge<br>ACL,2018.<br>Qian Chen, et al.<br>offical code link: <a href="https://github.com/lukecq1231/kim" target="_blank" rel="noopener">here</a>.</p></blockquote><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>作者针对NLI任务提出了一个问题：</p><ul><li>是否可以从数据中学习NLI所需要的所有知识？</li><li>如果不能，如何使外部知识帮助神经网络模型？如何构建NLI模型利用外部知识？</li></ul><p>本文的工作是作者基于其ESIM模型之上完成的</p><h2 id="Model-Framework"><a href="#Model-Framework" class="headerlink" title="Model Framework"></a>Model Framework</h2><ul><li>模型整体结构分为四部分:<ul><li><img src="/.io//kim.png" alt="kim"></li><li>1、representing</li><li>2、collecting local inference information</li><li>3、aggregating and composing local information</li><li>4、make global decision at sentence level</li><li>其中，将外部知识加入到了: co-attention、local inference collection、inference composition 模块中</li></ul></li></ul><h3 id="External-Knowledge"><a href="#External-Knowledge" class="headerlink" title="External Knowledge"></a>External Knowledge</h3><p>首先确定需要哪些知识来帮助NLI任务</p><ul><li>external, inference-related knowledge</li><li>intuitively Knowledge: <strong>synonymy(同义)</strong>、<strong>antonymy(反义)</strong>、<strong>hypernymy(上位)</strong>、<strong>hyponymy(下位)</strong><ul><li>上下位的关系可以帮助捕捉 entailment 信息</li><li>反义和co-hyponymy(共享相同上位词)的关系可以更好的建模 contradiction 关系</li></ul></li><li>这篇文章主要是引入了基础的词汇级的语义知识<ul><li>建模词$w_i$和$w_j$知识为 $r_{ij}$</li><li>重点是：如何构建 $r_ij$</li></ul></li></ul><h3 id="M1-Encoding-Premise-and-Hypothesis"><a href="#M1-Encoding-Premise-and-Hypothesis" class="headerlink" title="M1.Encoding Premise and Hypothesis"></a>M1.Encoding Premise and Hypothesis</h3><ul><li>premise: $a=(a_1,…,a_m)$</li><li>hypothesis: $b=(b_1,…,b_n)$</li><li>通过BiLSTM进行编码，得到context-dependent 隐藏状态：<ul><li>$a_i^s = Encoder(E(a),i)$</li><li>$b_j^s = Encoder(E(b),j)$</li></ul></li></ul><h3 id="M2-Knowledge-Enriched-Co-Attention"><a href="#M2-Knowledge-Enriched-Co-Attention" class="headerlink" title="M2.Knowledge-Enriched Co-Attention"></a>M2.Knowledge-Enriched Co-Attention</h3><ul><li>知识关系特征：$r_{ij} \in \mathbb{R}^{d_r}$</li><li>Co-attention:<ul><li>$e_{ij} = (a^s_i)^T b_j^s + F(r_{ij})$</li><li>$F(r_{ij}) = \lambda \mathbb{1}(r_{ij})$<ul><li>$\mathbb{1}(r_{ij})$ 判断 $r_{ij}$ 是否为0向量</li></ul></li><li>得到的 co-attention 矩阵 $e \in \mathbb{R}^{m\times n}$</li></ul></li><li>根据co-attention对premise和hypothesis的表示进行更新：<ul><li>$$a_i^c=\sum_{j=1}^n \alpha _{ij} b_j^s$$<ul><li>$$\alpha_{ij} = exp(e_{ij}) / \sum_{k=1}^n exp(e_{ik})$$</li></ul></li><li>$$b_j^c=\sum_{i=1}^m \beta _{ij} a_i^s$$<ul><li>$$\beta_{ij} = exp(e_{ij}) / \sum_{k=1}^m exp(e_{kj})$$</li></ul></li><li>$\alpha \in \mathbb{R}^{m\times n}$、$\beta \in \mathbb{R}^{m\times n}$</li></ul></li></ul><h3 id="M3-Local-inference-Collection-with-External-Knowledge"><a href="#M3-Local-inference-Collection-with-External-Knowledge" class="headerlink" title="M3.Local inference Collection with External Knowledge"></a>M3.Local inference Collection with External Knowledge</h3><ul><li>通过比较$a_i^s$、$a_i^c$ 和 他们的关系（从外部知识获得），可以获得词级的推理信息</li><li>Knowledge-enriched local inference:<ul><li>$$a_i^m = G([a_i^s; a_i^c; a_i^s - a_i^c; a_i^s \circ a_i^c; \sum_{j=1}^n \alpha_{ij}r_{ij}])$$</li><li>$$b_j^m = G([b_j^s; b_j^c; b_j^s - b_j^c; b_j^s \circ b_j^c; \sum_{i=1}^m \beta_{ij}r_{ji}])$$</li><li>最后一项的目的是：收集对齐词之间的关系特征，是从外部知识获得的word-level inference information</li><li>$G$ 是非线性映射，用于降维，relu + shortcut connection<ul><li>$$a_i^m + \sum_{j=1}^n \alpha_{ij}r_{ij}$$</li><li>$$b_j^m + \sum_{i=1}^m \beta_{ij}r_{ij}$$</li></ul></li></ul></li></ul><h3 id="M4-Knowledge-Enhanced-Inference-Composition"><a href="#M4-Knowledge-Enhanced-Inference-Composition" class="headerlink" title="M4.Knowledge-Enhanced Inference Composition"></a>M4.Knowledge-Enhanced Inference Composition</h3><ul><li>决定总体的推理关系：BiLSTM –&gt; mean;max;weighted Pooling，得到定长向量<ul><li>Composition = BiLSTM<ul><li>$a_i^v = Composition(a^m,i)$</li><li>$b_j^v = Composition(b^m,j)$</li></ul></li><li>Weighted Pooling<ul><li>$$a^w = \sum_{i=1}^m \left( \frac{exp(H(\sum_{j=1}^n \alpha_{ij}r_{ij}))}{\sum_{i=1}^m exp(H(\sum_{j=1}^n\alpha_{ij}r_{ij}))} \right) a_i^v$$</li><li>$$b^w = \sum_{j=1}^n \left( \frac{exp(H(\sum_{i=1}^m \beta_{ij}r_{ji}))}{\sum_{j=1}^n exp(H(\sum_{i=1}^m\beta_{ij}r_{ji}))} \right) b_j^v $$</li><li>$H$ 函数是 1层的前馈神经网络，激活函数是relu</li></ul></li></ul></li><li>最后得到定长向量之后，再过一层MLP，激活函数为tanh，和一层 softmax，得到分类结果</li></ul><h2 id="Experiment-Settings"><a href="#Experiment-Settings" class="headerlink" title="Experiment Settings"></a>Experiment Settings</h2><h3 id="Representation-of-External-Knowledge"><a href="#Representation-of-External-Knowledge" class="headerlink" title="Representation of External Knowledge"></a>Representation of External Knowledge</h3><h4 id="Lexical-Semantic-Relations"><a href="#Lexical-Semantic-Relations" class="headerlink" title="Lexical Semantic Relations"></a>Lexical Semantic Relations</h4><ul><li>relations of lexical pairs: 检索范围是wordnet<ul><li>synonymy: 如果词对是同义词，使值为1，否则为0</li><li>antonymy: 如果词对是反义词，使值为1，否则为0</li><li>hypernymy: 如果一个词是另一个词的上位词，取值 $1-\frac{n}{8}$，否则为0<ul><li>其中 $n$ 是两个词在层次上的边数</li><li>忽略边数超过8的</li></ul></li><li>hyponymy: inverse of the hypernymy feature</li><li>co-hyponymys: 如果两个词有相同的上位词且不是同义词，取值为1，否则为0</li><li>向量 $r$ 的维度为 $d_r = 5$</li><li>在 wordnet 中还有额外的一些（15种）关系，但是对结果的提升没有贡献</li></ul></li><li>relation embeddings<ul><li>pretrain based on wordnet</li><li>TransE</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Paper-Note </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> paper </tag>
            
            <tag> knowledge </tag>
            
            <tag> nli </tag>
            
            <tag> wordnet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Knowledgeable Reader Enhancing Cloze-Style Reading Comprehension with External Commonsense Knowledge</title>
      <link href="/2019/01/09/paper-knreader/"/>
      <url>/2019/01/09/paper-knreader/</url>
      
        <content type="html"><![CDATA[<p>Knowledgeable Reader: Enhancing Cloze-Style Reading Comprehension with External Commonsense Knowledge</p><ul><li>ACL,2018. Todor Mihaylov, et al.</li></ul><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><h2 id="Model-Framework"><a href="#Model-Framework" class="headerlink" title="Model Framework"></a>Model Framework</h2><p><img src="/.io//knreader.png" alt="knreader"></p>]]></content>
      
      
      <categories>
          
          <category> Paper-Note </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> mrc </tag>
            
            <tag> paper </tag>
            
            <tag> knowledge </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Knowledge-based NLU-Papers</title>
      <link href="/2019/01/09/kmrc-paper-info/"/>
      <url>/2019/01/09/kmrc-paper-info/</url>
      
        <content type="html"><![CDATA[<p>A list of recent papers on knowledge-based Natural Language Understand.</p><blockquote><p><em>Contributed by Luxi Xing and Yuqiang Xie, National Engineering Laboratory for Information Security Technologies, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China.</em> </p></blockquote><hr><style>    table th:nth-of-type(2){    width: 60%;    }</style><h2 id="NLI-with-Knowledge"><a href="#NLI-with-Knowledge" class="headerlink" title="NLI with Knowledge"></a>NLI with Knowledge</h2><table><thead><tr><th align="center">Conf.</th><th align="left">Title</th><th align="left">Authors/Org.</th><th align="center">Note</th></tr></thead><tbody><tr><td align="center">ACL<br>2018</td><td align="left">Neural Natural Language Inference Models Enhanced with External Knowledge</td><td align="left">Qian Chen</td><td align="center"><a href="/2019/01/09/paper-kim/" title="KIM-note">KIM-note</a></td></tr><tr><td align="center">2018</td><td align="left">Improving Natural Language Inference Using External Knowledge in the Science Questions Domain</td><td align="left">Xiaoyan Wang</td><td align="center"></td></tr></tbody></table><h2 id="MRC-with-Knowledge"><a href="#MRC-with-Knowledge" class="headerlink" title="MRC with Knowledge"></a>MRC with Knowledge</h2><table><thead><tr><th align="center">Conf.</th><th align="left">Title</th><th align="left">Authors/Org.</th><th align="center">Note</th></tr></thead><tbody><tr><td align="center">ACL<br>2017</td><td align="left"><a href="https://doi.org/10.18653/v1/P17-1132" target="_blank" rel="noopener">Leveraging knowledge bases in lstms for improving machine reading</a></td><td align="left">Yang, et al.<br>CMU</td><td align="center"></td></tr><tr><td align="center">ACL<br>2017</td><td align="left"><a href="http://www.aclweb.org/anthology/D17-1086" target="_blank" rel="noopener">World knowledge for reading comprehension: Rare entity prediction with hierarchical lstms using external descriptions</a></td><td align="left">Long, et al.<br>McGill University</td><td align="center"></td></tr><tr><td align="center">ACL<br>2018</td><td align="left"><a href="http://aclweb.org/anthology/P18-1076" target="_blank" rel="noopener">Knowledgeable Reader: Enhancing Cloze-Style Reading Comprehension with External Commonsense Knowledge</a></td><td align="left">Mihaylov, et al.<br>Heidelberg University</td><td align="center"><a href="/2019/01/09/paper-knreader/" title="knreader-note">knreader-note</a></td></tr><tr><td align="center">EMNLP<br>2018</td><td align="left">Commonsense for Generative Multi-Hop Question Answering Tasks</td><td align="left">Lisa Bauer</td><td align="center"><a href="/2019/02/21/paper-emnlp2018-mhpgm/" title="mhpgm-note">mhpgm-note</a></td></tr></tbody></table><h2 id="Dialog-with-Knowledge"><a href="#Dialog-with-Knowledge" class="headerlink" title="Dialog with Knowledge"></a>Dialog with Knowledge</h2><table><thead><tr><th align="center">Conf.</th><th align="left">Title</th><th align="left">Authors/Org.</th><th align="center">Note</th></tr></thead><tbody><tr><td align="center">ACL<br>2017</td><td align="left"><a href="http://aclweb.org/anthology/P17-1162" target="_blank" rel="noopener">Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings</a></td><td align="left">He, et al.<br>Stanford</td><td align="center"></td></tr><tr><td align="center">IJCAI18</td><td align="left"><a href="https://www.ijcai.org/proceedings/2018/0643.pdf" target="_blank" rel="noopener">Commonsense Knowledge Aware Conversation Generation with Graph Attention</a></td><td align="left">Zhou, et al.<br>THU</td><td align="center"><a href="/2019/01/23/paper-tg-with-commonsense/" title="note">note</a></td></tr><tr><td align="center">AAAI<br>2018</td><td align="left"><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/02/A_Knowledge_Grounded_Neural_Conversation_Model.pdf" target="_blank" rel="noopener">A Knowledge-Grounded Neural Conversation Model</a></td><td align="left">Ghazvininejad, et al.<br>Microsoft Research</td><td align="center"></td></tr><tr><td align="center">AAAI<br>2018</td><td align="left"><a href="https://arxiv.org/pdf/1709.04264.pdf" target="_blank" rel="noopener">Flexible End-to-End Dialogue System for Knowledge Grounded Conversation</a></td><td align="left">Zhu, et al.<br>HKUST</td><td align="center"></td></tr><tr><td align="center">2019</td><td align="left">Learning to Select Knowledge for Response Generation in Dialog Systems</td><td align="left">Baidu</td><td align="center"></td></tr></tbody></table><h2 id="Text-Generation-with-Knowledge"><a href="#Text-Generation-with-Knowledge" class="headerlink" title="Text Generation with Knowledge"></a>Text Generation with Knowledge</h2><table><thead><tr><th align="center">Conf.</th><th align="left">Title</th><th align="left">Authors/Org.</th><th align="center">Note</th></tr></thead><tbody><tr><td align="center">AAAI<br>2019</td><td align="left"><a href="https://arxiv.org/abs/1808.10113" target="_blank" rel="noopener">Story Ending Generation with Incremental Encoding and Commonsense Knowledge</a></td><td align="left">Jian Guan, et al.<br>THU</td><td align="center"><a href="/2019/01/23/paper-tg-with-commonsense/" title="note">note</a></td></tr></tbody></table><h2 id="Representation-with-Knowledge"><a href="#Representation-with-Knowledge" class="headerlink" title="Representation with Knowledge"></a>Representation with Knowledge</h2><table><thead><tr><th align="center">Conf.</th><th align="left">Title</th><th align="left">Authors/Org.</th><th align="center">Note</th></tr></thead><tbody><tr><td align="center">ICLR<br>2017</td><td align="left"><a href="https://arxiv.org/pdf/1608.00318v1.pdf" target="_blank" rel="noopener">A Neural Knowledge Language Model</a></td><td align="left">Ahn.et al.<br>Université de Montréal</td><td align="center"></td></tr><tr><td align="center">ACL<br>2017</td><td align="left"><a href="http://aclweb.org/anthology/P17-1187" target="_blank" rel="noopener">Improved Word Representation Learning with Sememes</a></td><td align="left">Niu, et al.<br>THU</td><td align="center"></td></tr><tr><td align="center">ACL<br>2018</td><td align="left"><a href="http://aclweb.org/anthology/D18-1033" target="_blank" rel="noopener">Cross-lingual Lexical Sememe Prediction</a></td><td align="left">Qi, et al.<br>THU</td><td align="center"></td></tr><tr><td align="center">AAAI<br>2018</td><td align="left"><a href="https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16321/16167" target="_blank" rel="noopener">Improving Neural Fine-Grained Entity Typing with Knowledge Attention</a></td><td align="left">Xin, et al.<br>THU</td><td align="center"></td></tr></tbody></table><h4 id="Level"><a href="#Level" class="headerlink" title="Level:"></a>Level:</h4><ol><li>KMRC area.</li><li>Relevant research area.</li><li>Heuristic.</li><li>Review.</li></ol><h4 id="Field"><a href="#Field" class="headerlink" title="Field:"></a>Field:</h4><ul><li><strong>KMRC:</strong> <strong>K</strong>nowledge-based <strong>M</strong>achine <strong>R</strong>eading <strong>C</strong>omprehension;</li><li><strong>KDS:</strong> <strong>K</strong>nowledge-based <strong>D</strong>ialogue <strong>S</strong>ystem;</li><li><strong>KIR:</strong> <strong>K</strong>nowledge-based <strong>I</strong>nformation <strong>R</strong>etrieval;</li><li><strong>SC:</strong> <strong>S</strong>ememe <strong>C</strong>omputation;</li><li><strong>NKLM:</strong> <strong>N</strong>eural <strong>K</strong>nowledge <strong>L</strong>anguage <strong>M</strong>odel.</li></ul>]]></content>
      
      
      <categories>
          
          <category> MRC-Paper-Intro </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nlp </tag>
            
            <tag> paper </tag>
            
            <tag> knowledge </tag>
            
            <tag> text-generation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2018年讨论组日程表</title>
      <link href="/2019/01/09/schedule-2018-md/"/>
      <url>/2019/01/09/schedule-2018-md/</url>
      
        <content type="html"><![CDATA[<h1 id="2018年讨论组论文报告会"><a href="#2018年讨论组论文报告会" class="headerlink" title="2018年讨论组论文报告会"></a>2018年讨论组论文报告会</h1><a id="more"></a><style>    /* 第一列表格宽度 */    table th:nth-of-type(1){    width: 90px;    }    /* 第二列表格宽度 */    table th:nth-of-type(2){    width: 90px;    }    /* 第三列表格宽度 */    table th:nth-of-type(3){    width: 50%;    }    /* 第四列表格宽度 */    table th:nth-of-type(4){    width: 100px;    }</style><table><thead><tr><th align="left">Date</th><th align="left">Reporter</th><th align="left">Title/Papers</th><th align="left">Confere.</th></tr></thead><tbody><tr><td align="left">01.13</td><td align="left">邢璐茜</td><td align="left"><a href="https://papers.nips.cc/paper/6775-deliberation-networks-sequence-generation-beyond-one-pass-decoding.pdf" target="_blank" rel="noopener">Deliberation Networks: Sequence Generation Beyond One-Pass Decoding</a></td><td align="left">NIPS,2017</td></tr><tr><td align="left">01.13</td><td align="left">谢玉强</td><td align="left">词法分析调研</td><td align="left"></td></tr><tr><td align="left">01.13</td><td align="left">孙雅静</td><td align="left">句法分析调研</td><td align="left"></td></tr><tr><td align="left">01.13</td><td align="left">彭  伟</td><td align="left">The Colorful World in the Neural Network</td><td align="left"></td></tr><tr><td align="left">03.17</td><td align="left">邢璐茜</td><td align="left">SIX Challenges In the Text Summarization</td><td align="left"></td></tr><tr><td align="left">03.17</td><td align="left">魏相鹏</td><td align="left">深度学习与文本分类</td><td align="left"></td></tr><tr><td align="left">03.17</td><td align="left">孙雅静</td><td align="left"><a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank" rel="noopener">Attention is all you need</a></td><td align="left">NIPS,2017</td></tr><tr><td align="left">03.17</td><td align="left">谢玉强</td><td align="left">Neural Word Segmentation Learning for Chinese</td><td align="left"></td></tr><tr><td align="left">03.17</td><td align="left">彭  伟</td><td align="left">Neural Network + CRF</td><td align="left"></td></tr><tr><td align="left">04.15</td><td align="left">邢璐茜</td><td align="left">NLG survey(partly)</td><td align="left"></td></tr><tr><td align="left">04.15</td><td align="left">魏相鹏</td><td align="left">NLG survey(partly)</td><td align="left"></td></tr><tr><td align="left">04.15</td><td align="left">雷扬帆</td><td align="left">开题报告</td><td align="left"></td></tr><tr><td align="left">04.15</td><td align="left">谢玉强</td><td align="left">Neural Word Segmentation Learning for Chinese</td><td align="left"></td></tr><tr><td align="left">04.15</td><td align="left">孙雅静</td><td align="left">1. <a href="https://arxiv.org/pdf/1711.02281.pdf" target="_blank" rel="noopener">Non autoregressive neural machine translation</a> <br>2. <a href="https://arxiv.org/pdf/1802.06901.pdf" target="_blank" rel="noopener">Deterministic Non autoregressive neural sequence modeling by iterative refinement</a></td><td align="left">ICLR,2018 <br> arXiv,2018</td></tr><tr><td align="left">04.15</td><td align="left">彭  伟</td><td align="left">毕设报告 + LSTM-CRF</td><td align="left"></td></tr><tr><td align="left">05.12</td><td align="left">邢璐茜</td><td align="left"><a href="https://aclanthology.info/pdf/D/D17/D17-1122.pdf" target="_blank" rel="noopener">Inter-Weighted Alignment Network for Sentence Pair Modeling</a></td><td align="left">EMNLP,2017</td></tr><tr><td align="left">05.12</td><td align="left">魏相鹏</td><td align="left">知识库问答系统-综述</td><td align="left"></td></tr><tr><td align="left">05.12</td><td align="left">雷扬帆</td><td align="left">Low Resource NMT 开题预讲</td><td align="left"></td></tr><tr><td align="left">05.12</td><td align="left">孙雅静</td><td align="left">Recursive Neural Network Architecture</td><td align="left"></td></tr><tr><td align="left">05.12</td><td align="left">谢玉强</td><td align="left"><a href="http://www.aclweb.org/anthology/P16-1122" target="_blank" rel="noopener">Inner Attention based Recurrent Neural Networks for Answer Selection</a></td><td align="left">ACL,2016</td></tr><tr><td align="left">06.09</td><td align="left">邢璐茜</td><td align="left">MRC 综述(Part I)</td><td align="left"></td></tr><tr><td align="left">06.09</td><td align="left">魏相鹏</td><td align="left"><a href="http://www.aclweb.org/anthology/N18-1202" target="_blank" rel="noopener">Deep contextualized word representations</a></td><td align="left">NAACL,2018<br>best paper</td></tr><tr><td align="left">06.09</td><td align="left">雷扬帆</td><td align="left"><a href="http://aclweb.org/anthology/N18-1038" target="_blank" rel="noopener">Learning Visually Grounded Sentence Representations</a></td><td align="left">NAACL-HLT,2018</td></tr><tr><td align="left">06.09</td><td align="left">孙雅静</td><td align="left">Generative Adversarial Network</td><td align="left"></td></tr><tr><td align="left">06.09</td><td align="left">谢玉强</td><td align="left"><a href="https://arxiv.org/pdf/1801.00102" target="_blank" rel="noopener">Compare, Compress and Propagate: Enhancing Neural Architectures with Alignment Factorization for Natural Language Inference</a></td><td align="left">EMNLP,2018</td></tr><tr><td align="left">06.30</td><td align="left">邢璐茜</td><td align="left">MRC 综述(Part II)</td><td align="left"></td></tr><tr><td align="left">06.30</td><td align="left">魏相鹏</td><td align="left"><a href="https://arxiv.org/pdf/1805.09461" target="_blank" rel="noopener">Deep Reinforcement Learning for Sequence to Sequence Models</a></td><td align="left">arXiv,2018</td></tr><tr><td align="left">06.30</td><td align="left">雷扬帆</td><td align="left"><a href="https://www.ijcai.org/proceedings/2017/579" target="_blank" rel="noopener">Bilateral Multi-Perspective Matching for Natural Language Sentences</a></td><td align="left">IJCAI,2017</td></tr><tr><td align="left">06.30</td><td align="left">孙雅静</td><td align="left"><a href="http://aclweb.org/anthology/P18-1087" target="_blank" rel="noopener">Transformation networks for target-oriented sentiment classification</a></td><td align="left">ACL,2018</td></tr><tr><td align="left">06.30</td><td align="left">谢玉强</td><td align="left"><a href="https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf" target="_blank" rel="noopener">Factorization Machines</a></td><td align="left">ICDM,2010</td></tr><tr><td align="left">08.03</td><td align="left">魏相鹏</td><td align="left">1. <a href="http://anthology.aclweb.org/attachments/P/P18/P18-2047.Notes.pdf" target="_blank" rel="noopener">A Simple and Effective Approach to Coverage-Aware NMT</a><br>2. <a href="http://www.aclweb.org/anthology/P18-2053" target="_blank" rel="noopener">Bag-of-Words as Traget for NMT</a></td><td align="left">ACL,2018<br>short paper</td></tr><tr><td align="left">08.03</td><td align="left">孙雅静</td><td align="left">对话系统综述</td><td align="left"></td></tr><tr><td align="left">08.03</td><td align="left">谢玉强</td><td align="left"><a href="https://arxiv.org/pdf/1801.03603" target="_blank" rel="noopener">Syntax-aware Entity Embedding for Neural Relation Extraction</a></td><td align="left">AAAI,2018</td></tr><tr><td align="left">08.03</td><td align="left">彭  伟</td><td align="left">语言表示</td><td align="left"></td></tr><tr><td align="left">08.12</td><td align="left">邢璐茜</td><td align="left">MRC 综述(Part III)</td><td align="left">R-Net<br>FastQA</td></tr><tr><td align="left">08.12</td><td align="left">雷扬帆</td><td align="left"><a href="https://www.ijcai.org/proceedings/2018/0613.pdf" target="_blank" rel="noopener">Multiway Attention Networks for Modeling Sentence Pairs</a></td><td align="left">IJCAI,2018</td></tr><tr><td align="left">08.12</td><td align="left">孙雅静</td><td align="left">对话系统综述-safe response</td><td align="left"></td></tr><tr><td align="left">08.12</td><td align="left">谢玉强</td><td align="left">MRC 模型介绍</td><td align="left"></td></tr><tr><td align="left">08.12</td><td align="left">彭伟</td><td align="left"><a href="http://papers.nips.cc/paper/7209-learned-in-translation-contextualized-word-vectors" target="_blank" rel="noopener">Learned in Translation: Contextualized Word Vectors</a></td><td align="left">NIPS,2017</td></tr><tr><td align="left">08.20</td><td align="left">邢璐茜</td><td align="left">MRC: J-Net Exploring Question understanding &amp; Adaptation in NN-based QA</td><td align="left"></td></tr><tr><td align="left">08.20</td><td align="left">魏相鹏</td><td align="left">VAE与NMT<br>1. <a href="https://arxiv.org/abs/1605.07869" target="_blank" rel="noopener">Variational Neural Machine Translation</a></td><td align="left">EMNLP,2016</td></tr><tr><td align="left">08.20</td><td align="left">孙雅静</td><td align="left">对话系统: Safe response<br>1. <a href="http://aclweb.org/anthology/D17-1065" target="_blank" rel="noopener">Neural Response Generation via GAN with an Approxiamte Embedding Layer</a><br>2. <a href="http://www.aclweb.org/anthology/P18-1139" target="_blank" rel="noopener">Generating Informative Responses with Controlled Sentence Function</a></td><td align="left">ACL,2018</td></tr><tr><td align="left">09.04</td><td align="left">邢璐茜</td><td align="left">MRC: Adversarial Evaluation &amp; Unanswerable Question for SQuAD</td><td align="left"></td></tr><tr><td align="left">09.04</td><td align="left">魏相鹏</td><td align="left">鲁棒性神经机器翻译</td><td align="left"></td></tr><tr><td align="left">09.04</td><td align="left">雷扬帆</td><td align="left">文本匹配</td><td align="left"></td></tr><tr><td align="left">09.04</td><td align="left">孙雅静</td><td align="left">对话: 对话一致性 <br>1. <a href="https://arxiv.org/pdf/1603.06155.pdf" target="_blank" rel="noopener">A Persona-Based Neural Conversation Model</a><br>2. <a href="http://aclweb.org/anthology/P17-1162" target="_blank" rel="noopener">Learning Symmetric collaborateve Dialogue with Dynamic Knowledge Graph Embedding</a><br>3.<a href="https://arxiv.org/pdf/1808.07042.pdf" target="_blank" rel="noopener">CoQA: A Conversational Question Answering Challenge</a></td><td align="left">arXiv,2016<br> ACL,2017 <br>arXiv,2018</td></tr><tr><td align="left">09.14</td><td align="left">邢璐茜</td><td align="left">MRC: Co-Match for Multi-Choice Reading Comprehension</td><td align="left">ACL,2018</td></tr><tr><td align="left">09.14</td><td align="left">魏相鹏</td><td align="left">文档级神经机器翻译<br>1. <a href="https://arxiv.org/abs/1809.01576" target="_blank" rel="noopener">Document-Level Neural Machine Translation with Hierachical Attention Networks</a></td><td align="left">EMNLP,2018</td></tr><tr><td align="left">09.14</td><td align="left">谢玉强</td><td align="left"><a href="https://arxiv.org/pdf/1608.07905.pdf" target="_blank" rel="noopener">Match-LSTM</a></td><td align="left">ICLR,2017</td></tr><tr><td align="left">09.14</td><td align="left">孙雅静</td><td align="left">文本改写<br>1. <a href="http://aclweb.org/anthology/Q18-1031" target="_blank" rel="noopener">Generating Sentences by Editing Prototypes</a></td><td align="left">TACL,2018</td></tr><tr><td align="left">09.22</td><td align="left">邢璐茜</td><td align="left">CopyNet<br>1. <a href="https://papers.nips.cc/paper/5866-pointer-networks.pdf" target="_blank" rel="noopener">Pointer Network</a><br>2. <a href="http://aclweb.org/anthology/P16-1154" target="_blank" rel="noopener">Incorporating Copying mechanism in Sequence-to-Sequence</a><br>3. <a href="https://arxiv.org/abs/1704.04368" target="_blank" rel="noopener">Get to The Point: Summarization with Pointer-Generator Networks</a></td><td align="left">NIPS,2015 <br>ACL,2016<br>arXiv,2017</td></tr><tr><td align="left">09.22</td><td align="left">魏相鹏</td><td align="left"><a href="http://aclweb.org/anthology/P18-2048" target="_blank" rel="noopener">Dynamic Sentence Sampling for Efficient Training of NMT</a></td><td align="left">ACL,2018</td></tr><tr><td align="left">09.22</td><td align="left">雷扬帆</td><td align="left">Modeling Sentence Tutorial</td><td align="left"></td></tr><tr><td align="left">09.22</td><td align="left">谢玉强</td><td align="left">Two Methods for Training Deeper Networks<br>1. <a href="https://arxiv.org/pdf/1505.00387.pdf" target="_blank" rel="noopener">Highway Network</a><br>2. <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf" target="_blank" rel="noopener">Residual Network</a></td><td align="left">ICML,2015<br>CVPR,2016</td></tr><tr><td align="left">09.22</td><td align="left">孙雅静</td><td align="left">GAN回顾</td><td align="left"></td></tr><tr><td align="left">09.22</td><td align="left">彭伟</td><td align="left"><a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank" rel="noopener">Neural Machine Translation by Jointly Learning to Align and Translate</a></td><td align="left">ICLR,2015</td></tr><tr><td align="left">10.20</td><td align="left">邢璐茜</td><td align="left">The Pre-Training Language Model<br>1. <a href="https://arxiv.org/pdf/1810.04805.pdf" target="_blank" rel="noopener">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></td><td align="left">arXiv,2018</td></tr><tr><td align="left">10.20</td><td align="left">魏相鹏</td><td align="left"><a href="https://openreview.net/pdf?id=ryza73R9tQ" target="_blank" rel="noopener">Machine Translation with Weakly Paired Bilingual Documents</a></td><td align="left">ICLR,2019.<br>OpenReview</td></tr><tr><td align="left">10.20</td><td align="left">谢玉强</td><td align="left"><a href="https://arxiv.org/pdf/1805.11360.pdf" target="_blank" rel="noopener">Semantic Sentence Matching with Densely-connected Recurrent and Co-attentive Information</a></td><td align="left">AAAI,2019</td></tr><tr><td align="left">10.20</td><td align="left">孙雅静</td><td align="left"><a href="https://aclanthology.info/papers/P17-1171/p17-1171" target="_blank" rel="noopener">Reading Wikipedia to Answer Open-domain Questions</a></td><td align="left">ACL,2017</td></tr><tr><td align="left">10.20</td><td align="left">彭  伟</td><td align="left"><a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank" rel="noopener">Attention is all you need</a></td><td align="left">NIPS,2017</td></tr><tr><td align="left">11.17</td><td align="left">邢璐茜</td><td align="left">MRC: Multi-Step Reasoning &amp; Open-Domain QA <br>1. <a href="http://aclweb.org/anthology/P18-1157" target="_blank" rel="noopener">Stochastic Answer Networks for Machine Reading Comprehension</a><br>2. <a href="http://aclweb.org/anthology/P18-1161" target="_blank" rel="noopener">Denoising Distantly Supervised Open-Domain Question Answering</a></td><td align="left">ACL,2018<br>ACL,2018</td></tr><tr><td align="left">11.17</td><td align="left">孙雅静</td><td align="left">1. <a href="http://www.aclweb.org/anthology/P17-1046" target="_blank" rel="noopener">Sequential Matching Network：A New Architecture for Multi-turn Response Selection in Retrieval-Based Chatbots</a><br>2. <a href="https://openreview.net/forum?id=ByftGnR9KX" target="_blank" rel="noopener">FlowQA: Grasping Flow in History for Conversational Machine Comprehension</a></td><td align="left">ACL,2017<br>ICLR,2019.OR</td></tr><tr><td align="left">11.17</td><td align="left">彭  伟</td><td align="left">文本分类<br>1. <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/download/9745/9552" target="_blank" rel="noopener">Recurrent convolutional neural networks for text classification</a> <br>2. <a href="http://www.aclweb.org/anthology/N16-1174" target="_blank" rel="noopener">Hierarchical Attention Networks for Document Classification</a></td><td align="left">AAAI,2015<br>NAACL,2016</td></tr><tr><td align="left">12.09</td><td align="left">邢璐茜</td><td align="left">MRC: external knowledge<br><a href="http://aclweb.org/anthology/P18-1076" target="_blank" rel="noopener">Knowledgeable Reader: Enhancing Cloze-Style Reading Comprehension with External Commonsense Knowledge</a></td><td align="left">ACL,2018</td></tr><tr><td align="left">12.09</td><td align="left">魏相鹏</td><td align="left"><a href="http://aclweb.org/anthology/D18-1045" target="_blank" rel="noopener">Understanding Back-Translation at Scale</a></td><td align="left">EMNLP,2018</td></tr><tr><td align="left">12.09</td><td align="left">彭  伟</td><td align="left"><a href="https://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf" target="_blank" rel="noopener">End-to-End Memory Networks</a></td><td align="left">NIPS,2015</td></tr></tbody></table><h1 id="相关内容列表"><a href="#相关内容列表" class="headerlink" title="相关内容列表"></a>相关内容列表</h1><ul><li><a href="/2019/01/09/schedule-2017-md/" title="2017年讨论组内容列表">2017年讨论组内容列表</a></li><li><a href="/2019/01/09/schedule-2019/" title="2019年讨论组内容列表">2019年讨论组内容列表</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Group-Discussion </category>
          
      </categories>
      
      
        <tags>
            
            <tag> schedule </tag>
            
            <tag> group </tag>
            
            <tag> discussion </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2017年讨论组日程表</title>
      <link href="/2019/01/09/schedule-2017-md/"/>
      <url>/2019/01/09/schedule-2017-md/</url>
      
        <content type="html"><![CDATA[<h1 id="2017年讨论组论文报告会"><a href="#2017年讨论组论文报告会" class="headerlink" title="2017年讨论组论文报告会"></a>2017年讨论组论文报告会</h1><a id="more"></a><style>    /* 第一列表格宽度 */    table th:nth-of-type(1){    width: 90px;    }    /* 第二列表格宽度 */    table th:nth-of-type(2){    width: 90px;    }    /* 第三列表格宽度 */    table th:nth-of-type(3){    width: 50%;    }    /* 第四列表格宽度 */    table th:nth-of-type(4){    width: 100px;    }</style><table><thead><tr><th align="left">日期</th><th align="left">报告人</th><th align="left">报告主题</th><th align="left">简介</th></tr></thead><tbody><tr><td align="left">03.25</td><td align="left">邢璐茜</td><td align="left">Generative Adversarial Nets</td><td align="left"><a href="https://arxiv.org/abs/1406.2661" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">03.25</td><td align="left">魏相鹏</td><td align="left">Neural Architectures for Named Entity Recognition</td><td align="left"><a href="https://arxiv.org/pdf/1603.01360.pdf" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">03.25</td><td align="left">雷扬帆</td><td align="left">使用字符级解码器的机器翻译</td><td align="left"></td></tr><tr><td align="left">04.15</td><td align="left">邢璐茜</td><td align="left">CSGAN for Machine Translation</td><td align="left"><a href="https://arxiv.org/abs/1703.04887" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">04.15</td><td align="left">魏相鹏</td><td align="left">Hybrid Word-Character Models for NMT</td><td align="left"><a href="https://arxiv.org/abs/1604.00788" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">04.15</td><td align="left">雷扬帆</td><td align="left">Character-based Neural Machine Translation</td><td align="left"></td></tr><tr><td align="left">05.06</td><td align="left">邢璐茜</td><td align="left">GAN4NLP</td><td align="left"></td></tr><tr><td align="left">05.06</td><td align="left">魏相鹏</td><td align="left">Neural Machine Translation with Reconstruction</td><td align="left"><a href="https://arxiv.org/abs/1611.01874" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">05.06</td><td align="left">雷扬帆</td><td align="left">Minimum Risk Training &amp; Modeling Coverage</td><td align="left"><a href="https://arxiv.org/abs/1512.02433" target="_blank" rel="noopener">link1</a><br><a href="https://arxiv.org/abs/1601.04811" target="_blank" rel="noopener">link2</a><br></td></tr><tr><td align="left">05.27</td><td align="left">邢璐茜</td><td align="left">Incorporating Copying Mechanism in Sequence-to-Sequence Learning</td><td align="left"><a href="http://www.aclweb.org/anthology/P16-1154" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">05.27</td><td align="left">魏相鹏</td><td align="left">Convolutional Sequence to Sequence Learning</td><td align="left"><a href="https://arxiv.org/abs/1705.03122" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">05.27</td><td align="left">雷扬帆</td><td align="left">多语神经机器翻译</td><td align="left"></td></tr><tr><td align="left">06.17</td><td align="left">邢璐茜</td><td align="left">Context Gates for Neural Machine Translation</td><td align="left"><a href="https://arxiv.org/abs/1608.06043" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">06.17</td><td align="left">魏相鹏</td><td align="left">Massive Exploration of Neural Machine Translation Architectures</td><td align="left"><a href="https://arxiv.org/abs/1703.03906" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">06.17</td><td align="left">雷扬帆</td><td align="left">String-based Translation</td><td align="left"><a href="https://www.isi.edu/natural-language/mt/emnlp16-nmt-grammar.pdf" target="_blank" rel="noopener">link1</a><br><a href="https://arxiv.org/abs/1704.04743" target="_blank" rel="noopener">link2</a><br><a href="https://arxiv.org/abs/1705.01020" target="_blank" rel="noopener">link3</a><br></td></tr><tr><td align="left">07.22</td><td align="left">邢璐茜</td><td align="left">Knowledge-Based Semantic Embedding for Machine Translation</td><td align="left"><a href="http://aclweb.org/anthology/P16-1212" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">07.22</td><td align="left">雷扬帆</td><td align="left">What do Neural Machine Translation Models Learn about Morphology?<br>Visualizing and understanding neural machine translation<br></td><td align="left"><a href="https://arxiv.org/abs/1704.03471" target="_blank" rel="noopener">link1</a><br><a href="http://nlp.csai.tsinghua.edu.cn/~ly/papers/acl2017_dyz.pdf" target="_blank" rel="noopener">link2</a><br></td></tr><tr><td align="left">07.22</td><td align="left">魏相鹏</td><td align="left">Dual Supervised Learning</td><td align="left"><a href="https://arxiv.org/abs/1707.00415" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">08.09</td><td align="left">邢璐茜</td><td align="left">Pointer Network &amp; It’s application in ACL 16\17</td><td align="left"><a href="https://arxiv.org/abs/1506.03134" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">08.16</td><td align="left">雷扬帆</td><td align="left">Interactive Attention for Neural Machine Translation <br> Neural Machine Translation with Supervised Attention</td><td align="left"><a href="https://arxiv.org/abs/1610.05011" target="_blank" rel="noopener">link1</a><br><a href="https://arxiv.org/abs/1609.04186" target="_blank" rel="noopener">link2</a></td></tr><tr><td align="left">09.23</td><td align="left">邢璐茜</td><td align="left">Plan, Attend, Generate: Char-NMT with Planning</td><td align="left"><a href="https://arxiv.org/abs/1706.05087" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">09.23</td><td align="left">魏相鹏</td><td align="left">AI Challenger</td><td align="left"></td></tr><tr><td align="left">09.23</td><td align="left">谢玉强</td><td align="left">RNN</td><td align="left"></td></tr><tr><td align="left">09.23</td><td align="left">孙雅静</td><td align="left">Neural Machine Translation with Word Predictions（EMNLP,2017）</td><td align="left"><a href="http://www.aclweb.org/anthology/D17-1013" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">10.14</td><td align="left">邢璐茜</td><td align="left">CWMT2017 Review</td><td align="left"></td></tr><tr><td align="left">10.14</td><td align="left">魏相鹏</td><td align="left">Experiments</td><td align="left"></td></tr><tr><td align="left">10.14</td><td align="left">谢玉强</td><td align="left">A Character-Aware Encoder for Neural Machine Translation（COLING,2016）</td><td align="left"><a href="http://www.aclweb.org/old_anthology/C/C16/C16-1288.pdf" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">10.14</td><td align="left">孙雅静</td><td align="left">Sequence-to-Dependency Neural Machine Translation（EMNLP,2017）</td><td align="left"><a href="http://www.aclweb.org/anthology/P17-1065" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">11.04</td><td align="left">邢璐茜</td><td align="left">Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems (EMNLP,2015)</td><td align="left"><a href="https://arxiv.org/abs/1508.01745" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">11.04</td><td align="left">魏相鹏</td><td align="left">Topic Aware Neural Response Generation (AAAI,2017)</td><td align="left"><a href="https://arxiv.org/abs/1606.08340" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">11.04</td><td align="left">雷扬帆</td><td align="left">Graph Convolutional Encoders for Syntax-aware Neural Machine Translation</td><td align="left"><a href="https://arxiv.org/abs/1704.04675" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">11.04</td><td align="left">谢玉强</td><td align="left">Agreement on Target-Bidirectional LSTMs for Sequence-to-Sequence Learning (AAAI,2016) <br> Agreement on Target-Bidirectional Neural Machine Translation（NAACL-HLT,2016）</td><td align="left"><a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12028" target="_blank" rel="noopener">link1</a> <br> <a href="http://www.aclweb.org/anthology/N16-1046" target="_blank" rel="noopener">link2</a></td></tr><tr><td align="left">11.04</td><td align="left">孙雅静</td><td align="left">Gated-Attention Readers for Text Comprehension</td><td align="left"><a href="https://arxiv.org/abs/1606.01549" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">11.25</td><td align="left">邢璐茜</td><td align="left">Unsupervised Machine Translation Using Monolingual Corpora Only</td><td align="left"><a href="https://arxiv.org/abs/1711.00043" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">11.25</td><td align="left">魏相鹏</td><td align="left">Unsupervised Neural Machine Translation</td><td align="left"><a href="https://arxiv.org/abs/1710.11041" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">11.25</td><td align="left">孙雅静</td><td align="left">Memory Augmented Neural Machine Translation</td><td align="left">EMNLP,2017<br><a href="https://arxiv.org/abs/1708.02005" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">11.25</td><td align="left">谢玉强</td><td align="left">Incorporating Word Reordering Knowledge into Attention-based Neural Machine Translation</td><td align="left">ACL,2017 <br> <a href="http://www.aclweb.org/anthology/P17-1140" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">12.16</td><td align="left">魏相鹏</td><td align="left">Decoding with Value Networks for Neural Machine Translation</td><td align="left">NIPS,2017 <br> <a href="http://papers.nips.cc/paper/6622-decoding-with-value-networks-for-neural-machine-translation" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">12.16</td><td align="left">孙雅静</td><td align="left">Learning to Remember Translation History with Continuous Cache</td><td align="left">TACL,2018 <br> <a href="https://arxiv.org/abs/1711.09367" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">12.16</td><td align="left">谢玉强</td><td align="left">Adversarial Multi-task Learning for Text Classification</td><td align="left">ACL,2017 <br> <a href="https://arxiv.org/abs/1704.05742" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">01.13</td><td align="left">邢璐茜</td><td align="left">Deliberation Networks: Sequence Generation Beyond One-Pass Decoding</td><td align="left">NIPS,2017 <br> <a href="https://papers.nips.cc/paper/6775-deliberation-networks-sequence-generation-beyond-one-pass-decoding.pdf" target="_blank" rel="noopener">link</a></td></tr><tr><td align="left">01.13</td><td align="left">谢玉强</td><td align="left">词法分析调研</td><td align="left"></td></tr><tr><td align="left">01.13</td><td align="left">孙雅静</td><td align="left">句法分析调研</td><td align="left"></td></tr><tr><td align="left">01.13</td><td align="left">彭  伟</td><td align="left">The Colorful World in the Neural Network</td><td align="left"></td></tr></tbody></table><h1 id="相关内容列表"><a href="#相关内容列表" class="headerlink" title="相关内容列表"></a>相关内容列表</h1><ul><li><a href="/2019/01/09/schedule-2018-md/" title="2018年讨论组内容列表">2018年讨论组内容列表</a></li><li><a href="/2019/01/09/schedule-2019/" title="2019年讨论组内容列表">2019年讨论组内容列表</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Group-Discussion </category>
          
      </categories>
      
      
        <tags>
            
            <tag> schedule </tag>
            
            <tag> group </tag>
            
            <tag> discussion </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/01/07/hello-world/"/>
      <url>/2019/01/07/hello-world/</url>
      
        <content type="html"><![CDATA[<p>This is a post to record some solutions in blog with hexo</p><a id="more"></a><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p><h2 id="美化方案"><a href="#美化方案" class="headerlink" title="美化方案"></a>美化方案</h2><p>参考：<a href="https://jerry011235.github.io/2015/05/06/Hexo%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BC%98%E5%8C%96%EF%BC%88%E4%BA%8C%EF%BC%89/" target="_blank" rel="noopener">https://jerry011235.github.io/2015/05/06/Hexo%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BC%98%E5%8C%96%EF%BC%88%E4%BA%8C%EF%BC%89/</a></p><h3 id="用css控制Markdown表格列宽"><a href="#用css控制Markdown表格列宽" class="headerlink" title="用css控制Markdown表格列宽"></a>用css控制Markdown表格列宽</h3><p>参考: <a href="http://blog.echoxu.cn/2018-05-15-Hexo中用CSS控制Markdown各列表格宽度.html" target="_blank" rel="noopener">http://blog.echoxu.cn/2018-05-15-Hexo中用CSS控制Markdown各列表格宽度.html</a></p><h2 id="编辑"><a href="#编辑" class="headerlink" title="编辑"></a>编辑</h2><h3 id="post样式"><a href="#post样式" class="headerlink" title="post样式"></a>post样式</h3><p>参考: <a href="http://dinghongkai.com/2017/12/19/Blog-development-6-Customized-Style-of-Writing/" target="_blank" rel="noopener">添加文章书写样</a></p><h3 id="添加站内文章链接"><a href="#添加站内文章链接" class="headerlink" title="添加站内文章链接"></a>添加站内文章链接</h3><ul><li><code>\{\% post_link post_name_in_source_posts link_show_title \%}</code></li><li><code>[title](/year/month/day/name.md#section)</code></li></ul><h3 id="字体颜色"><a href="#字体颜色" class="headerlink" title="字体颜色"></a>字体颜色</h3><ul><li>可以直接在Markdown 文档编辑中使用html语法<ul><li><code>&lt;font size=4 &gt; 这里输入文字，自定义大小 &lt;/font&gt;</code></li><li><code>&lt;font color=&quot;#FF0000&quot;&gt; 这里输入文字，自定义颜色的字体 &lt;/font&gt;</code></li></ul></li></ul><h2 id="在Hexo中渲染MathJax数学公式"><a href="#在Hexo中渲染MathJax数学公式" class="headerlink" title="在Hexo中渲染MathJax数学公式"></a>在Hexo中渲染MathJax数学公式</h2><ul><li><a href="https://www.jianshu.com/p/7ab21c7f0674" target="_blank" rel="noopener">https://www.jianshu.com/p/7ab21c7f0674</a></li></ul><h2 id="bugs"><a href="#bugs" class="headerlink" title="bugs"></a>bugs</h2><ul><li><code>fatal: multiple stage entries for merged file &#39;lib/pace&#39;</code><ul><li><code>cd .deploy_git</code></li><li><code>rm .git/index</code></li><li><code>git add -A</code></li><li><code>git commit -m &quot;&quot;</code></li></ul></li></ul><h2 id="迁移"><a href="#迁移" class="headerlink" title="迁移"></a>迁移</h2><ul><li>重装hexo、配置依赖</li><li>Git clone next主题</li><li>复制 站点配置 文件和 主题文件夹</li><li>复制 source 文件夹</li></ul>]]></content>
      
      
      <categories>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> Blog </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
